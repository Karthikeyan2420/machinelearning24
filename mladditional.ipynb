{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abef8702-2f7f-4b07-9935-49777c403077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (KNN): 0.14312849034929087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "data = pd.read_csv('adult.csv')\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                       'relationship', 'race', 'sex', 'nativeCountry']\n",
    "data = pd.get_dummies(data, columns=categorical_columns)\n",
    "data['income'] = data['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3)  # You can adjust 'n_neighbors' as needed\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the KNN model using Mean Squared Error\n",
    "knn_mse = mean_squared_error(y_test, knn_pred)\n",
    "print(f\"Mean Squared Error (KNN): {knn_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b126cc3a-26c1-42c5-9740-055302b7575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 11.54\n",
      "Baseline MSE: 36.52\n",
      "The Decision Tree model performs better than the baseline.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.drop('cv', axis=1)\n",
    "y = data['cv']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Decision Tree Regressor\n",
    "tree = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_tree = mean_squared_error(y_test, y_pred)\n",
    "print(f'Decision Tree MSE: {mse_tree:.2f}')\n",
    "\n",
    "# Baseline Model: Mean Predictor\n",
    "y_baseline_pred = np.full(shape=y_test.shape, fill_value=y_train.mean())\n",
    "mse_baseline = mean_squared_error(y_test, y_baseline_pred)\n",
    "print(f'Baseline MSE: {mse_baseline:.2f}')\n",
    "\n",
    "# Interpretation\n",
    "if mse_tree < mse_baseline:\n",
    "    print(\"The Decision Tree model performs better than the baseline.\")\n",
    "else:\n",
    "    print(\"The Decision Tree model does not outperform the baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4be145-ea82-4af8-96e7-3302a5980117",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feed forward neural networks are artificial neural networks in\n",
    "which nodes do not form loops. This type of neural network is also known\n",
    "as a multi-layer neural network as all information is\n",
    "only passed forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee00e449-228e-4d4c-95a1-9c4a0956743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 91.1011 - mean_squared_error: 91.1011 - val_loss: 33.7534 - val_mean_squared_error: 33.7534\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 90.2831 - mean_squared_error: 90.2831 - val_loss: 33.1942 - val_mean_squared_error: 33.1942\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 89.4732 - mean_squared_error: 89.4732 - val_loss: 32.6372 - val_mean_squared_error: 32.6372\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 88.6574 - mean_squared_error: 88.6574 - val_loss: 32.0934 - val_mean_squared_error: 32.0934\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 87.8500 - mean_squared_error: 87.8500 - val_loss: 31.5719 - val_mean_squared_error: 31.5719\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 87.0345 - mean_squared_error: 87.0345 - val_loss: 31.0605 - val_mean_squared_error: 31.0605\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 86.2250 - mean_squared_error: 86.2250 - val_loss: 30.5491 - val_mean_squared_error: 30.5491\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 85.4458 - mean_squared_error: 85.4458 - val_loss: 30.0528 - val_mean_squared_error: 30.0528\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 84.7013 - mean_squared_error: 84.7013 - val_loss: 29.5300 - val_mean_squared_error: 29.5300\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 83.9732 - mean_squared_error: 83.9732 - val_loss: 29.0050 - val_mean_squared_error: 29.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 83.2380 - mean_squared_error: 83.2380 - val_loss: 28.4849 - val_mean_squared_error: 28.4849\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 82.4954 - mean_squared_error: 82.4954 - val_loss: 27.9765 - val_mean_squared_error: 27.9765\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 81.7645 - mean_squared_error: 81.7645 - val_loss: 27.4934 - val_mean_squared_error: 27.4934\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 81.0732 - mean_squared_error: 81.0732 - val_loss: 27.0124 - val_mean_squared_error: 27.0124\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 80.3878 - mean_squared_error: 80.3878 - val_loss: 26.5240 - val_mean_squared_error: 26.5240\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 79.6945 - mean_squared_error: 79.6945 - val_loss: 26.0470 - val_mean_squared_error: 26.0470\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 78.9868 - mean_squared_error: 78.9868 - val_loss: 25.5691 - val_mean_squared_error: 25.5691\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 78.2537 - mean_squared_error: 78.2537 - val_loss: 25.0905 - val_mean_squared_error: 25.0905\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 77.5179 - mean_squared_error: 77.5179 - val_loss: 24.6135 - val_mean_squared_error: 24.6135\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 76.7901 - mean_squared_error: 76.7901 - val_loss: 24.1389 - val_mean_squared_error: 24.1389\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 76.0626 - mean_squared_error: 76.0626 - val_loss: 23.6684 - val_mean_squared_error: 23.6684\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 75.3242 - mean_squared_error: 75.3242 - val_loss: 23.2015 - val_mean_squared_error: 23.2015\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 74.5768 - mean_squared_error: 74.5768 - val_loss: 22.7326 - val_mean_squared_error: 22.7326\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 73.8125 - mean_squared_error: 73.8125 - val_loss: 22.2639 - val_mean_squared_error: 22.2639\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 73.0315 - mean_squared_error: 73.0315 - val_loss: 21.7957 - val_mean_squared_error: 21.7957\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 72.2374 - mean_squared_error: 72.2374 - val_loss: 21.3299 - val_mean_squared_error: 21.3299\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 71.4361 - mean_squared_error: 71.4361 - val_loss: 20.8663 - val_mean_squared_error: 20.8663\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 70.6274 - mean_squared_error: 70.6274 - val_loss: 20.4061 - val_mean_squared_error: 20.4061\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 69.7979 - mean_squared_error: 69.7979 - val_loss: 19.9472 - val_mean_squared_error: 19.9472\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 68.9511 - mean_squared_error: 68.9511 - val_loss: 19.4733 - val_mean_squared_error: 19.4733\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 68.1019 - mean_squared_error: 68.1019 - val_loss: 18.9877 - val_mean_squared_error: 18.9877\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 67.2366 - mean_squared_error: 67.2366 - val_loss: 18.5039 - val_mean_squared_error: 18.5039\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 66.3535 - mean_squared_error: 66.3535 - val_loss: 18.0248 - val_mean_squared_error: 18.0248\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 65.4530 - mean_squared_error: 65.4530 - val_loss: 17.5521 - val_mean_squared_error: 17.5521\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 64.5342 - mean_squared_error: 64.5342 - val_loss: 17.0791 - val_mean_squared_error: 17.0791\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 63.5940 - mean_squared_error: 63.5940 - val_loss: 16.5962 - val_mean_squared_error: 16.5962\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 62.6372 - mean_squared_error: 62.6372 - val_loss: 16.1143 - val_mean_squared_error: 16.1143\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 61.6630 - mean_squared_error: 61.6630 - val_loss: 15.6357 - val_mean_squared_error: 15.6357\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 60.6688 - mean_squared_error: 60.6688 - val_loss: 15.1609 - val_mean_squared_error: 15.1609\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 59.6583 - mean_squared_error: 59.6583 - val_loss: 14.6905 - val_mean_squared_error: 14.6905\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 58.6320 - mean_squared_error: 58.6320 - val_loss: 14.2254 - val_mean_squared_error: 14.2254\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 57.5906 - mean_squared_error: 57.5906 - val_loss: 13.7663 - val_mean_squared_error: 13.7663\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 56.5340 - mean_squared_error: 56.5340 - val_loss: 13.3143 - val_mean_squared_error: 13.3143\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 55.4628 - mean_squared_error: 55.4628 - val_loss: 12.8699 - val_mean_squared_error: 12.8699\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 54.3771 - mean_squared_error: 54.3771 - val_loss: 12.4339 - val_mean_squared_error: 12.4339\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 53.2774 - mean_squared_error: 53.2774 - val_loss: 12.0080 - val_mean_squared_error: 12.0080\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 52.1642 - mean_squared_error: 52.1642 - val_loss: 11.5929 - val_mean_squared_error: 11.5929\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 51.0381 - mean_squared_error: 51.0381 - val_loss: 11.1897 - val_mean_squared_error: 11.1897\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 49.8962 - mean_squared_error: 49.8962 - val_loss: 10.7985 - val_mean_squared_error: 10.7985\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 48.7308 - mean_squared_error: 48.7308 - val_loss: 10.4212 - val_mean_squared_error: 10.4212\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 47.5507 - mean_squared_error: 47.5507 - val_loss: 10.0594 - val_mean_squared_error: 10.0594\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 46.3465 - mean_squared_error: 46.3465 - val_loss: 9.7152 - val_mean_squared_error: 9.7152\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 45.1179 - mean_squared_error: 45.1179 - val_loss: 9.3997 - val_mean_squared_error: 9.3997\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 43.8748 - mean_squared_error: 43.8748 - val_loss: 9.1066 - val_mean_squared_error: 9.1066\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 42.6201 - mean_squared_error: 42.6201 - val_loss: 8.8375 - val_mean_squared_error: 8.8375\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 41.3559 - mean_squared_error: 41.3559 - val_loss: 8.5904 - val_mean_squared_error: 8.5904\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 40.0830 - mean_squared_error: 40.0830 - val_loss: 8.3678 - val_mean_squared_error: 8.3678\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 38.8036 - mean_squared_error: 38.8036 - val_loss: 8.1868 - val_mean_squared_error: 8.1868\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 37.5200 - mean_squared_error: 37.5200 - val_loss: 8.0442 - val_mean_squared_error: 8.0442\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 36.2349 - mean_squared_error: 36.2349 - val_loss: 7.9374 - val_mean_squared_error: 7.9374\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 34.9503 - mean_squared_error: 34.9503 - val_loss: 7.8679 - val_mean_squared_error: 7.8679\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 33.6688 - mean_squared_error: 33.6688 - val_loss: 7.8386 - val_mean_squared_error: 7.8386\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 32.3822 - mean_squared_error: 32.3822 - val_loss: 7.8506 - val_mean_squared_error: 7.8506\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 31.0949 - mean_squared_error: 31.0949 - val_loss: 7.9110 - val_mean_squared_error: 7.9110\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 29.8136 - mean_squared_error: 29.8136 - val_loss: 8.0218 - val_mean_squared_error: 8.0218\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 28.5443 - mean_squared_error: 28.5443 - val_loss: 8.1788 - val_mean_squared_error: 8.1788\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 27.2857 - mean_squared_error: 27.2857 - val_loss: 8.3771 - val_mean_squared_error: 8.3771\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 26.0396 - mean_squared_error: 26.0396 - val_loss: 8.6235 - val_mean_squared_error: 8.6235\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 24.8090 - mean_squared_error: 24.8090 - val_loss: 8.9190 - val_mean_squared_error: 8.9190\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 23.5965 - mean_squared_error: 23.5965 - val_loss: 9.2645 - val_mean_squared_error: 9.2645\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 22.4044 - mean_squared_error: 22.4044 - val_loss: 9.6604 - val_mean_squared_error: 9.6604\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21.2317 - mean_squared_error: 21.2317 - val_loss: 10.1070 - val_mean_squared_error: 10.1070\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 20.0826 - mean_squared_error: 20.0826 - val_loss: 10.6042 - val_mean_squared_error: 10.6042\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 18.9612 - mean_squared_error: 18.9612 - val_loss: 11.1511 - val_mean_squared_error: 11.1511\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 17.8679 - mean_squared_error: 17.8679 - val_loss: 11.7471 - val_mean_squared_error: 11.7471\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 16.8012 - mean_squared_error: 16.8012 - val_loss: 12.3912 - val_mean_squared_error: 12.3912\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 15.7685 - mean_squared_error: 15.7685 - val_loss: 13.0817 - val_mean_squared_error: 13.0817\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 14.7713 - mean_squared_error: 14.7713 - val_loss: 13.8164 - val_mean_squared_error: 13.8164\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 13.8118 - mean_squared_error: 13.8118 - val_loss: 14.5928 - val_mean_squared_error: 14.5928\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 12.8922 - mean_squared_error: 12.8922 - val_loss: 15.4080 - val_mean_squared_error: 15.4080\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 12.0141 - mean_squared_error: 12.0141 - val_loss: 16.2681 - val_mean_squared_error: 16.2681\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 11.1789 - mean_squared_error: 11.1789 - val_loss: 17.1617 - val_mean_squared_error: 17.1617\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 10.3878 - mean_squared_error: 10.3878 - val_loss: 18.0838 - val_mean_squared_error: 18.0838\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 9.6413 - mean_squared_error: 9.6413 - val_loss: 19.0294 - val_mean_squared_error: 19.0294\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.9403 - mean_squared_error: 8.9403 - val_loss: 19.9933 - val_mean_squared_error: 19.9933\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 8.2852 - mean_squared_error: 8.2852 - val_loss: 20.9695 - val_mean_squared_error: 20.9695\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 7.6758 - mean_squared_error: 7.6758 - val_loss: 21.9517 - val_mean_squared_error: 21.9517\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.1121 - mean_squared_error: 7.1121 - val_loss: 22.9353 - val_mean_squared_error: 22.9353\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.5934 - mean_squared_error: 6.5934 - val_loss: 23.9122 - val_mean_squared_error: 23.9122\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.1188 - mean_squared_error: 6.1188 - val_loss: 24.8755 - val_mean_squared_error: 24.8755\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 5.6857 - mean_squared_error: 5.6857 - val_loss: 25.8179 - val_mean_squared_error: 25.8179\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 5.2897 - mean_squared_error: 5.2897 - val_loss: 26.7406 - val_mean_squared_error: 26.7406\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4.9197 - mean_squared_error: 4.9197 - val_loss: 27.6379 - val_mean_squared_error: 27.6379\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 4.5848 - mean_squared_error: 4.5848 - val_loss: 28.5013 - val_mean_squared_error: 28.5013\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 4.2852 - mean_squared_error: 4.2852 - val_loss: 29.3207 - val_mean_squared_error: 29.3207\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.0191 - mean_squared_error: 4.0191 - val_loss: 30.0895 - val_mean_squared_error: 30.0895\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7857 - mean_squared_error: 3.7857 - val_loss: 30.8017 - val_mean_squared_error: 30.8017\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.5833 - mean_squared_error: 3.5833 - val_loss: 31.4495 - val_mean_squared_error: 31.4495\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 3.4093 - mean_squared_error: 3.4093 - val_loss: 32.0285 - val_mean_squared_error: 32.0285\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.2605 - mean_squared_error: 3.2605 - val_loss: 32.5377 - val_mean_squared_error: 32.5377\n",
      "Mean Squared Error on test set: 9.28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('cv', axis=1)\n",
    "y = data['cv']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Feedforward Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer + Hidden layer 1\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Hidden layer 2\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# Output layer (no activation for regression)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b747603d-317f-4567-98a8-239d71ad851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer neurons: 8\n",
      "Hidden layer 1 neurons: 64 (800.00% of input neurons)\n",
      "Hidden layer 2 neurons: 32 (400.00% of input neurons)\n",
      "Hidden layer 3 neurons: 16 (200.00% of input neurons)\n",
      "Output layer neurons: 1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 92.2266 - mean_squared_error: 92.2266 - val_loss: 38.9801 - val_mean_squared_error: 38.9801\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 91.4226 - mean_squared_error: 91.4226 - val_loss: 38.4453 - val_mean_squared_error: 38.4453\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 90.7767 - mean_squared_error: 90.7767 - val_loss: 37.9123 - val_mean_squared_error: 37.9123\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 90.2218 - mean_squared_error: 90.2218 - val_loss: 37.4435 - val_mean_squared_error: 37.4435\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 89.7177 - mean_squared_error: 89.7177 - val_loss: 37.0045 - val_mean_squared_error: 37.0045\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 89.2947 - mean_squared_error: 89.2947 - val_loss: 36.6036 - val_mean_squared_error: 36.6036\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 88.8402 - mean_squared_error: 88.8402 - val_loss: 36.2101 - val_mean_squared_error: 36.2101\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 88.3822 - mean_squared_error: 88.3822 - val_loss: 35.8432 - val_mean_squared_error: 35.8432\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 87.9446 - mean_squared_error: 87.9446 - val_loss: 35.4865 - val_mean_squared_error: 35.4865\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 87.5048 - mean_squared_error: 87.5048 - val_loss: 35.1439 - val_mean_squared_error: 35.1439\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 87.0539 - mean_squared_error: 87.0539 - val_loss: 34.8226 - val_mean_squared_error: 34.8226\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 86.6045 - mean_squared_error: 86.6045 - val_loss: 34.5113 - val_mean_squared_error: 34.5113\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 86.1418 - mean_squared_error: 86.1418 - val_loss: 34.1846 - val_mean_squared_error: 34.1846\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 85.6715 - mean_squared_error: 85.6715 - val_loss: 33.8640 - val_mean_squared_error: 33.8640\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 85.1834 - mean_squared_error: 85.1834 - val_loss: 33.5269 - val_mean_squared_error: 33.5269\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 84.6824 - mean_squared_error: 84.6824 - val_loss: 33.1665 - val_mean_squared_error: 33.1665\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 84.1851 - mean_squared_error: 84.1851 - val_loss: 32.8032 - val_mean_squared_error: 32.8032\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 83.6896 - mean_squared_error: 83.6896 - val_loss: 32.4407 - val_mean_squared_error: 32.4407\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 83.2009 - mean_squared_error: 83.2009 - val_loss: 32.0781 - val_mean_squared_error: 32.0781\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 82.7092 - mean_squared_error: 82.7092 - val_loss: 31.7245 - val_mean_squared_error: 31.7245\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 82.2039 - mean_squared_error: 82.2039 - val_loss: 31.3690 - val_mean_squared_error: 31.3690\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 81.6850 - mean_squared_error: 81.6850 - val_loss: 31.0120 - val_mean_squared_error: 31.0120\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 81.1447 - mean_squared_error: 81.1447 - val_loss: 30.6463 - val_mean_squared_error: 30.6463\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 80.5765 - mean_squared_error: 80.5765 - val_loss: 30.2690 - val_mean_squared_error: 30.2690\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 79.9841 - mean_squared_error: 79.9841 - val_loss: 29.8760 - val_mean_squared_error: 29.8760\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 79.3680 - mean_squared_error: 79.3680 - val_loss: 29.4695 - val_mean_squared_error: 29.4695\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 78.7328 - mean_squared_error: 78.7328 - val_loss: 29.0541 - val_mean_squared_error: 29.0541\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 78.0792 - mean_squared_error: 78.0792 - val_loss: 28.6361 - val_mean_squared_error: 28.6361\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 77.4083 - mean_squared_error: 77.4083 - val_loss: 28.2451 - val_mean_squared_error: 28.2451\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 76.7195 - mean_squared_error: 76.7195 - val_loss: 27.8489 - val_mean_squared_error: 27.8489\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 76.0086 - mean_squared_error: 76.0086 - val_loss: 27.4479 - val_mean_squared_error: 27.4479\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 75.2757 - mean_squared_error: 75.2757 - val_loss: 27.0425 - val_mean_squared_error: 27.0425\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 74.5213 - mean_squared_error: 74.5213 - val_loss: 26.6319 - val_mean_squared_error: 26.6319\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 73.7438 - mean_squared_error: 73.7438 - val_loss: 26.2173 - val_mean_squared_error: 26.2173\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 72.9459 - mean_squared_error: 72.9459 - val_loss: 25.7988 - val_mean_squared_error: 25.7988\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 72.1275 - mean_squared_error: 72.1275 - val_loss: 25.3774 - val_mean_squared_error: 25.3774\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 71.2868 - mean_squared_error: 71.2868 - val_loss: 24.9540 - val_mean_squared_error: 24.9540\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 70.4051 - mean_squared_error: 70.4051 - val_loss: 24.5262 - val_mean_squared_error: 24.5262\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 69.4949 - mean_squared_error: 69.4949 - val_loss: 24.0980 - val_mean_squared_error: 24.0980\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 68.5581 - mean_squared_error: 68.5581 - val_loss: 23.6707 - val_mean_squared_error: 23.6707\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 67.5901 - mean_squared_error: 67.5901 - val_loss: 23.2355 - val_mean_squared_error: 23.2355\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 66.5944 - mean_squared_error: 66.5944 - val_loss: 22.7748 - val_mean_squared_error: 22.7748\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 65.5726 - mean_squared_error: 65.5726 - val_loss: 22.3203 - val_mean_squared_error: 22.3203\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 64.5319 - mean_squared_error: 64.5319 - val_loss: 21.8670 - val_mean_squared_error: 21.8670\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 63.4644 - mean_squared_error: 63.4644 - val_loss: 21.4187 - val_mean_squared_error: 21.4187\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 62.3692 - mean_squared_error: 62.3692 - val_loss: 20.9697 - val_mean_squared_error: 20.9697\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 61.2299 - mean_squared_error: 61.2299 - val_loss: 20.5312 - val_mean_squared_error: 20.5312\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 60.0458 - mean_squared_error: 60.0458 - val_loss: 20.1053 - val_mean_squared_error: 20.1053\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 58.8327 - mean_squared_error: 58.8327 - val_loss: 19.6869 - val_mean_squared_error: 19.6869\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 57.5838 - mean_squared_error: 57.5838 - val_loss: 19.2313 - val_mean_squared_error: 19.2313\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 56.3087 - mean_squared_error: 56.3087 - val_loss: 18.7923 - val_mean_squared_error: 18.7923\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 55.0046 - mean_squared_error: 55.0046 - val_loss: 18.3715 - val_mean_squared_error: 18.3715\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 53.6704 - mean_squared_error: 53.6704 - val_loss: 17.9737 - val_mean_squared_error: 17.9737\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 52.3084 - mean_squared_error: 52.3084 - val_loss: 17.6021 - val_mean_squared_error: 17.6021\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 50.9214 - mean_squared_error: 50.9214 - val_loss: 17.2578 - val_mean_squared_error: 17.2578\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 49.5114 - mean_squared_error: 49.5114 - val_loss: 16.9464 - val_mean_squared_error: 16.9464\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 48.0802 - mean_squared_error: 48.0802 - val_loss: 16.6750 - val_mean_squared_error: 16.6750\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 46.6299 - mean_squared_error: 46.6299 - val_loss: 16.4450 - val_mean_squared_error: 16.4450\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 45.1626 - mean_squared_error: 45.1626 - val_loss: 16.2608 - val_mean_squared_error: 16.2608\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 43.6806 - mean_squared_error: 43.6806 - val_loss: 16.1265 - val_mean_squared_error: 16.1265\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 42.1863 - mean_squared_error: 42.1863 - val_loss: 16.0462 - val_mean_squared_error: 16.0462\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 40.6823 - mean_squared_error: 40.6823 - val_loss: 16.0233 - val_mean_squared_error: 16.0233\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 39.1690 - mean_squared_error: 39.1690 - val_loss: 16.0595 - val_mean_squared_error: 16.0595\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 37.6474 - mean_squared_error: 37.6474 - val_loss: 16.1641 - val_mean_squared_error: 16.1641\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 36.1169 - mean_squared_error: 36.1169 - val_loss: 16.3548 - val_mean_squared_error: 16.3548\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 34.5759 - mean_squared_error: 34.5759 - val_loss: 16.6400 - val_mean_squared_error: 16.6400\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 33.0387 - mean_squared_error: 33.0387 - val_loss: 16.9997 - val_mean_squared_error: 16.9997\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 31.4970 - mean_squared_error: 31.4970 - val_loss: 17.4260 - val_mean_squared_error: 17.4260\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 29.9596 - mean_squared_error: 29.9596 - val_loss: 17.9246 - val_mean_squared_error: 17.9246\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 28.4374 - mean_squared_error: 28.4374 - val_loss: 18.5061 - val_mean_squared_error: 18.5061\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 26.9365 - mean_squared_error: 26.9365 - val_loss: 19.1759 - val_mean_squared_error: 19.1759\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 25.4617 - mean_squared_error: 25.4617 - val_loss: 19.9733 - val_mean_squared_error: 19.9733\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 24.0029 - mean_squared_error: 24.0029 - val_loss: 20.9273 - val_mean_squared_error: 20.9273\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 22.5626 - mean_squared_error: 22.5626 - val_loss: 21.9664 - val_mean_squared_error: 21.9664\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21.1535 - mean_squared_error: 21.1535 - val_loss: 23.0879 - val_mean_squared_error: 23.0879\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 19.7825 - mean_squared_error: 19.7825 - val_loss: 24.2660 - val_mean_squared_error: 24.2660\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 18.4528 - mean_squared_error: 18.4528 - val_loss: 25.5128 - val_mean_squared_error: 25.5128\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 17.1788 - mean_squared_error: 17.1788 - val_loss: 26.8181 - val_mean_squared_error: 26.8181\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.9462 - mean_squared_error: 15.9462 - val_loss: 28.1663 - val_mean_squared_error: 28.1663\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 14.7719 - mean_squared_error: 14.7719 - val_loss: 29.5395 - val_mean_squared_error: 29.5395\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 13.6559 - mean_squared_error: 13.6559 - val_loss: 30.9176 - val_mean_squared_error: 30.9176\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 12.6030 - mean_squared_error: 12.6030 - val_loss: 32.2804 - val_mean_squared_error: 32.2804\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 11.6165 - mean_squared_error: 11.6165 - val_loss: 33.6067 - val_mean_squared_error: 33.6067\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 10.6969 - mean_squared_error: 10.6969 - val_loss: 34.8780 - val_mean_squared_error: 34.8780\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 9.8436 - mean_squared_error: 9.8436 - val_loss: 36.0762 - val_mean_squared_error: 36.0762\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 9.0550 - mean_squared_error: 9.0550 - val_loss: 37.1851 - val_mean_squared_error: 37.1851\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.3289 - mean_squared_error: 8.3289 - val_loss: 38.1898 - val_mean_squared_error: 38.1898\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.6666 - mean_squared_error: 7.6666 - val_loss: 39.0777 - val_mean_squared_error: 39.0777\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 7.0651 - mean_squared_error: 7.0651 - val_loss: 39.8388 - val_mean_squared_error: 39.8388\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 6.5224 - mean_squared_error: 6.5224 - val_loss: 40.4653 - val_mean_squared_error: 40.4653\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.0354 - mean_squared_error: 6.0354 - val_loss: 40.9520 - val_mean_squared_error: 40.9520\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.6008 - mean_squared_error: 5.6008 - val_loss: 41.2965 - val_mean_squared_error: 41.2965\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.2149 - mean_squared_error: 5.2149 - val_loss: 41.4986 - val_mean_squared_error: 41.4986\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 4.8741 - mean_squared_error: 4.8741 - val_loss: 41.5601 - val_mean_squared_error: 41.5601\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.5744 - mean_squared_error: 4.5744 - val_loss: 41.4849 - val_mean_squared_error: 41.4849\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 4.3115 - mean_squared_error: 4.3115 - val_loss: 41.2793 - val_mean_squared_error: 41.2793\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 4.0819 - mean_squared_error: 4.0819 - val_loss: 40.9531 - val_mean_squared_error: 40.9531\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.8819 - mean_squared_error: 3.8819 - val_loss: 40.5255 - val_mean_squared_error: 40.5255\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7078 - mean_squared_error: 3.7078 - val_loss: 39.9880 - val_mean_squared_error: 39.9880\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 3.5565 - mean_squared_error: 3.5565 - val_loss: 39.3567 - val_mean_squared_error: 39.3567\n",
      "Mean Squared Error on test set: 12.13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('cv', axis=1)\n",
    "y = data['cv']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Multilayer Perceptron model\n",
    "input_neurons = X_train.shape[1]\n",
    "print(f\"Input layer neurons: {input_neurons}\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer + Hidden layer 1\n",
    "layer1_neurons = 64\n",
    "model.add(Dense(layer1_neurons, input_shape=(input_neurons,), activation='relu'))\n",
    "print(f\"Hidden layer 1 neurons: {layer1_neurons} ({(layer1_neurons / input_neurons) * 100:.2f}% of input neurons)\")\n",
    "\n",
    "# Hidden layer 2\n",
    "layer2_neurons = 32\n",
    "model.add(Dense(layer2_neurons, activation='relu'))\n",
    "print(f\"Hidden layer 2 neurons: {layer2_neurons} ({(layer2_neurons / input_neurons) * 100:.2f}% of input neurons)\")\n",
    "\n",
    "# Hidden layer 3\n",
    "layer3_neurons = 16\n",
    "model.add(Dense(layer3_neurons, activation='relu'))\n",
    "print(f\"Hidden layer 3 neurons: {layer3_neurons} ({(layer3_neurons / input_neurons) * 100:.2f}% of input neurons)\")\n",
    "\n",
    "# Output layer (no activation for regression)\n",
    "output_neurons = 1\n",
    "model.add(Dense(output_neurons))\n",
    "print(f\"Output layer neurons: {output_neurons}\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bb20fb-c92d-4940-927b-f35c797442a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 89.0842 - mean_squared_error: 89.0842 - val_loss: 33.1002 - val_mean_squared_error: 33.1002\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 87.1261 - mean_squared_error: 87.1261 - val_loss: 31.8167 - val_mean_squared_error: 31.8167\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 85.0967 - mean_squared_error: 85.0967 - val_loss: 30.5230 - val_mean_squared_error: 30.5230\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 83.0975 - mean_squared_error: 83.0975 - val_loss: 29.0009 - val_mean_squared_error: 29.0009\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 81.0539 - mean_squared_error: 81.0539 - val_loss: 27.3823 - val_mean_squared_error: 27.3823\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 78.9724 - mean_squared_error: 78.9724 - val_loss: 25.6817 - val_mean_squared_error: 25.6817\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 76.7615 - mean_squared_error: 76.7615 - val_loss: 23.9592 - val_mean_squared_error: 23.9592\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 74.3708 - mean_squared_error: 74.3708 - val_loss: 22.3007 - val_mean_squared_error: 22.3007\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 71.7691 - mean_squared_error: 71.7691 - val_loss: 20.6150 - val_mean_squared_error: 20.6150\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 69.0114 - mean_squared_error: 69.0114 - val_loss: 18.9469 - val_mean_squared_error: 18.9469\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 66.0745 - mean_squared_error: 66.0745 - val_loss: 17.3262 - val_mean_squared_error: 17.3262\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 62.9471 - mean_squared_error: 62.9471 - val_loss: 15.7923 - val_mean_squared_error: 15.7923\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 59.6226 - mean_squared_error: 59.6226 - val_loss: 14.3336 - val_mean_squared_error: 14.3336\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 56.0913 - mean_squared_error: 56.0913 - val_loss: 13.0901 - val_mean_squared_error: 13.0901\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 52.3544 - mean_squared_error: 52.3544 - val_loss: 12.1234 - val_mean_squared_error: 12.1234\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 48.4380 - mean_squared_error: 48.4380 - val_loss: 11.5010 - val_mean_squared_error: 11.5010\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 44.3308 - mean_squared_error: 44.3308 - val_loss: 11.3468 - val_mean_squared_error: 11.3468\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 40.0495 - mean_squared_error: 40.0495 - val_loss: 11.7958 - val_mean_squared_error: 11.7958\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 35.6430 - mean_squared_error: 35.6430 - val_loss: 13.0105 - val_mean_squared_error: 13.0105\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 31.1900 - mean_squared_error: 31.1900 - val_loss: 15.1986 - val_mean_squared_error: 15.1986\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 26.7382 - mean_squared_error: 26.7382 - val_loss: 18.5063 - val_mean_squared_error: 18.5063\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 22.3927 - mean_squared_error: 22.3927 - val_loss: 23.1122 - val_mean_squared_error: 23.1122\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 18.2444 - mean_squared_error: 18.2444 - val_loss: 29.1376 - val_mean_squared_error: 29.1376\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 14.5148 - mean_squared_error: 14.5148 - val_loss: 36.6906 - val_mean_squared_error: 36.6906\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 11.3711 - mean_squared_error: 11.3711 - val_loss: 45.6243 - val_mean_squared_error: 45.6243\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 8.9573 - mean_squared_error: 8.9573 - val_loss: 55.5905 - val_mean_squared_error: 55.5905\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 7.3809 - mean_squared_error: 7.3809 - val_loss: 65.8101 - val_mean_squared_error: 65.8101\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.6696 - mean_squared_error: 6.6696 - val_loss: 75.3017 - val_mean_squared_error: 75.3017\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.7006 - mean_squared_error: 6.7006 - val_loss: 82.7068 - val_mean_squared_error: 82.7068\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 7.1631 - mean_squared_error: 7.1631 - val_loss: 86.9655 - val_mean_squared_error: 86.9655\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 7.6725 - mean_squared_error: 7.6725 - val_loss: 87.5782 - val_mean_squared_error: 87.5782\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.9114 - mean_squared_error: 7.9114 - val_loss: 84.7145 - val_mean_squared_error: 84.7145\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.6910 - mean_squared_error: 7.6910 - val_loss: 79.0028 - val_mean_squared_error: 79.0028\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 7.0259 - mean_squared_error: 7.0259 - val_loss: 71.3960 - val_mean_squared_error: 71.3960\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.0826 - mean_squared_error: 6.0826 - val_loss: 62.9116 - val_mean_squared_error: 62.9116\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.0843 - mean_squared_error: 5.0843 - val_loss: 54.4133 - val_mean_squared_error: 54.4133\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 4.1975 - mean_squared_error: 4.1975 - val_loss: 46.4298 - val_mean_squared_error: 46.4298\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 3.5479 - mean_squared_error: 3.5479 - val_loss: 39.3728 - val_mean_squared_error: 39.3728\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 3.1701 - mean_squared_error: 3.1701 - val_loss: 33.4033 - val_mean_squared_error: 33.4033\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 3.0408 - mean_squared_error: 3.0408 - val_loss: 28.5327 - val_mean_squared_error: 28.5327\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3.1137 - mean_squared_error: 3.1137 - val_loss: 24.6853 - val_mean_squared_error: 24.6853\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.3088 - mean_squared_error: 3.3088 - val_loss: 21.8145 - val_mean_squared_error: 21.8145\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.5351 - mean_squared_error: 3.5351 - val_loss: 19.7676 - val_mean_squared_error: 19.7676\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.7138 - mean_squared_error: 3.7138 - val_loss: 18.4291 - val_mean_squared_error: 18.4291\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7972 - mean_squared_error: 3.7972 - val_loss: 17.6787 - val_mean_squared_error: 17.6787\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7675 - mean_squared_error: 3.7675 - val_loss: 17.4072 - val_mean_squared_error: 17.4072\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.6326 - mean_squared_error: 3.6326 - val_loss: 17.5290 - val_mean_squared_error: 17.5290\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 3.4287 - mean_squared_error: 3.4287 - val_loss: 17.9836 - val_mean_squared_error: 17.9836\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.1799 - mean_squared_error: 3.1799 - val_loss: 18.7268 - val_mean_squared_error: 18.7268\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2.9343 - mean_squared_error: 2.9343 - val_loss: 19.6804 - val_mean_squared_error: 19.6804\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 2.7186 - mean_squared_error: 2.7186 - val_loss: 20.7687 - val_mean_squared_error: 20.7687\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.5480 - mean_squared_error: 2.5480 - val_loss: 21.9081 - val_mean_squared_error: 21.9081\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.4297 - mean_squared_error: 2.4297 - val_loss: 23.0002 - val_mean_squared_error: 23.0002\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.3540 - mean_squared_error: 2.3540 - val_loss: 23.9601 - val_mean_squared_error: 23.9601\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.3080 - mean_squared_error: 2.3080 - val_loss: 24.7190 - val_mean_squared_error: 24.7190\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2729 - mean_squared_error: 2.2729 - val_loss: 25.2168 - val_mean_squared_error: 25.2168\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2299 - mean_squared_error: 2.2299 - val_loss: 25.4459 - val_mean_squared_error: 25.4459\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.1617 - mean_squared_error: 2.1617 - val_loss: 25.4298 - val_mean_squared_error: 25.4298\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.0673 - mean_squared_error: 2.0673 - val_loss: 25.2260 - val_mean_squared_error: 25.2260\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.9576 - mean_squared_error: 1.9576 - val_loss: 24.8895 - val_mean_squared_error: 24.8895\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.8437 - mean_squared_error: 1.8437 - val_loss: 24.4908 - val_mean_squared_error: 24.4908\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.7395 - mean_squared_error: 1.7395 - val_loss: 24.0791 - val_mean_squared_error: 24.0791\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1.6554 - mean_squared_error: 1.6554 - val_loss: 23.6937 - val_mean_squared_error: 23.6937\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.5977 - mean_squared_error: 1.5977 - val_loss: 23.3773 - val_mean_squared_error: 23.3773\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.5618 - mean_squared_error: 1.5618 - val_loss: 23.1562 - val_mean_squared_error: 23.1562\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.5407 - mean_squared_error: 1.5407 - val_loss: 23.0353 - val_mean_squared_error: 23.0353\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.5225 - mean_squared_error: 1.5225 - val_loss: 23.0077 - val_mean_squared_error: 23.0077\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.4977 - mean_squared_error: 1.4977 - val_loss: 23.0559 - val_mean_squared_error: 23.0559\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.4611 - mean_squared_error: 1.4611 - val_loss: 23.1609 - val_mean_squared_error: 23.1609\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.4118 - mean_squared_error: 1.4118 - val_loss: 23.3035 - val_mean_squared_error: 23.3035\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.3530 - mean_squared_error: 1.3530 - val_loss: 23.4604 - val_mean_squared_error: 23.4604\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.2898 - mean_squared_error: 1.2898 - val_loss: 23.6086 - val_mean_squared_error: 23.6086\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 1.2280 - mean_squared_error: 1.2280 - val_loss: 23.7261 - val_mean_squared_error: 23.7261\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.1721 - mean_squared_error: 1.1721 - val_loss: 23.7927 - val_mean_squared_error: 23.7927\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.1235 - mean_squared_error: 1.1235 - val_loss: 23.7934 - val_mean_squared_error: 23.7934\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0813 - mean_squared_error: 1.0813 - val_loss: 23.7201 - val_mean_squared_error: 23.7201\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0422 - mean_squared_error: 1.0422 - val_loss: 23.5732 - val_mean_squared_error: 23.5732\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.0024 - mean_squared_error: 1.0024 - val_loss: 23.3620 - val_mean_squared_error: 23.3620\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.9590 - mean_squared_error: 0.9590 - val_loss: 23.1038 - val_mean_squared_error: 23.1038\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9114 - mean_squared_error: 0.9114 - val_loss: 22.8225 - val_mean_squared_error: 22.8225\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.8606 - mean_squared_error: 0.8606 - val_loss: 22.5439 - val_mean_squared_error: 22.5439\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8094 - mean_squared_error: 0.8094 - val_loss: 22.2927 - val_mean_squared_error: 22.2927\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7607 - mean_squared_error: 0.7607 - val_loss: 22.0894 - val_mean_squared_error: 22.0894\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7164 - mean_squared_error: 0.7164 - val_loss: 21.9493 - val_mean_squared_error: 21.9493\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6771 - mean_squared_error: 0.6771 - val_loss: 21.8797 - val_mean_squared_error: 21.8797\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.6416 - mean_squared_error: 0.6416 - val_loss: 21.8826 - val_mean_squared_error: 21.8826\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6079 - mean_squared_error: 0.6079 - val_loss: 21.9543 - val_mean_squared_error: 21.9543\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5742 - mean_squared_error: 0.5742 - val_loss: 22.0886 - val_mean_squared_error: 22.0886\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5393 - mean_squared_error: 0.5393 - val_loss: 22.2814 - val_mean_squared_error: 22.2814\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5032 - mean_squared_error: 0.5032 - val_loss: 22.5257 - val_mean_squared_error: 22.5257\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4669 - mean_squared_error: 0.4669 - val_loss: 22.8156 - val_mean_squared_error: 22.8156\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4316 - mean_squared_error: 0.4316 - val_loss: 23.1286 - val_mean_squared_error: 23.1286\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3986 - mean_squared_error: 0.3986 - val_loss: 23.4685 - val_mean_squared_error: 23.4685\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3681 - mean_squared_error: 0.3681 - val_loss: 23.8415 - val_mean_squared_error: 23.8415\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3400 - mean_squared_error: 0.3400 - val_loss: 24.2460 - val_mean_squared_error: 24.2460\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3134 - mean_squared_error: 0.3134 - val_loss: 24.6813 - val_mean_squared_error: 24.6813\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2875 - mean_squared_error: 0.2875 - val_loss: 25.1604 - val_mean_squared_error: 25.1604\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2622 - mean_squared_error: 0.2622 - val_loss: 25.6714 - val_mean_squared_error: 25.6714\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2377 - mean_squared_error: 0.2377 - val_loss: 26.2042 - val_mean_squared_error: 26.2042\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2146 - mean_squared_error: 0.2146 - val_loss: 26.6875 - val_mean_squared_error: 26.6875\n",
      "Mean Squared Error on test set: 12.83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.drop('cv', axis=1)  # Features\n",
    "y = data['cv']               # Target variable\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Deep Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "# Add multiple hidden layers to make it deep\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Output layer for regression (1 neuron, no activation)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c81049-b040-4e6a-943d-66deb1020d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10.45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.drop('cv', axis=1)  # Features\n",
    "y = data['cv']               # Target variable\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train a gradient boosting model\n",
    "model = GradientBoostingRegressor(learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2fae30-55e5-4e9b-9d99-0b44f46f1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[-0.14228773  0.23097992  0.18103433 -0.1794548  -0.2291621   0.17873633\n",
      "  -0.0134089   0.00837946  0.26026273 -0.31612873  0.40984845 -0.13697457\n",
      "  -0.00084341 -0.12880862 -0.21547854 -0.37155998]\n",
      " [-0.2273618  -0.44749045 -0.16939104 -0.15489662  0.49923956  0.2774104\n",
      "   0.15419292  0.2422961  -0.15746343  0.41638255  0.16779017 -0.32647264\n",
      "   0.06560421 -0.28800893 -0.41184103 -0.44949746]\n",
      " [-0.37288237 -0.32915163  0.01651227 -0.06445384 -0.30833793  0.15362978\n",
      "   0.47124386 -0.11557508 -0.05737221  0.2217288   0.34901965 -0.16314995\n",
      "  -0.00805211  0.30972135  0.2597803  -0.37829113]\n",
      " [ 0.42146242 -0.13924325  0.32248342 -0.30105853 -0.45820332  0.2677939\n",
      "  -0.27899337  0.28837264 -0.481686    0.06170845 -0.09427822 -0.05464876\n",
      "   0.36891448 -0.36418557 -0.00064945 -0.48920667]\n",
      " [-0.12956476  0.20435119 -0.39946127  0.23367977 -0.31297803  0.04287601\n",
      "   0.01046765  0.3525555   0.39286125 -0.18087852  0.4251238  -0.32807446\n",
      "   0.28970897 -0.3680675  -0.48786616  0.49409306]\n",
      " [-0.11493146 -0.17050385  0.14826238 -0.13007069  0.41311145 -0.12236726\n",
      "   0.4573927  -0.3558483   0.1287669  -0.39864635  0.39293647 -0.00509906\n",
      "   0.14871287  0.12029767 -0.08730364  0.44719374]\n",
      " [-0.20887601  0.2922436  -0.1921525   0.2579683  -0.3782674   0.03256845\n",
      "  -0.13117671  0.06130362  0.40141845  0.42340314  0.37248456  0.46125305\n",
      "   0.0163244   0.27038944 -0.3480549   0.1026206 ]\n",
      " [ 0.26945293  0.08941936  0.4686272  -0.3857689  -0.41085255 -0.48642397\n",
      "   0.38528442 -0.31649888  0.21903813  0.25443304 -0.382586    0.44632328\n",
      "   0.22821689 -0.06730998 -0.23781419 -0.27181995]]\n",
      "Biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Weights:\n",
      "[[-0.14435303  0.32895744 -0.1370889  -0.4996382   0.14483142 -0.34053946\n",
      "  -0.15237808  0.04643703]\n",
      " [ 0.14983213  0.32368279 -0.02762282 -0.11859024  0.0986166  -0.3228097\n",
      "   0.06358981 -0.01138902]\n",
      " [ 0.02437544 -0.22815347 -0.32856035  0.14454293 -0.01583529 -0.4043963\n",
      "  -0.40034962  0.2522843 ]\n",
      " [ 0.4938439   0.34732938 -0.4841615   0.0506022  -0.22821903 -0.34036624\n",
      "   0.00168061  0.44986582]\n",
      " [-0.05742931  0.367239    0.02441788  0.15787649 -0.40687764 -0.30990458\n",
      "   0.00470865  0.44520557]\n",
      " [ 0.48143208  0.16988981  0.4128778  -0.17111027 -0.47754145  0.18410456\n",
      "   0.03580689 -0.33499265]\n",
      " [-0.0975405  -0.19848073  0.49313366  0.08819091 -0.48745513  0.25734854\n",
      "  -0.3094077  -0.42505896]\n",
      " [ 0.06692088 -0.49180222  0.18459964 -0.19830716  0.3434056   0.42977977\n",
      "  -0.26914942  0.37777305]\n",
      " [-0.00609326 -0.11691761  0.23387933  0.32442296  0.26770973 -0.44133437\n",
      "  -0.21890152  0.10401046]\n",
      " [-0.03487992 -0.3687197  -0.11612201 -0.28964686  0.35687053  0.3122897\n",
      "   0.23634815 -0.40962076]\n",
      " [-0.32186127 -0.05738819 -0.12840176 -0.49938118 -0.22743845 -0.4702717\n",
      "   0.38125682 -0.49483228]\n",
      " [ 0.29685056  0.16585541  0.33482265  0.43765974  0.36808646  0.44851148\n",
      "   0.35658205  0.48053896]\n",
      " [-0.22142875 -0.14606762  0.46054137 -0.4361632   0.11302817 -0.34219646\n",
      "  -0.476254    0.11712718]\n",
      " [-0.4978578  -0.4733292   0.39845896  0.0922929  -0.30537724  0.3948568\n",
      "  -0.03031623  0.05161238]\n",
      " [ 0.42714775 -0.26350534 -0.09469175 -0.06010818  0.2770406   0.15147913\n",
      "   0.20950496  0.3081317 ]\n",
      " [-0.1810683  -0.11235964  0.05579674 -0.41674352 -0.27218378  0.05375791\n",
      "   0.04346573 -0.26916707]]\n",
      "Biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Weights:\n",
      "[[ 0.5577158 ]\n",
      " [-0.0812881 ]\n",
      " [-0.7025656 ]\n",
      " [ 0.21640503]\n",
      " [-0.67959595]\n",
      " [ 0.47837198]\n",
      " [-0.11169696]\n",
      " [ 0.09988201]]\n",
      "Biases:\n",
      "[0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Example ANN Model\n",
    "model = Sequential([\n",
    "    Dense(16, input_dim=8, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# After training the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Extract weights and biases\n",
    "for layer in model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Weights:\\n{weights}\\nBiases:\\n{biases}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d8324a-3856-477b-b1ce-3e106554c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your small CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Define how many times you want to repeat the data\n",
    "repeats = 10  # Adjust the number of repetitions\n",
    "\n",
    "# Repeat the dataset\n",
    "df_expanded = pd.concat([df] * repeats, ignore_index=True)\n",
    "\n",
    "# Save the new larger CSV\n",
    "df_expanded.to_csv(\"large_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257ee210-6105-4ed3-8845-14be7a810e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "def perturb_data(df, noise_level=0.1):\n",
    "    df_perturbed = df.copy()\n",
    "    for column in df.select_dtypes(include=np.number).columns:\n",
    "        noise = np.random.normal(0, noise_level, df[column].shape)\n",
    "        df_perturbed[column] = df[column] + noise\n",
    "    return df_perturbed\n",
    "additional_rows = 1000 \n",
    "expanded_df = df.copy()\n",
    "for _ in range(additional_rows // len(df)): \n",
    "    perturbed_df = perturb_data(df)\n",
    "    expanded_df = pd.concat([expanded_df, perturbed_df], ignore_index=True)\n",
    "expanded_df.to_csv(\"large_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d7f211-cd76-4038-be3f-881107119348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6.02972719401873\n",
      "R²: 0.8711413805992194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAHHCAYAAABqVYatAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9vElEQVR4nO3deVyU5f7/8feAgIACoiJi5r7mmiaZa0miWbl0Mpe+amodE/O4RGWLilaYno52srTyqJVaVsc2t8QUrTQz0yxLckHNhSzLlZTt+v3RjzmNoAJyOcz0ej4e85C57mvu+XzmHoa399xzj8MYYwQAAABrfNxdAAAAgLcjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABQCHNnz9fDodD+/btc3cpADwEgQvAJeUGjPwujzzyiJX73LBhgyZOnKjjx49bWf9fWXp6uiZOnKjk5GR3lwL8ZZRydwEAPMekSZNUo0YNl7FGjRpZua8NGzYoISFBgwYNUlhYmJX7KKr/+7//U58+fRQQEODuUookPT1dCQkJkqSOHTu6txjgL4LABaDAunbtqpYtW7q7jMty5swZBQcHX9Y6fH195evrW0wVXTk5OTnKyMhwdxnAXxJvKQIoNitWrFC7du0UHByssmXLqlu3btqxY4fLnO3bt2vQoEGqWbOmSpcurcjISA0ePFjHjh1zzpk4caLi4+MlSTVq1HC+fblv3z7t27dPDodD8+fPz3P/DodDEydOdFmPw+HQd999p379+qlcuXJq27atc/mCBQvUokULBQYGKjw8XH369NGPP/54yT7zO4arevXquvXWW5WcnKyWLVsqMDBQjRs3dr5tt2TJEjVu3FilS5dWixYttHXrVpd1Dho0SGXKlNHevXsVGxur4OBgRUVFadKkSTLGuMw9c+aMxo4dq6pVqyogIED16tXTP//5zzzzHA6HRowYoYULF+qaa65RQECAZs+erYoVK0qSEhISnI9t7uNWkO3z58d29+7dzr2QoaGhuueee5Senp7nMVuwYIFatWqloKAglStXTu3bt9eqVatc5hTk+QN4KvZwASiwEydO6JdffnEZq1ChgiTp9ddf18CBAxUbG6tnnnlG6enpmjVrltq2bautW7eqevXqkqSkpCTt3btX99xzjyIjI7Vjxw69/PLL2rFjhz7//HM5HA716tVLP/zwg9544w1Nnz7deR8VK1bUzz//XOi677zzTtWpU0dPP/20M5Q89dRTeuKJJ9S7d28NHTpUP//8s55//nm1b99eW7duLdLbmLt371a/fv3097//XXfffbf++c9/6rbbbtPs2bP16KOPavjw4ZKkxMRE9e7dWykpKfLx+d//e7Ozs9WlSxddf/31mjp1qlauXKkJEyYoKytLkyZNkiQZY3T77bdr7dq1GjJkiJo1a6aPPvpI8fHxOnTokKZPn+5S05o1a/TWW29pxIgRqlChgpo2bapZs2bp/vvvV8+ePdWrVy9JUpMmTSQVbPv8We/evVWjRg0lJibqq6++0pw5cxQREaFnnnnGOSchIUETJ07UDTfcoEmTJsnf31+bNm3SmjVr1LlzZ0kFf/4AHssAwCXMmzfPSMr3Yowxp06dMmFhYebee+91uV1aWpoJDQ11GU9PT8+z/jfeeMNIMuvXr3eOTZs2zUgyqampLnNTU1ONJDNv3rw865FkJkyY4Lw+YcIEI8n07dvXZd6+ffuMr6+veeqpp1zGv/nmG1OqVKk84xd6PP5cW7Vq1Ywks2HDBufYRx99ZCSZwMBAs3//fuf4Sy+9ZCSZtWvXOscGDhxoJJkHHnjAOZaTk2O6detm/P39zc8//2yMMea9994zksyTTz7pUtPf/vY343A4zO7du10eDx8fH7Njxw6XuT///HOexypXQbdP7mM7ePBgl7k9e/Y05cuXd17ftWuX8fHxMT179jTZ2dkuc3NycowxhXv+AJ6KtxQBFNgLL7ygpKQkl4v0x16R48ePq2/fvvrll1+cF19fX0VHR2vt2rXOdQQGBjp/Pnv2rH755Rddf/31kqSvvvrKSt3Dhg1zub5kyRLl5OSod+/eLvVGRkaqTp06LvUWRsOGDdW6dWvn9ejoaEnSTTfdpKuvvjrP+N69e/OsY8SIEc6fc98SzMjI0OrVqyVJy5cvl6+vr0aOHOlyu7Fjx8oYoxUrVriMd+jQQQ0bNixwD4XdPuc/tu3atdOxY8d08uRJSdJ7772nnJwcjR8/3mVvXm5/UuGeP4Cn4i1FAAXWqlWrfA+a37Vrl6Q/gkV+QkJCnD//+uuvSkhI0JtvvqmjR4+6zDtx4kQxVvs/53+ycteuXTLGqE6dOvnO9/PzK9L9/DlUSVJoaKgkqWrVqvmO//bbby7jPj4+qlmzpstY3bp1Jcl5vNj+/fsVFRWlsmXLusxr0KCBc/mfnd/7pRR2+5zfc7ly5ST90VtISIj27NkjHx+fi4a+wjx/AE9F4AJw2XJyciT9cRxOZGRknuWlSv3vpaZ3797asGGD4uPj1axZM5UpU0Y5OTnq0qWLcz0Xc/4xRLmys7MveJs/77XJrdfhcGjFihX5ftqwTJkyl6wjPxf65OKFxs15B7nbcH7vl1LY7VMcvRXm+QN4Kp7FAC5brVq1JEkRERGKiYm54LzffvtNH3/8sRISEjR+/HjneO4ejj+7ULDK3YNy/glRz9+zc6l6jTGqUaOGcw9SSZCTk6O9e/e61PTDDz9IkvOg8WrVqmn16tU6deqUy16unTt3OpdfyoUe28Jsn4KqVauWcnJy9N1336lZs2YXnCNd+vkDeDKO4QJw2WJjYxUSEqKnn35amZmZeZbnfrIwd2/I+Xs/ZsyYkec2uefKOj9YhYSEqEKFClq/fr3L+Isvvljgenv16iVfX18lJCTkqcUYk+cUCFfSzJkzXWqZOXOm/Pz81KlTJ0nSLbfcouzsbJd5kjR9+nQ5HA517dr1kvcRFBQkKe9jW5jtU1A9evSQj4+PJk2alGcPWe79FPT5A3gy9nABuGwhISGaNWuW/u///k/XXnut+vTpo4oVK+rAgQNatmyZ2rRpo5kzZyokJETt27fX1KlTlZmZqSpVqmjVqlVKTU3Ns84WLVpIkh577DH16dNHfn5+uu222xQcHKyhQ4dqypQpGjp0qFq2bKn169c79wQVRK1atfTkk09q3Lhx2rdvn3r06KGyZcsqNTVV7777ru677z49+OCDxfb4FFTp0qW1cuVKDRw4UNHR0VqxYoWWLVumRx991HnurNtuu0033nijHnvsMe3bt09NmzbVqlWr9P7772vUqFHOvUUXExgYqIYNG2rx4sWqW7euwsPD1ahRIzVq1KjA26egateurccee0yTJ09Wu3bt1KtXLwUEBGjz5s2KiopSYmJigZ8/gEdz06cjAXiQ3NMgbN68+aLz1q5da2JjY01oaKgpXbq0qVWrlhk0aJD58ssvnXMOHjxoevbsacLCwkxoaKi58847zeHDh/M9TcHkyZNNlSpVjI+Pj8tpGNLT082QIUNMaGioKVu2rOndu7c5evToBU8LkXtKhfP997//NW3btjXBwcEmODjY1K9f38TFxZmUlJQCPR7nnxaiW7dueeZKMnFxcS5juae2mDZtmnNs4MCBJjg42OzZs8d07tzZBAUFmUqVKpkJEybkOZ3CqVOnzOjRo01UVJTx8/MzderUMdOmTXOeZuFi951rw4YNpkWLFsbf39/lcSvo9rnQY5vfY2OMMXPnzjXNmzc3AQEBply5cqZDhw4mKSnJZU5Bnj+Ap3IYcwWO2gQAXNSgQYP0zjvv6PTp0+4uBYAFHMMFAABgGYELAADAMgIXAACAZRzDBQAAYBl7uAAAACwjcAEAAFjGiU9LgJycHB0+fFhly5a94FduAACAksUYo1OnTikqKko+Phffh0XgKgEOHz6sqlWrursMAABQBD/++KOuuuqqi84hcJUAuV9Am5qaqvDwcDdXY0dmZqZWrVqlzp07y8/Pz93lFDv683ze3qO39yd5f4/0V/KcPHlSVatWdfki+QshcJUAuW8jli1bViEhIW6uxo7MzEwFBQUpJCTEY36RCoP+PJ+39+jt/Une3yP9lVwFORyIg+YBAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlpVydwH4n+jEj5VVKtjdZVgR4Gs0tZXUaOJHOpftcHc5xY7+PJ+39+jt/Une3+NfpT9vxR4uAAAAywhcAAAAlhG4AAAALCNwAQCAEikxMVHXXXedypYtq4iICPXo0UMpKSkuc86ePau4uDiVL19eZcqU0R133KGffvrJZc6BAwfUrVs3BQUFKSIiQvHx8crKyrroff/666/q37+/QkJCFBYWpiFDhuj06dNF7sWtgWvQoEFyOBxyOBzy9/dX7dq1NWnSpEs+CAAAwPutW7dOcXFx+vzzz5WUlKTMzEx17txZZ86ccc4ZPXq0PvzwQ7399ttat26dDh8+rF69ejmXZ2dnq1u3bsrIyNCGDRv06quvav78+Ro/fvxF77t///7asWOHkpKStHTpUq1fv1733XdfkXtx+6cUu3Tponnz5uncuXNavny54uLi5Ofnp3HjxrnMy8jIkL+/v5uqzF9JrAkAAG+xcuVKl+vz589XRESEtmzZovbt2+vEiRP6z3/+o0WLFummm26SJM2bN08NGjTQ559/ruuvv16rVq3Sd999p9WrV6tSpUpq1qyZJk+erIcfflgTJ07M9+/4999/r5UrV2rz5s1q2bKlJOn555/XLbfcon/+85+KiooqdC9uf0sxICBAkZGRqlatmu6//37FxMTogw8+0KBBg9SjRw899dRTioqKUr169SRJP/74o3r37q2wsDCFh4ere/fu2rdvn3N9ycnJatWqlYKDgxUWFqY2bdpo//79kqSvv/5aN954o8qWLauQkBC1aNFCX375pSRp4sSJatasmUttM2bMUPXq1Z3Xi1oTAAC4fCdOnJAkhYeHS5K2bNmizMxMxcTEOOfUr19fV199tTZu3ChJ2rhxoxo3bqxKlSo558TGxurkyZPasWNHvvezceNGhYWFOcOWJMXExMjHx0ebNm0qUu1uD1znCwwMVEZGhiTp448/VkpKinN3XmZmpmJjY1W2bFl98skn+uyzz1SmTBl16dJFGRkZysrKUo8ePdShQwdt375dGzdu1H333SeH44/zlfTv319XXXWVNm/erC1btuiRRx6Rn59foeorbE0AAODy5eTkaNSoUWrTpo0aNWokSUpLS5O/v7/CwsJc5laqVElpaWnOOX8OW7nLc5flJy0tTRERES5jpUqVUnh4+AVvcyluf0sxlzFGH3/8sT766CM98MAD+vnnnxUcHKw5c+Y4d/ctWLBAOTk5mjNnjjNEzZs3T2FhYUpOTlbLli114sQJ3XrrrapVq5YkqUGDBs77OHDggOLj41W/fn1JUp06dQpdZ2Fr6ty5c551nDt3TufOnXNeP3nypCQpwMfI19cUuiZPEOBjXP71NvTn+by9R2/vT/L+Hv8q/WVmZua7fMSIEfr222+1du1a55zcY77Pv40xRtnZ2crMzFROTo6MMS5z/nz7/O4vOzs7z23+vCx3/EK15sftgWvp0qUqU6aM80Hp16+fJk6cqLi4ODVu3NjlvdWvv/5au3fvVtmyZV3WcfbsWe3Zs0edO3fWoEGDFBsbq5tvvlkxMTHq3bu3KleuLEkaM2aMhg4dqtdff10xMTG68847ncGsoApbU34SExOVkJCQZ/zx5jkKCsouVD2eZnLLHHeXYBX9eT5v79Hb+5O8v0dv7y8pKSnP2Msvv6xNmzbp6aef1vbt27V9+3ZJ0v79+5WRkaG33npLZcqUcc7fv3+/fvvtNy1fvlynTp3Srl27tHz5cufy3E8x7t6922U819GjR3X48GGXZdnZ2Tp27JgOHTrkHE9PTy9wX24PXDfeeKNmzZolf39/RUVFqVSp/5UUHOz6NTenT59WixYttHDhwjzrqVixoqQ/9i6NHDlSK1eu1OLFi/X4448rKSlJ119/vSZOnKh+/fpp2bJlWrFihSZMmKA333xTPXv2lI+Pj4xx/V9Dfsm1KDWdb9y4cRozZozz+smTJ1W1alU9udVHWX6++d7G0wX4GE1umaMnvvTRuRwv/EoK+vN43t6jt/cneX+Pf5X+br75ZufhPsYYjRo1Stu2bdP69evzvDPVpk0bTZ48WaVKldItt9wiSUpJSdHPP/+se+65R9HR0fLx8dE777yjli1bOt8mnDNnjkJCQnTvvfcqICAgTy01atTQzJkzFRkZqWuvvVbSH0HQGKNhw4Y5D5rPfYeqINweuIKDg1W7du0Czb322mu1ePFiRUREKCQk5ILzmjdvrubNm2vcuHFq3bq1Fi1apOuvv16SVLduXdWtW1ejR49W3759NW/ePPXs2VMVK1ZUWlqajDHOtwa3bdtWbDX9WUBAQL4b+FyOQ1le+P1Yf3Yux+GV3wGWi/48n7f36O39Sd7fo7f35+fn5wxcw4cP16JFi/T+++8rPDxcx44dkySFhoYqMDBQFSpU0JAhQ/TQQw85/w4/8MADat26tdq2bStJuuWWW9SwYUMNHjxYU6dOVVpamiZMmKC4uDjnXrEvvvhCAwYM0Mcff6wqVaqoSZMm6tKli+6//37Nnj1bmZmZGjVqlPr06aNq1aq51FpQJe6g+Yvp37+/KlSooO7du+uTTz5RamqqkpOTNXLkSB08eFCpqakaN26cNm7cqP3792vVqlXatWuXGjRooN9//10jRoxQcnKy9u/fr88++0ybN292HuPVsWNH/fzzz5o6dar27NmjF154QStWrLjsmgAAQNHMmjVLJ06cUMeOHVW5cmXnZfHixc4506dP16233qo77rhD7du3V2RkpJYsWeJc7uvrq6VLl8rX11etW7fW3XffrQEDBmjSpEnOOenp6UpJSXF5Z2vhwoWqX7++OnXqpFtuuUVt27bVyy+/XORe3L6HqzCCgoK0fv16Pfzww+rVq5dOnTqlKlWqqFOnTgoJCdHvv/+unTt36tVXX9WxY8dUuXJlxcXF6e9//7uysrJ07NgxDRgwQD/99JMqVKigXr16OY+latCggV588UU9/fTTmjx5su644w49+OCDl3xwL1UTAAAomvMP9clP6dKl9cILL+iFF1644Jxq1arle6xWro4dO+a5r/DwcC1atKjgxV6CWwPX/PnzC70sMjJSr776ar7LQkJC9O677+a7zN/fX2+88cZF6xk2bJiGDRvmMvboo49eVk0AAAAe9ZYiAACAJyJwAQAAWEbgAgAAsMyjDpr3dpvGdVL58uXdXYYVmZmZWr58ub6dGFvor1PyBPTn+by9R2/vT/L+Hv8q/Xkr9nABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhVb4Dp+/HhxrQoAAMCrFClwPfPMM1q8eLHzeu/evVW+fHlVqVJFX3/9dbEVBwAA4A2KFLhmz56tqlWrSpKSkpKUlJSkFStWqGvXroqPjy/WAgEAADxdqaLcKC0tzRm4li5dqt69e6tz586qXr26oqOji7VAAAAAT1ekPVzlypXTjz/+KElauXKlYmJiJEnGGGVnZxdfdQAAAF6gSHu4evXqpX79+qlOnTo6duyYunbtKknaunWrateuXawFAgAAeLoiBa7p06erevXq+vHHHzV16lSVKVNGknTkyBENHz68WAsEAADwdEUKXH5+fnrwwQfzjI8ePfqyCwIAAPA2RT4P1+uvv662bdsqKipK+/fvlyTNmDFD77//frEVBwAA4A2KFLhmzZqlMWPGqGvXrjp+/LjzQPmwsDDNmDGjOOsDAADweEUKXM8//7xeeeUVPfbYY/L19XWOt2zZUt98802xFQcAAOANihS4UlNT1bx58zzjAQEBOnPmzGUXBQAA4E2KFLhq1Kihbdu25RlfuXKlGjRocLk1AQAAeJUifUpxzJgxiouL09mzZ2WM0RdffKE33nhDiYmJmjNnTnHXCAAA4NGKFLiGDh2qwMBAPf7440pPT1e/fv0UFRWl5557Tn369CnuGgEAADxaoQNXVlaWFi1apNjYWPXv31/p6ek6ffq0IiIibNQHAADg8Qp9DFepUqU0bNgwnT17VpIUFBRE2AIAALiIIh0036pVK23durW4awEAAPBKRTqGa/jw4Ro7dqwOHjyoFi1aKDg42GV5kyZNiqW4v5roxI+VVSr40hM9UICv0dRWUqOJH+lctsPd5RQ7+iv59k3p5u4SAPyFFSlw5R4YP3LkSOeYw+GQMUYOh8N55nkAAAAUMXClpqYWdx0AAABeq0jHcFWrVu2iFwAo6U6dOqVRo0apWrVqCgwMVPv27bVr1y6XOd9//71uv/12hYaGKjg4WNddd50OHDhw0fW+/fbbql+/vkqXLq3GjRtr+fLlNtsA4CGKtIfrtddeu+jyAQMGFKkYALhShg4dqm+//Vavv/66oqKi9Oqrr2rChAn629/+purVq2vPnj1q27athgwZooSEBIWEhGjHjh0qXbr0Bde5YcMG9e3bV4mJibr11lu1aNEi9ejRQ1999ZUaNWp0BbsDUNIUKXD94x//cLmemZmp9PR0+fv7Kygo6C8XuNLS0pSYmKhly5bp4MGDCg0NVe3atXX33Xdr4MCBCgoKcneJAP7k999/13//+1+9//77at++vSRp/PjxWrRokV566SUlJibqscce0y233KKpU6c6b1erVq2Lrve5555Tly5dFB8fL0maPHmykpKSNHPmTM2ePdteQwBKvCK9pfjbb7+5XE6fPq2UlBS1bdtWb7zxRnHXWKLt3btXzZs316pVq/T0009r69at2rhxox566CEtXbpUq1evdneJAM6TlZWl7OzsPHurAgICtGHDBuXk5GjZsmWqW7euYmNjFRERoejoaL333nsXXe/GjRsVExPjMhYbG6uNGzcWdwsAPEyR9nDlp06dOpoyZYruvvtu7dy5s7hWW+INHz5cpUqV0pdffulyeoyaNWuqe/fuMsa4sToA+Slbtqxat26tyZMnq0GDBqpUqZIWLlyolJQUZWVl6ejRozp9+rSmTJmiJ598Us8884xWrlypXr16ae3aterQoUO+601LS1OlSpVcxipVqqS0tLQr0RaAEqzYApf0x1noDx8+XJyrLNGOHTvm3LN1/rnIcjkcec9ZdO7cOZ07d855/eTJk5KkAB8jX1/vDGgBPsblX29DfyVfZmamy/W5c+fqvvvuU5UqVeTr66tmzZqpXbt2SktLc/5+3nbbbRoxYoQk6ZprrtGnn36qF198UTfccMMF7ycrK8vlvnJPk3P+/V9puffv7jps8vYe6a/kKUytRQpcH3zwgct1Y4yOHDmimTNnqk2bNkVZpUfavXu3jDGqV6+ey3iFChWcX30UFxenZ555xmV5YmKiEhIS8qzv8eY5Cgry7nOYTW6Z4+4SrKK/kiu/TwuOHTtWcXFxSk9PV3h4uKZNm6YyZcpo8+bN8vX1la+vr8vt/P39tX379gt+8jA0NFTJyckKCQlxjn322WcKCgoqMZ9WTEpKcncJ1nl7j/RXcqSnpxd4bpECV48ePVyuOxwOVaxYUTfddJOeffbZoqzSq3zxxRfKyclR//79XfZk5Ro3bpzGjBnjvH7y5ElVrVpVT271UZaf75Us9YoJ8DGa3DJHT3zpo3M5nnmm8ouhv5Lv24mxF11+9OhRbd26Vc8884y6d++u6667TpJ0yy23OOfMnTtXTZs2dRn7s44dOyotLc1l+ZQpU3TzzTdf8DZXSmZmppKSknTzzTfLz8/PrbXY4u090l/Jk/sOVUEUKXDl5Hju/3KLU+3ateVwOJSSkuIyXrNmTUlSYGBgvrcLCAhQQEBAnvFzOQ5leejXphTUuRyHx341TEHQX8l1/gv4Rx995NxDvXv3bj344IO66qqrNHjwYPn5+emhhx7SXXfdpY4dO+rGG2/UypUrtWzZMiUnJzvXNWDAAFWpUkWJiYmSpNGjR6tDhw7697//rW7duunNN9/Uli1b9Morr5SYPyB+fn4lphZbvL1H+is5ClNnkT6lOGnSpHx3o/3++++aNGlSUVbpkcqXL6+bb75ZM2fO1JkzZ9xdDoBCOHHihOLi4lS/fn0NGDBAbdq00YQJE5wvoD179tTs2bM1depUNW7cWHPmzNF///tftW3b1rmOAwcO6MiRI87rN9xwgxYtWqSXX35ZTZs21TvvvKP33nuPc3ABKFrgSkhI0OnTp/OMp6en53tskjd78cUXlZWVpZYtW2rx4sX6/vvvlZKSogULFmjnzp3y9fXOtwgBT9e7d2/t2bNH586d05EjR/Tcc8/l+fDL4MGDtWvXLv3+++/atm2bunfv7rI8OTlZ8+fPdxm78847lZKSonPnzunbb791+1uJAEqGIr2lmPsl1ef7+uuvFR4eftlFeZJatWpp69atevrppzVu3DgdPHhQAQEBatiwoR588EENHz7c3SUCAAA3K1TgKleunBwOhxwOh+rWresSurKzs3X69GkNGzas2Iss6SpXrqznn39ezz//vLtLAQAAJVChAteMGTNkjNHgwYOVkJCg0NBQ5zJ/f39Vr15drVu3LvYiAQAAPFmhAtfAgQMlSTVq1NANN9zgMZ8iAAAAcKciHcP156+1OHv2rDIyMlyW//mkfyi4TeM6qXz58u4uw4rMzEwtX75c306M9cqgTn8AgIsp0qcU09PTNWLECEVERCg4OFjlypVzuQAAAOB/ihS44uPjtWbNGs2aNUsBAQGaM2eOEhISFBUVpddee624awQAAPBoRXpL8cMPP9Rrr72mjh076p577lG7du1Uu3ZtVatWTQsXLlT//v2Lu04AAACPVaQ9XL/++qvz62tCQkL066+/SpLatm2r9evXF191AAAAXqBIgatmzZpKTU2VJNWvX19vvfWWpD/2fIWFhRVbcQAAAN6gSIHrnnvu0ddffy1JeuSRR/TCCy+odOnSGj16tOLj44u1QAAAAE9XpGO4Ro8e7fw5JiZGO3fu1JYtW1S7dm01adKk2IoDAADwBkUKXH929uxZVatWTdWqVSuOegAAALxOkd5SzM7O1uTJk1WlShWVKVNGe/fulSQ98cQT+s9//lOsBQIAAHi6IgWup556SvPnz9fUqVPl7+/vHG/UqJHmzJlTbMUBAAB4gyIFrtdee00vv/yy+vfvL19fX+d406ZNtXPnzmIrDgAAwBsUKXAdOnRItWvXzjOek5OjzMzMyy4KAADAmxQpcDVs2FCffPJJnvF33nlHzZs3v+yiAAAAvEmRPqU4fvx4DRw4UIcOHVJOTo6WLFmilJQUvfbaa1q6dGlx1wgAAODRCrWHa+/evTLGqHv37vrwww+1evVqBQcHa/z48fr+++/14Ycf6uabb7ZVKwAAgEcq1B6uOnXq6MiRI4qIiFC7du0UHh6ub775RpUqVbJVHwAAgMcr1B4uY4zL9RUrVujMmTPFWhAAAIC3KdJB87nOD2AAAADIq1CBy+FwyOFw5BkDAADAhRXqGC5jjAYNGqSAgABJf3yP4rBhwxQcHOwyb8mSJcVXIQAAgIcrVOAaOHCgy/W77767WIsBAADwRoUKXPPmzbNVBwAAgNe6rIPmAQAAcGkELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJaVcncB+J/oxI+VVSrY3WVYEeBrNLWV1GjiRzqX7XB3OcXur9IfAKBo2MMFAABgGYELAADAMgIXAACAZQQuAEVSvXp1ORyOPJe4uDhJUseOHfMsGzZs2EXXaYzR+PHjVblyZQUGBiomJka7du26Eu0AgFUErmKQnJwsh8Oh48ePu7sU4IrZvHmzjhw54rwkJSVJku68807nnHvvvddlztSpUy+6zqlTp+rf//63Zs+erU2bNik4OFixsbE6e/as1V4AwDY+pQigSCpWrOhyfcqUKapVq5Y6dOjgHAsKClJkZGSB1meM0YwZM/T444+re/fukqTXXntNlSpV0nvvvac+ffoUX/EAcIWxh+sCli5dqrCwMGVnZ0uStm3bJofDoUceecQ5Z+jQobr77rvdVSJQYmRkZGjBggUaPHiwHI7/nRZj4cKFqlChgho1aqRx48YpPT39gutITU1VWlqaYmJinGOhoaGKjo7Wxo0brdYPALaxh+sC2rVrp1OnTmnr1q1q2bKl1q1bpwoVKig5Odk5Z926dXr44YcLve5z587p3LlzzusnT56UJAX4GPn6msuuvSQK8DEu/3qbv0p/mZmZ+S5/5513dPz4cfXv398556677tLVV1+typUr65tvvtFjjz2m77//Xm+//Xa+6zh48KAkKTw83OV+KlasqMOHD1/wvotL7vpt34+7eHt/kvf3SH8lT2FqdRhjvPMvRDFo0aKF+vbtqwcffFA9e/bUddddp4SEBB07dkwnTpzQVVddpR9++EGHDh3SjTfeqN9++01hYWGXXO/EiROVkJCQZ3zRokUKCgqy0Alg18SJE1WqVCk9/vjjF5yzfft2jR8/XrNmzVLlypXzLN+5c6ceeeQRzZ07V+Hh4c7xqVOnyuFwKD4+3krtAFBU6enp6tevn06cOKGQkJCLziVwXcSYMWP0ww8/6MMPP1TFihX16aefqk+fPpoyZYp+/fVXxcfH69ChQ0pOTi5U4MpvD1fVqlXVMP5NZfl56ZnmfYwmt8zRE1/66FyOF56J/S/S38033yw/Pz+XZfv371e9evX01ltv6fbbb7/gOs6cOaNy5cpp6dKl6ty5c57le/fuVf369fXFF1+oWbNmzvFOnTqpadOm+te//lVs/eQnMzNTSUlJ+fboDby9P8n7e6S/kufkyZOqUKFCgQIXbyleRMeOHTV37lx9/fXX8vPzU/369dWxY0clJyfrt99+czk4uDACAgIUEBCQZ/xcjkNZXvi1MH92LsfhlV99k8vb+/Pz88vzQrhgwQJFRESoe/fuKlXqwi8pO3bskCRVrVo13xfTunXrKjIyUuvXr9d1110n6Y8Xsy+++ELDhw+/Yi/A+fXoTby9P8n7e6S/kqMwdXLQ/EXkHsc1ffp0Z7jKDVzJycnq2LGjewsE3CwnJ0fz5s3TwIEDXcLWnj17NHnyZG3ZskX79u3TBx98oAEDBqh9+/Zq0qSJc179+vX17rvvSpIcDodGjRqlJ598Uh988IG++eYbDRgwQFFRUerRo8eVbg0AihV7uC6iXLlyatKkiRYuXKiZM2dKktq3b6/evXsrMzMzzx6ub775RmXLlnVedzgcatq06RWtGbiSVq9erQMHDmjw4MEu4/7+/lq9erVmzJihM2fOqGrVqrrjjjvyHOOVkpKiEydOOK8/9NBDOnPmjO677z4dP35cbdu21cqVK1W6dOkr0g8A2ELguoQOHTpo27Ztzr1Z4eHhatiwoX766SfVq1fPZW779u1drvv6+iorK+tKlQpccZ07d1Z+h4FWrVpV69atu+Ttz7+tw+HQpEmTNGnSpGKrEQBKAt5SvIQZM2bIGKP69es7x7Zt26YjR444r3fs2FHGmDwXwhYAAJAIXAAAANYRuAAAACwjcAEAAFjGQfMlyKZxnVS+fHl3l2FFZmamli9frm8nxnrM+VUK46/SHwCgaNjDBQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AAADLCFwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsIzABQAAYBmBCwAAwDICFwAAgGUELgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGBZKXcXAMkYI0k6deqU/Pz83FyNHZmZmUpPT9fJkye9skf683ze3qO39yd5f4/0V/KcPHlS0v/+jl8MgasEOHbsmCSpRo0abq4EAAAU1qlTpxQaGnrROQSuEiA8PFySdODAgUtuME918uRJVa1aVT/++KNCQkLcXU6xoz/P5+09ent/kvf3SH8ljzFGp06dUlRU1CXnErhKAB+fPw6lCw0N9ZgnWVGFhIR4dY/05/m8vUdv70/y/h7pr2Qp6I4SDpoHAACwjMAFAABgGYGrBAgICNCECRMUEBDg7lKs8fYe6c/zeXuP3t6f5P090p9nc5iCfJYRAAAARcYeLgAAAMsIXAAAAJYRuAAAACwjcAEAAFhG4CoBXnjhBVWvXl2lS5dWdHS0vvjiC3eXVCSJiYm67rrrVLZsWUVERKhHjx5KSUlxmdOxY0c5HA6Xy7Bhw9xUceFMnDgxT+3169d3Lj979qzi4uJUvnx5lSlTRnfccYd++uknN1ZceNWrV8/To8PhUFxcnCTP237r16/XbbfdpqioKDkcDr333nsuy40xGj9+vCpXrqzAwEDFxMRo165dLnN+/fVX9e/fXyEhIQoLC9OQIUN0+vTpK9jFxV2sx8zMTD388MNq3LixgoODFRUVpQEDBujw4cMu68hvu0+ZMuUKd5K/S23DQYMG5am9S5cuLnNK8ja8VH/5/T46HA5NmzbNOackb7+C/F0oyGvngQMH1K1bNwUFBSkiIkLx8fHKysq6kq1cNgKXmy1evFhjxozRhAkT9NVXX6lp06aKjY3V0aNH3V1aoa1bt05xcXH6/PPPlZSUpMzMTHXu3FlnzpxxmXfvvffqyJEjzsvUqVPdVHHhXXPNNS61f/rpp85lo0eP1ocffqi3335b69at0+HDh9WrVy83Vlt4mzdvdukvKSlJknTnnXc653jS9jtz5oyaNm2qF154Id/lU6dO1b///W/Nnj1bmzZtUnBwsGJjY3X27FnnnP79+2vHjh1KSkrS0qVLtX79et13331XqoVLuliP6enp+uqrr/TEE0/oq6++0pIlS5SSkqLbb789z9xJkya5bNcHHnjgSpR/SZfahpLUpUsXl9rfeOMNl+UleRteqr8/93XkyBHNnTtXDodDd9xxh8u8krr9CvJ34VKvndnZ2erWrZsyMjK0YcMGvfrqq5o/f77Gjx/vjpaKzsCtWrVqZeLi4pzXs7OzTVRUlElMTHRjVcXj6NGjRpJZt26dc6xDhw7mH//4h/uKugwTJkwwTZs2zXfZ8ePHjZ+fn3n77bedY99//72RZDZu3HiFKix+//jHP0ytWrVMTk6OMcazt58k8+677zqv5+TkmMjISDNt2jTn2PHjx01AQIB54403jDHGfPfdd0aS2bx5s3POihUrjMPhMIcOHbpitRfU+T3m54svvjCSzP79+51j1apVM9OnT7dbXDHIr7+BAwea7t27X/A2nrQNC7L9unfvbm666SaXMU/Zfsbk/btQkNfO5cuXGx8fH5OWluacM2vWLBMSEmLOnTt3ZRu4DOzhcqOMjAxt2bJFMTExzjEfHx/FxMRo48aNbqyseJw4cULS/76cO9fChQtVoUIFNWrUSOPGjVN6ero7yiuSXbt2KSoqSjVr1lT//v114MABSdKWLVuUmZnpsi3r16+vq6++2mO3ZUZGhhYsWKDBgwfL4XA4xz15+/1Zamqq0tLSXLZZaGiooqOjndts48aNCgsLU8uWLZ1zYmJi5OPjo02bNl3xmovDiRMn5HA4FBYW5jI+ZcoUlS9fXs2bN9e0adM86u2a5ORkRUREqF69err//vt17Ngx5zJv2oY//fSTli1bpiFDhuRZ5inb7/y/CwV57dy4caMaN26sSpUqOefExsbq5MmT2rFjxxWs/vLw5dVu9Msvvyg7O9vlSSRJlSpV0s6dO91UVfHIycnRqFGj1KZNGzVq1Mg53q9fP1WrVk1RUVHavn27Hn74YaWkpGjJkiVurLZgoqOjNX/+fNWrV09HjhxRQkKC2rVrp2+//VZpaWny9/fP80esUqVKSktLc0/Bl+m9997T8ePHNWjQIOeYJ2+/8+Vul/x+/3KXpaWlKSIiwmV5qVKlFB4e7pHb9ezZs3r44YfVt29fly8HHjlypK699lqFh4drw4YNGjdunI4cOaJ//etfbqy2YLp06aJevXqpRo0a2rNnjx599FF17dpVGzdulK+vr1dtw1dffVVly5bNc6iCp2y//P4uFOS1My0tLd/f09xlnoLABSvi4uL07bffuhzjJMnluInGjRurcuXK6tSpk/bs2aNatWpd6TILpWvXrs6fmzRpoujoaFWrVk1vvfWWAgMD3ViZHf/5z3/UtWtXRUVFOcc8efv91WVmZqp3794yxmjWrFkuy8aMGeP8uUmTJvL399ff//53JSYmlvivWenTp4/z58aNG6tJkyaqVauWkpOT1alTJzdWVvzmzp2r/v37q3Tp0i7jnrL9LvR34a+CtxTdqEKFCvL19c3zaYyffvpJkZGRbqrq8o0YMUJLly7V2rVrddVVV110bnR0tCRp9+7dV6K0YhUWFqa6detq9+7dioyMVEZGho4fP+4yx1O35f79+7V69WoNHTr0ovM8efvlbpeL/f5FRkbm+QBLVlaWfv31V4/arrlha//+/UpKSnLZu5Wf6OhoZWVlad++fVemwGJUs2ZNVahQwfmc9JZt+MknnyglJeWSv5NSydx+F/q7UJDXzsjIyHx/T3OXeQoClxv5+/urRYsW+vjjj51jOTk5+vjjj9W6dWs3VlY0xhiNGDFC7777rtasWaMaNWpc8jbbtm2TJFWuXNlydcXv9OnT2rNnjypXrqwWLVrIz8/PZVumpKTowIEDHrkt582bp4iICHXr1u2i8zx5+9WoUUORkZEu2+zkyZPatGmTc5u1bt1ax48f15YtW5xz1qxZo5ycHGfYLOlyw9auXbu0evVqlS9f/pK32bZtm3x8fPK8FecJDh48qGPHjjmfk96wDaU/9ji3aNFCTZs2veTckrT9LvV3oSCvna1bt9Y333zjEpxz/+PQsGHDK9NIcXDzQft/eW+++aYJCAgw8+fPN99995257777TFhYmMunMTzF/fffb0JDQ01ycrI5cuSI85Kenm6MMWb37t1m0qRJ5ssvvzSpqanm/fffNzVr1jTt27d3c+UFM3bsWJOcnGxSU1PNZ599ZmJiYkyFChXM0aNHjTHGDBs2zFx99dVmzZo15ssvvzStW7c2rVu3dnPVhZednW2uvvpq8/DDD7uMe+L2O3XqlNm6davZunWrkWT+9a9/ma1btzo/oTdlyhQTFhZm3n//fbN9+3bTvXt3U6NGDfP7778719GlSxfTvHlzs2nTJvPpp5+aOnXqmL59+7qrpTwu1mNGRoa5/fbbzVVXXWW2bdvm8nuZ++muDRs2mOnTp5tt27aZPXv2mAULFpiKFSuaAQMGuLmzP1ysv1OnTpkHH3zQbNy40aSmpprVq1eba6+91tSpU8ecPXvWuY6SvA0v9Rw1xpgTJ06YoKAgM2vWrDy3L+nb71J/F4y59GtnVlaWadSokencubPZtm2bWblypalYsaIZN26cO1oqMgJXCfD888+bq6++2vj7+5tWrVqZzz//3N0lFYmkfC/z5s0zxhhz4MAB0759exMeHm4CAgJM7dq1TXx8vDlx4oR7Cy+gu+66y1SuXNn4+/ubKlWqmLvuusvs3r3bufz33383w4cPN+XKlTNBQUGmZ8+e5siRI26suGg++ugjI8mkpKS4jHvi9lu7dm2+z8mBAwcaY/44NcQTTzxhKlWqZAICAkynTp3y9H3s2DHTt29fU6ZMGRMSEmLuuecec+rUKTd0k7+L9ZiamnrB38u1a9caY4zZsmWLiY6ONqGhoaZ06dKmQYMG5umnn3YJLO50sf7S09NN586dTcWKFY2fn5+pVq2auffee/P8h7Ukb8NLPUeNMeall14ygYGB5vjx43luX9K336X+LhhTsNfOffv2ma5du5rAwEBToUIFM3bsWJOZmXmFu7k8DmOMsbTzDAAAAOIYLgAAAOsIXAAAAJYRuAAAACwjcAEAAFhG4AIAALCMwAUAAGAZgQsAAMAyAhcAAIBlBC4AkDRo0CA5HI48F0/8Ym4AJU8pdxcAACVFly5dNG/ePJexihUruqkaV5mZmfLz83N3GQCKiD1cAPD/BQQEKDIy0uXi6+ub79z9+/frtttuU7ly5RQcHKxrrrlGy5cvdy7fsWOHbr31VoWEhKhs2bJq166d9uzZI0nKycnRpEmTdNVVVykgIEDNmjXTypUrnbfdt2+fHA6HFi9erA4dOqh06dJauHChJGnOnDlq0KCBSpcurfr16+vFF1+0+IgAKC7s4QKAIoiLi1NGRobWr1+v4OBgfffddypTpowk6dChQ2rfvr06duyoNWvWKCQkRJ999pmysrIkSc8995yeffZZvfTSS2revLnmzp2r22+/XTt27FCdOnWc9/HII4/o2WefVfPmzZ2ha/z48Zo5c6aaN2+urVu36t5771VwcLAGDhzolscBQAG5+9uzAaAkGDhwoPH19TXBwcHOy9/+9rcLzm/cuLGZOHFivsvGjRtnatSoYTIyMvJdHhUVZZ566imXseuuu84MHz7cGGNMamqqkWRmzJjhMqdWrVpm0aJFLmOTJ082rVu3vmR/ANyLPVwA8P/deOONmjVrlvN6cHDwBeeOHDlS999/v1atWqWYmBjdcccdatKkiSRp27ZtateuXb7HXJ08eVKHDx9WmzZtXMbbtGmjr7/+2mWsZcuWzp/PnDmjPXv2aMiQIbr33nud41lZWQoNDS1cowCuOAIXAPx/wcHBql27doHmDh06VLGxsVq2bJlWrVqlxMREPfvss3rggQcUGBhYbPXkOn36tCTplVdeUXR0tMu8Cx1nBqDk4KB5ACiiqlWratiwYVqyZInGjh2rV155RZLUpEkTffLJJ8rMzMxzm5CQEEVFRemzzz5zGf/ss8/UsGHDC95XpUqVFBUVpb1796p27doulxo1ahRvYwCKHXu4AKAIRo0apa5du6pu3br67bfftHbtWjVo0ECSNGLECD3//PPq06ePxo0bp9DQUH3++edq1aqV6tWrp/j4eE2YMEG1atVSs2bNNG/ePG3bts35ScQLSUhI0MiRIxUaGqouXbro3Llz+vLLL/Xbb79pzJgxV6JtAEVE4AKAIsjOzlZcXJwOHjyokJAQdenSRdOnT5cklS9fXmvWrFF8fLw6dOggX19fNWvWzHnc1siRI3XixAmNHTtWR48eVcOGDfXBBx+4fEIxP0OHDlVQUJCmTZum+Ph4BQcHq3Hjxho1apTtdgFcJocxxri7CAAAAG/GMVwAAACWEbgAAAAsI3ABAABYRuACAACwjMAFAABgGYELAADAMgIXAACAZQQuAAAAywhcAAAAlhG4AAAALCNwAQAAWEbgAgAAsOz/AWAYE8nrqde+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(\"cv\", axis=1)\n",
    "y = data[\"cv\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Plot feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_importance(model, importance_type=\"weight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2b3e06-9555-4896-9a47-c37900fc30cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2384925707.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Splitting Criteria:\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Splitting Criteria:\n",
    "\n",
    "XGBoost builds decision trees by selecting splits that maximize a gain metric \n",
    "(e.g., information gain, Gini index, etc.).\n",
    "Features that contribute to significant improvements in splitting the data are\n",
    "assigned higher importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4de5397-8534-41d7-a891-c9923177e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.02972719401873\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(\"cv\", axis=1)\n",
    "y = data[\"cv\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c550ef44-8fee-49e4-a369-774326acd32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation 3.350358100054996\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score=cross_val_score(model,X,y,cv=5,scoring=\"neg_root_mean_squared_error\")\n",
    "print(\"cross validation\",-cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973623fb-1052-4e2a-b7c4-71af30952ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G  -  0.0\n",
      "wL  -  0.7513631\n",
      "wp  -  0.0\n",
      "IP  -  0.0\n",
      "% Clay  -  0.0\n",
      "% Silt  -  0.0\n",
      "% Sand  -  0.0\n",
      "Pressure  -  0.0\n"
     ]
    }
   ],
   "source": [
    "#Feature importance sensitivity analysis\n",
    "import numpy as np\n",
    "for feature in X.columns:\n",
    "    X_copy=X_test.copy()\n",
    "    X_copy[feature]+=np.random.normal(0,0.1,size=X_copy[feature].shape)\n",
    "    y_per=model.predict(X_copy)\n",
    "    sen=np.mean(np.abs(y_per-y_pred))\n",
    "    print(feature ,\" - \", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf0deb4-aa00-4b26-a5e7-a3370c4b8d87",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3716389146.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Feature importance sensitivity analysis is a technique that helps identify the most\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Feature importance sensitivity analysis is a technique that helps identify the most \n",
    "important features in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01a585-dfae-4c78-a56b-d164862f1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging regressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bg_model=BaggingRegressor(estimator = XGBRegressor(),n_estimators=10,random_state=42)\n",
    "bg_model.fit(X_train,y_train)\n",
    "y_pred1=bg_model.predict(X_test)\n",
    "bg_mse=mean_squared_error(y_test,y_pred1,squared=False)\n",
    "print(bg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e92f5-b656-419e-9676-a39e9939ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_model = XGBRegressor(\n",
    "    n_estimators=200, \n",
    "    learning_rate=0.05, \n",
    "    max_depth=4, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8, \n",
    "    random_state=42\n",
    ")\n",
    "boosting_model.fit(X_train, y_train)\n",
    "y_boosting_pred = boosting_model.predict(X_test)\n",
    "boosting_rmse = mean_squared_error(y_test, y_boosting_pred, squared=False)\n",
    "print(f\"Boosting RMSE: {boosting_rmse:.4f}\")\n",
    "\n",
    "# Step 10: Plot Feature Importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_importance(model, importance_type=\"weight\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9d0b77-3746-43ce-aae4-336c29cfa15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ae6599070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_regression(n_samples=1000, n_features=5, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=X.shape[1], activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c718939-9d53-4a4a-b9fa-170bdfff3022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances (Garson): [0.1199988  0.11173499 0.11938599 0.00069652 0.1210194  0.1509683\n",
      " 0.1310856  0.1050675  0.13924736 0.00079549]\n"
     ]
    }
   ],
   "source": [
    "def garson_feature_importance(model):\n",
    "    \"\"\"\n",
    "    Calculates feature importance using the Garson algorithm.\n",
    "    Parameters:\n",
    "        model (keras.Sequential): A trained neural network model.\n",
    "    Returns:\n",
    "        numpy.ndarray: Feature importances.\n",
    "    \"\"\"\n",
    "    weights = [layer.get_weights()[0] for layer in model.layers if len(layer.get_weights()) > 0]\n",
    "\n",
    "    # Extract input-to-hidden and hidden-to-output weights\n",
    "    input_hidden_weights = weights[0]\n",
    "    hidden_output_weights = weights[1]\n",
    "    \n",
    "    # Compute absolute contributions\n",
    "    abs_input_hidden = np.abs(input_hidden_weights)\n",
    "    abs_hidden_output = np.abs(hidden_output_weights)\n",
    "    \n",
    "    # Contribution of each input feature\n",
    "    total_contribution = np.sum(abs_input_hidden, axis=0) * np.sum(abs_hidden_output, axis=1)\n",
    " \n",
    "    feature_importance = total_contribution / np.sum(total_contribution)\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "# Get feature importances\n",
    "importances = garson_feature_importance(model)\n",
    "print(\"Feature Importances (Garson):\", importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009bb5e3-450e-414b-a6d9-533712d037f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11101669 0.13238314 0.29257685 0.20841286 0.25561044]\n"
     ]
    }
   ],
   "source": [
    "def connection_weight_importance(model):\n",
    "    weights=[layer.get_weights()[0] for layer in model.layers if len(layer.get_weights())>0 ]\n",
    "    input_hidden_weights=weights[0]\n",
    "    hidden_output_weights=weights[1]\n",
    "\n",
    "    conection_weight=input_hidden_weights @ hidden_output_weights\n",
    "    feature_importance=np.sum(np.abs(conection_weight),axis=1)\n",
    "    feature_importance/= np.sum(feature_importance)\n",
    "    return feature_importance\n",
    "\n",
    "importance = connection_weight_importance(model)\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d99bd9-0d9a-4b19-80e2-dbd9284a9053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
