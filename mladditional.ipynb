{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abef8702-2f7f-4b07-9935-49777c403077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (KNN): 0.14312849034929087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "data = pd.read_csv('adult.csv')\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                       'relationship', 'race', 'sex', 'nativeCountry']\n",
    "data = pd.get_dummies(data, columns=categorical_columns)\n",
    "data['income'] = data['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3)  # You can adjust 'n_neighbors' as needed\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the KNN model using Mean Squared Error\n",
    "knn_mse = mean_squared_error(y_test, knn_pred)\n",
    "print(f\"Mean Squared Error (KNN): {knn_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b126cc3a-26c1-42c5-9740-055302b7575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 11.54\n",
      "Baseline MSE: 36.52\n",
      "The Decision Tree model performs better than the baseline.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.drop('cv', axis=1)\n",
    "y = data['cv']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Decision Tree Regressor\n",
    "tree = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_tree = mean_squared_error(y_test, y_pred)\n",
    "print(f'Decision Tree MSE: {mse_tree:.2f}')\n",
    "\n",
    "# Baseline Model: Mean Predictor\n",
    "y_baseline_pred = np.full(shape=y_test.shape, fill_value=y_train.mean())\n",
    "mse_baseline = mean_squared_error(y_test, y_baseline_pred)\n",
    "print(f'Baseline MSE: {mse_baseline:.2f}')\n",
    "\n",
    "# Interpretation\n",
    "if mse_tree < mse_baseline:\n",
    "    print(\"The Decision Tree model performs better than the baseline.\")\n",
    "else:\n",
    "    print(\"The Decision Tree model does not outperform the baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4be145-ea82-4af8-96e7-3302a5980117",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feed forward neural networks are artificial neural networks in\n",
    "which nodes do not form loops. This type of neural network is also known\n",
    "as a multi-layer neural network as all information is\n",
    "only passed forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee00e449-228e-4d4c-95a1-9c4a0956743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 91.1011 - mean_squared_error: 91.1011 - val_loss: 33.7534 - val_mean_squared_error: 33.7534\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 90.2831 - mean_squared_error: 90.2831 - val_loss: 33.1942 - val_mean_squared_error: 33.1942\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 89.4732 - mean_squared_error: 89.4732 - val_loss: 32.6372 - val_mean_squared_error: 32.6372\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 88.6574 - mean_squared_error: 88.6574 - val_loss: 32.0934 - val_mean_squared_error: 32.0934\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 87.8500 - mean_squared_error: 87.8500 - val_loss: 31.5719 - val_mean_squared_error: 31.5719\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 87.0345 - mean_squared_error: 87.0345 - val_loss: 31.0605 - val_mean_squared_error: 31.0605\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 86.2250 - mean_squared_error: 86.2250 - val_loss: 30.5491 - val_mean_squared_error: 30.5491\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 85.4458 - mean_squared_error: 85.4458 - val_loss: 30.0528 - val_mean_squared_error: 30.0528\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 84.7013 - mean_squared_error: 84.7013 - val_loss: 29.5300 - val_mean_squared_error: 29.5300\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 83.9732 - mean_squared_error: 83.9732 - val_loss: 29.0050 - val_mean_squared_error: 29.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 83.2380 - mean_squared_error: 83.2380 - val_loss: 28.4849 - val_mean_squared_error: 28.4849\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 82.4954 - mean_squared_error: 82.4954 - val_loss: 27.9765 - val_mean_squared_error: 27.9765\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 81.7645 - mean_squared_error: 81.7645 - val_loss: 27.4934 - val_mean_squared_error: 27.4934\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 81.0732 - mean_squared_error: 81.0732 - val_loss: 27.0124 - val_mean_squared_error: 27.0124\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 80.3878 - mean_squared_error: 80.3878 - val_loss: 26.5240 - val_mean_squared_error: 26.5240\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 79.6945 - mean_squared_error: 79.6945 - val_loss: 26.0470 - val_mean_squared_error: 26.0470\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 78.9868 - mean_squared_error: 78.9868 - val_loss: 25.5691 - val_mean_squared_error: 25.5691\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 78.2537 - mean_squared_error: 78.2537 - val_loss: 25.0905 - val_mean_squared_error: 25.0905\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 77.5179 - mean_squared_error: 77.5179 - val_loss: 24.6135 - val_mean_squared_error: 24.6135\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 76.7901 - mean_squared_error: 76.7901 - val_loss: 24.1389 - val_mean_squared_error: 24.1389\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 76.0626 - mean_squared_error: 76.0626 - val_loss: 23.6684 - val_mean_squared_error: 23.6684\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 75.3242 - mean_squared_error: 75.3242 - val_loss: 23.2015 - val_mean_squared_error: 23.2015\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 74.5768 - mean_squared_error: 74.5768 - val_loss: 22.7326 - val_mean_squared_error: 22.7326\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 73.8125 - mean_squared_error: 73.8125 - val_loss: 22.2639 - val_mean_squared_error: 22.2639\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 73.0315 - mean_squared_error: 73.0315 - val_loss: 21.7957 - val_mean_squared_error: 21.7957\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 72.2374 - mean_squared_error: 72.2374 - val_loss: 21.3299 - val_mean_squared_error: 21.3299\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 71.4361 - mean_squared_error: 71.4361 - val_loss: 20.8663 - val_mean_squared_error: 20.8663\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 70.6274 - mean_squared_error: 70.6274 - val_loss: 20.4061 - val_mean_squared_error: 20.4061\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 69.7979 - mean_squared_error: 69.7979 - val_loss: 19.9472 - val_mean_squared_error: 19.9472\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 68.9511 - mean_squared_error: 68.9511 - val_loss: 19.4733 - val_mean_squared_error: 19.4733\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 68.1019 - mean_squared_error: 68.1019 - val_loss: 18.9877 - val_mean_squared_error: 18.9877\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 67.2366 - mean_squared_error: 67.2366 - val_loss: 18.5039 - val_mean_squared_error: 18.5039\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 66.3535 - mean_squared_error: 66.3535 - val_loss: 18.0248 - val_mean_squared_error: 18.0248\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 65.4530 - mean_squared_error: 65.4530 - val_loss: 17.5521 - val_mean_squared_error: 17.5521\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 64.5342 - mean_squared_error: 64.5342 - val_loss: 17.0791 - val_mean_squared_error: 17.0791\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 63.5940 - mean_squared_error: 63.5940 - val_loss: 16.5962 - val_mean_squared_error: 16.5962\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 62.6372 - mean_squared_error: 62.6372 - val_loss: 16.1143 - val_mean_squared_error: 16.1143\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 61.6630 - mean_squared_error: 61.6630 - val_loss: 15.6357 - val_mean_squared_error: 15.6357\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 60.6688 - mean_squared_error: 60.6688 - val_loss: 15.1609 - val_mean_squared_error: 15.1609\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 59.6583 - mean_squared_error: 59.6583 - val_loss: 14.6905 - val_mean_squared_error: 14.6905\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 58.6320 - mean_squared_error: 58.6320 - val_loss: 14.2254 - val_mean_squared_error: 14.2254\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 57.5906 - mean_squared_error: 57.5906 - val_loss: 13.7663 - val_mean_squared_error: 13.7663\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 56.5340 - mean_squared_error: 56.5340 - val_loss: 13.3143 - val_mean_squared_error: 13.3143\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 55.4628 - mean_squared_error: 55.4628 - val_loss: 12.8699 - val_mean_squared_error: 12.8699\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 54.3771 - mean_squared_error: 54.3771 - val_loss: 12.4339 - val_mean_squared_error: 12.4339\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 53.2774 - mean_squared_error: 53.2774 - val_loss: 12.0080 - val_mean_squared_error: 12.0080\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 52.1642 - mean_squared_error: 52.1642 - val_loss: 11.5929 - val_mean_squared_error: 11.5929\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 51.0381 - mean_squared_error: 51.0381 - val_loss: 11.1897 - val_mean_squared_error: 11.1897\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 49.8962 - mean_squared_error: 49.8962 - val_loss: 10.7985 - val_mean_squared_error: 10.7985\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 48.7308 - mean_squared_error: 48.7308 - val_loss: 10.4212 - val_mean_squared_error: 10.4212\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 47.5507 - mean_squared_error: 47.5507 - val_loss: 10.0594 - val_mean_squared_error: 10.0594\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 46.3465 - mean_squared_error: 46.3465 - val_loss: 9.7152 - val_mean_squared_error: 9.7152\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 45.1179 - mean_squared_error: 45.1179 - val_loss: 9.3997 - val_mean_squared_error: 9.3997\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 43.8748 - mean_squared_error: 43.8748 - val_loss: 9.1066 - val_mean_squared_error: 9.1066\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 42.6201 - mean_squared_error: 42.6201 - val_loss: 8.8375 - val_mean_squared_error: 8.8375\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 41.3559 - mean_squared_error: 41.3559 - val_loss: 8.5904 - val_mean_squared_error: 8.5904\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 40.0830 - mean_squared_error: 40.0830 - val_loss: 8.3678 - val_mean_squared_error: 8.3678\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 38.8036 - mean_squared_error: 38.8036 - val_loss: 8.1868 - val_mean_squared_error: 8.1868\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 37.5200 - mean_squared_error: 37.5200 - val_loss: 8.0442 - val_mean_squared_error: 8.0442\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 36.2349 - mean_squared_error: 36.2349 - val_loss: 7.9374 - val_mean_squared_error: 7.9374\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 34.9503 - mean_squared_error: 34.9503 - val_loss: 7.8679 - val_mean_squared_error: 7.8679\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 33.6688 - mean_squared_error: 33.6688 - val_loss: 7.8386 - val_mean_squared_error: 7.8386\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 32.3822 - mean_squared_error: 32.3822 - val_loss: 7.8506 - val_mean_squared_error: 7.8506\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 31.0949 - mean_squared_error: 31.0949 - val_loss: 7.9110 - val_mean_squared_error: 7.9110\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 29.8136 - mean_squared_error: 29.8136 - val_loss: 8.0218 - val_mean_squared_error: 8.0218\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 28.5443 - mean_squared_error: 28.5443 - val_loss: 8.1788 - val_mean_squared_error: 8.1788\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 27.2857 - mean_squared_error: 27.2857 - val_loss: 8.3771 - val_mean_squared_error: 8.3771\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 26.0396 - mean_squared_error: 26.0396 - val_loss: 8.6235 - val_mean_squared_error: 8.6235\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 24.8090 - mean_squared_error: 24.8090 - val_loss: 8.9190 - val_mean_squared_error: 8.9190\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 23.5965 - mean_squared_error: 23.5965 - val_loss: 9.2645 - val_mean_squared_error: 9.2645\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 22.4044 - mean_squared_error: 22.4044 - val_loss: 9.6604 - val_mean_squared_error: 9.6604\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21.2317 - mean_squared_error: 21.2317 - val_loss: 10.1070 - val_mean_squared_error: 10.1070\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 20.0826 - mean_squared_error: 20.0826 - val_loss: 10.6042 - val_mean_squared_error: 10.6042\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 18.9612 - mean_squared_error: 18.9612 - val_loss: 11.1511 - val_mean_squared_error: 11.1511\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 17.8679 - mean_squared_error: 17.8679 - val_loss: 11.7471 - val_mean_squared_error: 11.7471\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 16.8012 - mean_squared_error: 16.8012 - val_loss: 12.3912 - val_mean_squared_error: 12.3912\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 15.7685 - mean_squared_error: 15.7685 - val_loss: 13.0817 - val_mean_squared_error: 13.0817\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 14.7713 - mean_squared_error: 14.7713 - val_loss: 13.8164 - val_mean_squared_error: 13.8164\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 13.8118 - mean_squared_error: 13.8118 - val_loss: 14.5928 - val_mean_squared_error: 14.5928\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 12.8922 - mean_squared_error: 12.8922 - val_loss: 15.4080 - val_mean_squared_error: 15.4080\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 12.0141 - mean_squared_error: 12.0141 - val_loss: 16.2681 - val_mean_squared_error: 16.2681\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 11.1789 - mean_squared_error: 11.1789 - val_loss: 17.1617 - val_mean_squared_error: 17.1617\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 10.3878 - mean_squared_error: 10.3878 - val_loss: 18.0838 - val_mean_squared_error: 18.0838\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 9.6413 - mean_squared_error: 9.6413 - val_loss: 19.0294 - val_mean_squared_error: 19.0294\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.9403 - mean_squared_error: 8.9403 - val_loss: 19.9933 - val_mean_squared_error: 19.9933\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 8.2852 - mean_squared_error: 8.2852 - val_loss: 20.9695 - val_mean_squared_error: 20.9695\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 7.6758 - mean_squared_error: 7.6758 - val_loss: 21.9517 - val_mean_squared_error: 21.9517\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.1121 - mean_squared_error: 7.1121 - val_loss: 22.9353 - val_mean_squared_error: 22.9353\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.5934 - mean_squared_error: 6.5934 - val_loss: 23.9122 - val_mean_squared_error: 23.9122\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.1188 - mean_squared_error: 6.1188 - val_loss: 24.8755 - val_mean_squared_error: 24.8755\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 5.6857 - mean_squared_error: 5.6857 - val_loss: 25.8179 - val_mean_squared_error: 25.8179\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 5.2897 - mean_squared_error: 5.2897 - val_loss: 26.7406 - val_mean_squared_error: 26.7406\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4.9197 - mean_squared_error: 4.9197 - val_loss: 27.6379 - val_mean_squared_error: 27.6379\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 4.5848 - mean_squared_error: 4.5848 - val_loss: 28.5013 - val_mean_squared_error: 28.5013\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 4.2852 - mean_squared_error: 4.2852 - val_loss: 29.3207 - val_mean_squared_error: 29.3207\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.0191 - mean_squared_error: 4.0191 - val_loss: 30.0895 - val_mean_squared_error: 30.0895\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7857 - mean_squared_error: 3.7857 - val_loss: 30.8017 - val_mean_squared_error: 30.8017\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.5833 - mean_squared_error: 3.5833 - val_loss: 31.4495 - val_mean_squared_error: 31.4495\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 3.4093 - mean_squared_error: 3.4093 - val_loss: 32.0285 - val_mean_squared_error: 32.0285\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.2605 - mean_squared_error: 3.2605 - val_loss: 32.5377 - val_mean_squared_error: 32.5377\n",
      "Mean Squared Error on test set: 9.28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('cv', axis=1)\n",
    "y = data['cv']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Feedforward Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer + Hidden layer 1\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Hidden layer 2\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# Output layer (no activation for regression)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b747603d-317f-4567-98a8-239d71ad851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer neurons: 8\n",
      "Hidden layer 1 neurons: 64 (800.00% of input neurons)\n",
      "Hidden layer 2 neurons: 32 (400.00% of input neurons)\n",
      "Hidden layer 3 neurons: 16 (200.00% of input neurons)\n",
      "Output layer neurons: 1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 92.2266 - mean_squared_error: 92.2266 - val_loss: 38.9801 - val_mean_squared_error: 38.9801\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 91.4226 - mean_squared_error: 91.4226 - val_loss: 38.4453 - val_mean_squared_error: 38.4453\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 90.7767 - mean_squared_error: 90.7767 - val_loss: 37.9123 - val_mean_squared_error: 37.9123\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 90.2218 - mean_squared_error: 90.2218 - val_loss: 37.4435 - val_mean_squared_error: 37.4435\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 89.7177 - mean_squared_error: 89.7177 - val_loss: 37.0045 - val_mean_squared_error: 37.0045\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 89.2947 - mean_squared_error: 89.2947 - val_loss: 36.6036 - val_mean_squared_error: 36.6036\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 88.8402 - mean_squared_error: 88.8402 - val_loss: 36.2101 - val_mean_squared_error: 36.2101\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 88.3822 - mean_squared_error: 88.3822 - val_loss: 35.8432 - val_mean_squared_error: 35.8432\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 87.9446 - mean_squared_error: 87.9446 - val_loss: 35.4865 - val_mean_squared_error: 35.4865\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 87.5048 - mean_squared_error: 87.5048 - val_loss: 35.1439 - val_mean_squared_error: 35.1439\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 87.0539 - mean_squared_error: 87.0539 - val_loss: 34.8226 - val_mean_squared_error: 34.8226\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 86.6045 - mean_squared_error: 86.6045 - val_loss: 34.5113 - val_mean_squared_error: 34.5113\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 86.1418 - mean_squared_error: 86.1418 - val_loss: 34.1846 - val_mean_squared_error: 34.1846\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 85.6715 - mean_squared_error: 85.6715 - val_loss: 33.8640 - val_mean_squared_error: 33.8640\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 85.1834 - mean_squared_error: 85.1834 - val_loss: 33.5269 - val_mean_squared_error: 33.5269\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 84.6824 - mean_squared_error: 84.6824 - val_loss: 33.1665 - val_mean_squared_error: 33.1665\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 84.1851 - mean_squared_error: 84.1851 - val_loss: 32.8032 - val_mean_squared_error: 32.8032\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 83.6896 - mean_squared_error: 83.6896 - val_loss: 32.4407 - val_mean_squared_error: 32.4407\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 83.2009 - mean_squared_error: 83.2009 - val_loss: 32.0781 - val_mean_squared_error: 32.0781\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 82.7092 - mean_squared_error: 82.7092 - val_loss: 31.7245 - val_mean_squared_error: 31.7245\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 82.2039 - mean_squared_error: 82.2039 - val_loss: 31.3690 - val_mean_squared_error: 31.3690\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 81.6850 - mean_squared_error: 81.6850 - val_loss: 31.0120 - val_mean_squared_error: 31.0120\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 81.1447 - mean_squared_error: 81.1447 - val_loss: 30.6463 - val_mean_squared_error: 30.6463\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 80.5765 - mean_squared_error: 80.5765 - val_loss: 30.2690 - val_mean_squared_error: 30.2690\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 79.9841 - mean_squared_error: 79.9841 - val_loss: 29.8760 - val_mean_squared_error: 29.8760\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 79.3680 - mean_squared_error: 79.3680 - val_loss: 29.4695 - val_mean_squared_error: 29.4695\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 78.7328 - mean_squared_error: 78.7328 - val_loss: 29.0541 - val_mean_squared_error: 29.0541\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 78.0792 - mean_squared_error: 78.0792 - val_loss: 28.6361 - val_mean_squared_error: 28.6361\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 77.4083 - mean_squared_error: 77.4083 - val_loss: 28.2451 - val_mean_squared_error: 28.2451\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 76.7195 - mean_squared_error: 76.7195 - val_loss: 27.8489 - val_mean_squared_error: 27.8489\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 76.0086 - mean_squared_error: 76.0086 - val_loss: 27.4479 - val_mean_squared_error: 27.4479\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 75.2757 - mean_squared_error: 75.2757 - val_loss: 27.0425 - val_mean_squared_error: 27.0425\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 74.5213 - mean_squared_error: 74.5213 - val_loss: 26.6319 - val_mean_squared_error: 26.6319\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 73.7438 - mean_squared_error: 73.7438 - val_loss: 26.2173 - val_mean_squared_error: 26.2173\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 72.9459 - mean_squared_error: 72.9459 - val_loss: 25.7988 - val_mean_squared_error: 25.7988\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 72.1275 - mean_squared_error: 72.1275 - val_loss: 25.3774 - val_mean_squared_error: 25.3774\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 71.2868 - mean_squared_error: 71.2868 - val_loss: 24.9540 - val_mean_squared_error: 24.9540\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 70.4051 - mean_squared_error: 70.4051 - val_loss: 24.5262 - val_mean_squared_error: 24.5262\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 69.4949 - mean_squared_error: 69.4949 - val_loss: 24.0980 - val_mean_squared_error: 24.0980\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 68.5581 - mean_squared_error: 68.5581 - val_loss: 23.6707 - val_mean_squared_error: 23.6707\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 67.5901 - mean_squared_error: 67.5901 - val_loss: 23.2355 - val_mean_squared_error: 23.2355\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 66.5944 - mean_squared_error: 66.5944 - val_loss: 22.7748 - val_mean_squared_error: 22.7748\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 65.5726 - mean_squared_error: 65.5726 - val_loss: 22.3203 - val_mean_squared_error: 22.3203\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 64.5319 - mean_squared_error: 64.5319 - val_loss: 21.8670 - val_mean_squared_error: 21.8670\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 63.4644 - mean_squared_error: 63.4644 - val_loss: 21.4187 - val_mean_squared_error: 21.4187\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 62.3692 - mean_squared_error: 62.3692 - val_loss: 20.9697 - val_mean_squared_error: 20.9697\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 61.2299 - mean_squared_error: 61.2299 - val_loss: 20.5312 - val_mean_squared_error: 20.5312\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 60.0458 - mean_squared_error: 60.0458 - val_loss: 20.1053 - val_mean_squared_error: 20.1053\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 58.8327 - mean_squared_error: 58.8327 - val_loss: 19.6869 - val_mean_squared_error: 19.6869\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 57.5838 - mean_squared_error: 57.5838 - val_loss: 19.2313 - val_mean_squared_error: 19.2313\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 56.3087 - mean_squared_error: 56.3087 - val_loss: 18.7923 - val_mean_squared_error: 18.7923\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 55.0046 - mean_squared_error: 55.0046 - val_loss: 18.3715 - val_mean_squared_error: 18.3715\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 53.6704 - mean_squared_error: 53.6704 - val_loss: 17.9737 - val_mean_squared_error: 17.9737\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 52.3084 - mean_squared_error: 52.3084 - val_loss: 17.6021 - val_mean_squared_error: 17.6021\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 50.9214 - mean_squared_error: 50.9214 - val_loss: 17.2578 - val_mean_squared_error: 17.2578\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 49.5114 - mean_squared_error: 49.5114 - val_loss: 16.9464 - val_mean_squared_error: 16.9464\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 48.0802 - mean_squared_error: 48.0802 - val_loss: 16.6750 - val_mean_squared_error: 16.6750\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 46.6299 - mean_squared_error: 46.6299 - val_loss: 16.4450 - val_mean_squared_error: 16.4450\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 45.1626 - mean_squared_error: 45.1626 - val_loss: 16.2608 - val_mean_squared_error: 16.2608\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 43.6806 - mean_squared_error: 43.6806 - val_loss: 16.1265 - val_mean_squared_error: 16.1265\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 42.1863 - mean_squared_error: 42.1863 - val_loss: 16.0462 - val_mean_squared_error: 16.0462\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 40.6823 - mean_squared_error: 40.6823 - val_loss: 16.0233 - val_mean_squared_error: 16.0233\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 39.1690 - mean_squared_error: 39.1690 - val_loss: 16.0595 - val_mean_squared_error: 16.0595\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 37.6474 - mean_squared_error: 37.6474 - val_loss: 16.1641 - val_mean_squared_error: 16.1641\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 36.1169 - mean_squared_error: 36.1169 - val_loss: 16.3548 - val_mean_squared_error: 16.3548\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 34.5759 - mean_squared_error: 34.5759 - val_loss: 16.6400 - val_mean_squared_error: 16.6400\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 33.0387 - mean_squared_error: 33.0387 - val_loss: 16.9997 - val_mean_squared_error: 16.9997\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 31.4970 - mean_squared_error: 31.4970 - val_loss: 17.4260 - val_mean_squared_error: 17.4260\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 29.9596 - mean_squared_error: 29.9596 - val_loss: 17.9246 - val_mean_squared_error: 17.9246\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 28.4374 - mean_squared_error: 28.4374 - val_loss: 18.5061 - val_mean_squared_error: 18.5061\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 26.9365 - mean_squared_error: 26.9365 - val_loss: 19.1759 - val_mean_squared_error: 19.1759\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 25.4617 - mean_squared_error: 25.4617 - val_loss: 19.9733 - val_mean_squared_error: 19.9733\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 24.0029 - mean_squared_error: 24.0029 - val_loss: 20.9273 - val_mean_squared_error: 20.9273\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 22.5626 - mean_squared_error: 22.5626 - val_loss: 21.9664 - val_mean_squared_error: 21.9664\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21.1535 - mean_squared_error: 21.1535 - val_loss: 23.0879 - val_mean_squared_error: 23.0879\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 19.7825 - mean_squared_error: 19.7825 - val_loss: 24.2660 - val_mean_squared_error: 24.2660\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 18.4528 - mean_squared_error: 18.4528 - val_loss: 25.5128 - val_mean_squared_error: 25.5128\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 17.1788 - mean_squared_error: 17.1788 - val_loss: 26.8181 - val_mean_squared_error: 26.8181\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 15.9462 - mean_squared_error: 15.9462 - val_loss: 28.1663 - val_mean_squared_error: 28.1663\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 14.7719 - mean_squared_error: 14.7719 - val_loss: 29.5395 - val_mean_squared_error: 29.5395\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 13.6559 - mean_squared_error: 13.6559 - val_loss: 30.9176 - val_mean_squared_error: 30.9176\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 12.6030 - mean_squared_error: 12.6030 - val_loss: 32.2804 - val_mean_squared_error: 32.2804\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 11.6165 - mean_squared_error: 11.6165 - val_loss: 33.6067 - val_mean_squared_error: 33.6067\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 10.6969 - mean_squared_error: 10.6969 - val_loss: 34.8780 - val_mean_squared_error: 34.8780\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 9.8436 - mean_squared_error: 9.8436 - val_loss: 36.0762 - val_mean_squared_error: 36.0762\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 9.0550 - mean_squared_error: 9.0550 - val_loss: 37.1851 - val_mean_squared_error: 37.1851\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.3289 - mean_squared_error: 8.3289 - val_loss: 38.1898 - val_mean_squared_error: 38.1898\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.6666 - mean_squared_error: 7.6666 - val_loss: 39.0777 - val_mean_squared_error: 39.0777\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 7.0651 - mean_squared_error: 7.0651 - val_loss: 39.8388 - val_mean_squared_error: 39.8388\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 6.5224 - mean_squared_error: 6.5224 - val_loss: 40.4653 - val_mean_squared_error: 40.4653\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.0354 - mean_squared_error: 6.0354 - val_loss: 40.9520 - val_mean_squared_error: 40.9520\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.6008 - mean_squared_error: 5.6008 - val_loss: 41.2965 - val_mean_squared_error: 41.2965\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.2149 - mean_squared_error: 5.2149 - val_loss: 41.4986 - val_mean_squared_error: 41.4986\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 4.8741 - mean_squared_error: 4.8741 - val_loss: 41.5601 - val_mean_squared_error: 41.5601\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.5744 - mean_squared_error: 4.5744 - val_loss: 41.4849 - val_mean_squared_error: 41.4849\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 4.3115 - mean_squared_error: 4.3115 - val_loss: 41.2793 - val_mean_squared_error: 41.2793\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 4.0819 - mean_squared_error: 4.0819 - val_loss: 40.9531 - val_mean_squared_error: 40.9531\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.8819 - mean_squared_error: 3.8819 - val_loss: 40.5255 - val_mean_squared_error: 40.5255\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7078 - mean_squared_error: 3.7078 - val_loss: 39.9880 - val_mean_squared_error: 39.9880\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 3.5565 - mean_squared_error: 3.5565 - val_loss: 39.3567 - val_mean_squared_error: 39.3567\n",
      "Mean Squared Error on test set: 12.13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('cv', axis=1)\n",
    "y = data['cv']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Multilayer Perceptron model\n",
    "input_neurons = X_train.shape[1]\n",
    "print(f\"Input layer neurons: {input_neurons}\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer + Hidden layer 1\n",
    "layer1_neurons = 64\n",
    "model.add(Dense(layer1_neurons, input_shape=(input_neurons,), activation='relu'))\n",
    "print(f\"Hidden layer 1 neurons: {layer1_neurons} ({(layer1_neurons / input_neurons) * 100:.2f}% of input neurons)\")\n",
    "\n",
    "# Hidden layer 2\n",
    "layer2_neurons = 32\n",
    "model.add(Dense(layer2_neurons, activation='relu'))\n",
    "print(f\"Hidden layer 2 neurons: {layer2_neurons} ({(layer2_neurons / input_neurons) * 100:.2f}% of input neurons)\")\n",
    "\n",
    "# Hidden layer 3\n",
    "layer3_neurons = 16\n",
    "model.add(Dense(layer3_neurons, activation='relu'))\n",
    "print(f\"Hidden layer 3 neurons: {layer3_neurons} ({(layer3_neurons / input_neurons) * 100:.2f}% of input neurons)\")\n",
    "\n",
    "# Output layer (no activation for regression)\n",
    "output_neurons = 1\n",
    "model.add(Dense(output_neurons))\n",
    "print(f\"Output layer neurons: {output_neurons}\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bb20fb-c92d-4940-927b-f35c797442a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 89.0842 - mean_squared_error: 89.0842 - val_loss: 33.1002 - val_mean_squared_error: 33.1002\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 87.1261 - mean_squared_error: 87.1261 - val_loss: 31.8167 - val_mean_squared_error: 31.8167\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 85.0967 - mean_squared_error: 85.0967 - val_loss: 30.5230 - val_mean_squared_error: 30.5230\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 83.0975 - mean_squared_error: 83.0975 - val_loss: 29.0009 - val_mean_squared_error: 29.0009\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 81.0539 - mean_squared_error: 81.0539 - val_loss: 27.3823 - val_mean_squared_error: 27.3823\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 78.9724 - mean_squared_error: 78.9724 - val_loss: 25.6817 - val_mean_squared_error: 25.6817\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 76.7615 - mean_squared_error: 76.7615 - val_loss: 23.9592 - val_mean_squared_error: 23.9592\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 74.3708 - mean_squared_error: 74.3708 - val_loss: 22.3007 - val_mean_squared_error: 22.3007\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 71.7691 - mean_squared_error: 71.7691 - val_loss: 20.6150 - val_mean_squared_error: 20.6150\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 69.0114 - mean_squared_error: 69.0114 - val_loss: 18.9469 - val_mean_squared_error: 18.9469\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 66.0745 - mean_squared_error: 66.0745 - val_loss: 17.3262 - val_mean_squared_error: 17.3262\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 62.9471 - mean_squared_error: 62.9471 - val_loss: 15.7923 - val_mean_squared_error: 15.7923\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 59.6226 - mean_squared_error: 59.6226 - val_loss: 14.3336 - val_mean_squared_error: 14.3336\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 56.0913 - mean_squared_error: 56.0913 - val_loss: 13.0901 - val_mean_squared_error: 13.0901\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 52.3544 - mean_squared_error: 52.3544 - val_loss: 12.1234 - val_mean_squared_error: 12.1234\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 48.4380 - mean_squared_error: 48.4380 - val_loss: 11.5010 - val_mean_squared_error: 11.5010\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 44.3308 - mean_squared_error: 44.3308 - val_loss: 11.3468 - val_mean_squared_error: 11.3468\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 40.0495 - mean_squared_error: 40.0495 - val_loss: 11.7958 - val_mean_squared_error: 11.7958\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 35.6430 - mean_squared_error: 35.6430 - val_loss: 13.0105 - val_mean_squared_error: 13.0105\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 31.1900 - mean_squared_error: 31.1900 - val_loss: 15.1986 - val_mean_squared_error: 15.1986\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 26.7382 - mean_squared_error: 26.7382 - val_loss: 18.5063 - val_mean_squared_error: 18.5063\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 22.3927 - mean_squared_error: 22.3927 - val_loss: 23.1122 - val_mean_squared_error: 23.1122\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 18.2444 - mean_squared_error: 18.2444 - val_loss: 29.1376 - val_mean_squared_error: 29.1376\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 14.5148 - mean_squared_error: 14.5148 - val_loss: 36.6906 - val_mean_squared_error: 36.6906\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 11.3711 - mean_squared_error: 11.3711 - val_loss: 45.6243 - val_mean_squared_error: 45.6243\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 8.9573 - mean_squared_error: 8.9573 - val_loss: 55.5905 - val_mean_squared_error: 55.5905\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 7.3809 - mean_squared_error: 7.3809 - val_loss: 65.8101 - val_mean_squared_error: 65.8101\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.6696 - mean_squared_error: 6.6696 - val_loss: 75.3017 - val_mean_squared_error: 75.3017\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.7006 - mean_squared_error: 6.7006 - val_loss: 82.7068 - val_mean_squared_error: 82.7068\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 7.1631 - mean_squared_error: 7.1631 - val_loss: 86.9655 - val_mean_squared_error: 86.9655\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 7.6725 - mean_squared_error: 7.6725 - val_loss: 87.5782 - val_mean_squared_error: 87.5782\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.9114 - mean_squared_error: 7.9114 - val_loss: 84.7145 - val_mean_squared_error: 84.7145\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.6910 - mean_squared_error: 7.6910 - val_loss: 79.0028 - val_mean_squared_error: 79.0028\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 7.0259 - mean_squared_error: 7.0259 - val_loss: 71.3960 - val_mean_squared_error: 71.3960\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.0826 - mean_squared_error: 6.0826 - val_loss: 62.9116 - val_mean_squared_error: 62.9116\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.0843 - mean_squared_error: 5.0843 - val_loss: 54.4133 - val_mean_squared_error: 54.4133\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 4.1975 - mean_squared_error: 4.1975 - val_loss: 46.4298 - val_mean_squared_error: 46.4298\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 3.5479 - mean_squared_error: 3.5479 - val_loss: 39.3728 - val_mean_squared_error: 39.3728\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 3.1701 - mean_squared_error: 3.1701 - val_loss: 33.4033 - val_mean_squared_error: 33.4033\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 3.0408 - mean_squared_error: 3.0408 - val_loss: 28.5327 - val_mean_squared_error: 28.5327\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3.1137 - mean_squared_error: 3.1137 - val_loss: 24.6853 - val_mean_squared_error: 24.6853\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.3088 - mean_squared_error: 3.3088 - val_loss: 21.8145 - val_mean_squared_error: 21.8145\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.5351 - mean_squared_error: 3.5351 - val_loss: 19.7676 - val_mean_squared_error: 19.7676\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.7138 - mean_squared_error: 3.7138 - val_loss: 18.4291 - val_mean_squared_error: 18.4291\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7972 - mean_squared_error: 3.7972 - val_loss: 17.6787 - val_mean_squared_error: 17.6787\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 3.7675 - mean_squared_error: 3.7675 - val_loss: 17.4072 - val_mean_squared_error: 17.4072\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.6326 - mean_squared_error: 3.6326 - val_loss: 17.5290 - val_mean_squared_error: 17.5290\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 3.4287 - mean_squared_error: 3.4287 - val_loss: 17.9836 - val_mean_squared_error: 17.9836\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.1799 - mean_squared_error: 3.1799 - val_loss: 18.7268 - val_mean_squared_error: 18.7268\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2.9343 - mean_squared_error: 2.9343 - val_loss: 19.6804 - val_mean_squared_error: 19.6804\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 2.7186 - mean_squared_error: 2.7186 - val_loss: 20.7687 - val_mean_squared_error: 20.7687\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.5480 - mean_squared_error: 2.5480 - val_loss: 21.9081 - val_mean_squared_error: 21.9081\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.4297 - mean_squared_error: 2.4297 - val_loss: 23.0002 - val_mean_squared_error: 23.0002\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.3540 - mean_squared_error: 2.3540 - val_loss: 23.9601 - val_mean_squared_error: 23.9601\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.3080 - mean_squared_error: 2.3080 - val_loss: 24.7190 - val_mean_squared_error: 24.7190\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2729 - mean_squared_error: 2.2729 - val_loss: 25.2168 - val_mean_squared_error: 25.2168\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2299 - mean_squared_error: 2.2299 - val_loss: 25.4459 - val_mean_squared_error: 25.4459\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.1617 - mean_squared_error: 2.1617 - val_loss: 25.4298 - val_mean_squared_error: 25.4298\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.0673 - mean_squared_error: 2.0673 - val_loss: 25.2260 - val_mean_squared_error: 25.2260\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.9576 - mean_squared_error: 1.9576 - val_loss: 24.8895 - val_mean_squared_error: 24.8895\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.8437 - mean_squared_error: 1.8437 - val_loss: 24.4908 - val_mean_squared_error: 24.4908\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.7395 - mean_squared_error: 1.7395 - val_loss: 24.0791 - val_mean_squared_error: 24.0791\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1.6554 - mean_squared_error: 1.6554 - val_loss: 23.6937 - val_mean_squared_error: 23.6937\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.5977 - mean_squared_error: 1.5977 - val_loss: 23.3773 - val_mean_squared_error: 23.3773\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.5618 - mean_squared_error: 1.5618 - val_loss: 23.1562 - val_mean_squared_error: 23.1562\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.5407 - mean_squared_error: 1.5407 - val_loss: 23.0353 - val_mean_squared_error: 23.0353\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.5225 - mean_squared_error: 1.5225 - val_loss: 23.0077 - val_mean_squared_error: 23.0077\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.4977 - mean_squared_error: 1.4977 - val_loss: 23.0559 - val_mean_squared_error: 23.0559\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.4611 - mean_squared_error: 1.4611 - val_loss: 23.1609 - val_mean_squared_error: 23.1609\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.4118 - mean_squared_error: 1.4118 - val_loss: 23.3035 - val_mean_squared_error: 23.3035\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.3530 - mean_squared_error: 1.3530 - val_loss: 23.4604 - val_mean_squared_error: 23.4604\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.2898 - mean_squared_error: 1.2898 - val_loss: 23.6086 - val_mean_squared_error: 23.6086\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 1.2280 - mean_squared_error: 1.2280 - val_loss: 23.7261 - val_mean_squared_error: 23.7261\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.1721 - mean_squared_error: 1.1721 - val_loss: 23.7927 - val_mean_squared_error: 23.7927\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.1235 - mean_squared_error: 1.1235 - val_loss: 23.7934 - val_mean_squared_error: 23.7934\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0813 - mean_squared_error: 1.0813 - val_loss: 23.7201 - val_mean_squared_error: 23.7201\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0422 - mean_squared_error: 1.0422 - val_loss: 23.5732 - val_mean_squared_error: 23.5732\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.0024 - mean_squared_error: 1.0024 - val_loss: 23.3620 - val_mean_squared_error: 23.3620\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.9590 - mean_squared_error: 0.9590 - val_loss: 23.1038 - val_mean_squared_error: 23.1038\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9114 - mean_squared_error: 0.9114 - val_loss: 22.8225 - val_mean_squared_error: 22.8225\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.8606 - mean_squared_error: 0.8606 - val_loss: 22.5439 - val_mean_squared_error: 22.5439\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8094 - mean_squared_error: 0.8094 - val_loss: 22.2927 - val_mean_squared_error: 22.2927\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7607 - mean_squared_error: 0.7607 - val_loss: 22.0894 - val_mean_squared_error: 22.0894\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7164 - mean_squared_error: 0.7164 - val_loss: 21.9493 - val_mean_squared_error: 21.9493\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6771 - mean_squared_error: 0.6771 - val_loss: 21.8797 - val_mean_squared_error: 21.8797\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.6416 - mean_squared_error: 0.6416 - val_loss: 21.8826 - val_mean_squared_error: 21.8826\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6079 - mean_squared_error: 0.6079 - val_loss: 21.9543 - val_mean_squared_error: 21.9543\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5742 - mean_squared_error: 0.5742 - val_loss: 22.0886 - val_mean_squared_error: 22.0886\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5393 - mean_squared_error: 0.5393 - val_loss: 22.2814 - val_mean_squared_error: 22.2814\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5032 - mean_squared_error: 0.5032 - val_loss: 22.5257 - val_mean_squared_error: 22.5257\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4669 - mean_squared_error: 0.4669 - val_loss: 22.8156 - val_mean_squared_error: 22.8156\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4316 - mean_squared_error: 0.4316 - val_loss: 23.1286 - val_mean_squared_error: 23.1286\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3986 - mean_squared_error: 0.3986 - val_loss: 23.4685 - val_mean_squared_error: 23.4685\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3681 - mean_squared_error: 0.3681 - val_loss: 23.8415 - val_mean_squared_error: 23.8415\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3400 - mean_squared_error: 0.3400 - val_loss: 24.2460 - val_mean_squared_error: 24.2460\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3134 - mean_squared_error: 0.3134 - val_loss: 24.6813 - val_mean_squared_error: 24.6813\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2875 - mean_squared_error: 0.2875 - val_loss: 25.1604 - val_mean_squared_error: 25.1604\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2622 - mean_squared_error: 0.2622 - val_loss: 25.6714 - val_mean_squared_error: 25.6714\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2377 - mean_squared_error: 0.2377 - val_loss: 26.2042 - val_mean_squared_error: 26.2042\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2146 - mean_squared_error: 0.2146 - val_loss: 26.6875 - val_mean_squared_error: 26.6875\n",
      "Mean Squared Error on test set: 12.83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.drop('cv', axis=1)  # Features\n",
    "y = data['cv']               # Target variable\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Deep Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "# Add multiple hidden layers to make it deep\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Output layer for regression (1 neuron, no activation)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c81049-b040-4e6a-943d-66deb1020d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10.45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.drop('cv', axis=1)  # Features\n",
    "y = data['cv']               # Target variable\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train a gradient boosting model\n",
    "model = GradientBoostingRegressor(learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2fae30-55e5-4e9b-9d99-0b44f46f1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[-0.14228773  0.23097992  0.18103433 -0.1794548  -0.2291621   0.17873633\n",
      "  -0.0134089   0.00837946  0.26026273 -0.31612873  0.40984845 -0.13697457\n",
      "  -0.00084341 -0.12880862 -0.21547854 -0.37155998]\n",
      " [-0.2273618  -0.44749045 -0.16939104 -0.15489662  0.49923956  0.2774104\n",
      "   0.15419292  0.2422961  -0.15746343  0.41638255  0.16779017 -0.32647264\n",
      "   0.06560421 -0.28800893 -0.41184103 -0.44949746]\n",
      " [-0.37288237 -0.32915163  0.01651227 -0.06445384 -0.30833793  0.15362978\n",
      "   0.47124386 -0.11557508 -0.05737221  0.2217288   0.34901965 -0.16314995\n",
      "  -0.00805211  0.30972135  0.2597803  -0.37829113]\n",
      " [ 0.42146242 -0.13924325  0.32248342 -0.30105853 -0.45820332  0.2677939\n",
      "  -0.27899337  0.28837264 -0.481686    0.06170845 -0.09427822 -0.05464876\n",
      "   0.36891448 -0.36418557 -0.00064945 -0.48920667]\n",
      " [-0.12956476  0.20435119 -0.39946127  0.23367977 -0.31297803  0.04287601\n",
      "   0.01046765  0.3525555   0.39286125 -0.18087852  0.4251238  -0.32807446\n",
      "   0.28970897 -0.3680675  -0.48786616  0.49409306]\n",
      " [-0.11493146 -0.17050385  0.14826238 -0.13007069  0.41311145 -0.12236726\n",
      "   0.4573927  -0.3558483   0.1287669  -0.39864635  0.39293647 -0.00509906\n",
      "   0.14871287  0.12029767 -0.08730364  0.44719374]\n",
      " [-0.20887601  0.2922436  -0.1921525   0.2579683  -0.3782674   0.03256845\n",
      "  -0.13117671  0.06130362  0.40141845  0.42340314  0.37248456  0.46125305\n",
      "   0.0163244   0.27038944 -0.3480549   0.1026206 ]\n",
      " [ 0.26945293  0.08941936  0.4686272  -0.3857689  -0.41085255 -0.48642397\n",
      "   0.38528442 -0.31649888  0.21903813  0.25443304 -0.382586    0.44632328\n",
      "   0.22821689 -0.06730998 -0.23781419 -0.27181995]]\n",
      "Biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Weights:\n",
      "[[-0.14435303  0.32895744 -0.1370889  -0.4996382   0.14483142 -0.34053946\n",
      "  -0.15237808  0.04643703]\n",
      " [ 0.14983213  0.32368279 -0.02762282 -0.11859024  0.0986166  -0.3228097\n",
      "   0.06358981 -0.01138902]\n",
      " [ 0.02437544 -0.22815347 -0.32856035  0.14454293 -0.01583529 -0.4043963\n",
      "  -0.40034962  0.2522843 ]\n",
      " [ 0.4938439   0.34732938 -0.4841615   0.0506022  -0.22821903 -0.34036624\n",
      "   0.00168061  0.44986582]\n",
      " [-0.05742931  0.367239    0.02441788  0.15787649 -0.40687764 -0.30990458\n",
      "   0.00470865  0.44520557]\n",
      " [ 0.48143208  0.16988981  0.4128778  -0.17111027 -0.47754145  0.18410456\n",
      "   0.03580689 -0.33499265]\n",
      " [-0.0975405  -0.19848073  0.49313366  0.08819091 -0.48745513  0.25734854\n",
      "  -0.3094077  -0.42505896]\n",
      " [ 0.06692088 -0.49180222  0.18459964 -0.19830716  0.3434056   0.42977977\n",
      "  -0.26914942  0.37777305]\n",
      " [-0.00609326 -0.11691761  0.23387933  0.32442296  0.26770973 -0.44133437\n",
      "  -0.21890152  0.10401046]\n",
      " [-0.03487992 -0.3687197  -0.11612201 -0.28964686  0.35687053  0.3122897\n",
      "   0.23634815 -0.40962076]\n",
      " [-0.32186127 -0.05738819 -0.12840176 -0.49938118 -0.22743845 -0.4702717\n",
      "   0.38125682 -0.49483228]\n",
      " [ 0.29685056  0.16585541  0.33482265  0.43765974  0.36808646  0.44851148\n",
      "   0.35658205  0.48053896]\n",
      " [-0.22142875 -0.14606762  0.46054137 -0.4361632   0.11302817 -0.34219646\n",
      "  -0.476254    0.11712718]\n",
      " [-0.4978578  -0.4733292   0.39845896  0.0922929  -0.30537724  0.3948568\n",
      "  -0.03031623  0.05161238]\n",
      " [ 0.42714775 -0.26350534 -0.09469175 -0.06010818  0.2770406   0.15147913\n",
      "   0.20950496  0.3081317 ]\n",
      " [-0.1810683  -0.11235964  0.05579674 -0.41674352 -0.27218378  0.05375791\n",
      "   0.04346573 -0.26916707]]\n",
      "Biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Weights:\n",
      "[[ 0.5577158 ]\n",
      " [-0.0812881 ]\n",
      " [-0.7025656 ]\n",
      " [ 0.21640503]\n",
      " [-0.67959595]\n",
      " [ 0.47837198]\n",
      " [-0.11169696]\n",
      " [ 0.09988201]]\n",
      "Biases:\n",
      "[0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Example ANN Model\n",
    "model = Sequential([\n",
    "    Dense(16, input_dim=8, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# After training the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Extract weights and biases\n",
    "for layer in model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Weights:\\n{weights}\\nBiases:\\n{biases}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d8324a-3856-477b-b1ce-3e106554c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your small CSV\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Define how many times you want to repeat the data\n",
    "repeats = 10  # Adjust the number of repetitions\n",
    "\n",
    "# Repeat the dataset\n",
    "df_expanded = pd.concat([df] * repeats, ignore_index=True)\n",
    "\n",
    "# Save the new larger CSV\n",
    "df_expanded.to_csv(\"large_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257ee210-6105-4ed3-8845-14be7a810e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "def perturb_data(df, noise_level=0.1):\n",
    "    df_perturbed = df.copy()\n",
    "    for column in df.select_dtypes(include=np.number).columns:\n",
    "        noise = np.random.normal(0, noise_level, df[column].shape)\n",
    "        df_perturbed[column] = df[column] + noise\n",
    "    return df_perturbed\n",
    "additional_rows = 1000 \n",
    "expanded_df = df.copy()\n",
    "for _ in range(additional_rows // len(df)): \n",
    "    perturbed_df = perturb_data(df)\n",
    "    expanded_df = pd.concat([expanded_df, perturbed_df], ignore_index=True)\n",
    "expanded_df.to_csv(\"large_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d7f211-cd76-4038-be3f-881107119348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6.02972719401873\n",
      "R²: 0.8711413805992194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(\"cv\", axis=1)\n",
    "y = data[\"cv\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Plot feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_importance(model, importance_type=\"weight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2b3e06-9555-4896-9a47-c37900fc30cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2384925707.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Splitting Criteria:\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Splitting Criteria:\n",
    "\n",
    "XGBoost builds decision trees by selecting splits that maximize a gain metric \n",
    "(e.g., information gain, Gini index, etc.).\n",
    "Features that contribute to significant improvements in splitting the data are\n",
    "assigned higher importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4de5397-8534-41d7-a891-c9923177e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.02972719401873\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(\"cv\", axis=1)\n",
    "y = data[\"cv\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c550ef44-8fee-49e4-a369-774326acd32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation 3.350358100054996\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score=cross_val_score(model,X,y,cv=5,scoring=\"neg_root_mean_squared_error\")\n",
    "print(\"cross validation\",-cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973623fb-1052-4e2a-b7c4-71af30952ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G  -  0.0\n",
      "wL  -  0.7513631\n",
      "wp  -  0.0\n",
      "IP  -  0.0\n",
      "% Clay  -  0.0\n",
      "% Silt  -  0.0\n",
      "% Sand  -  0.0\n",
      "Pressure  -  0.0\n"
     ]
    }
   ],
   "source": [
    "#Feature importance sensitivity analysis\n",
    "import numpy as np\n",
    "for feature in X.columns:\n",
    "    X_copy=X_test.copy()\n",
    "    X_copy[feature]+=np.random.normal(0,0.1,size=X_copy[feature].shape)\n",
    "    y_per=model.predict(X_copy)\n",
    "    sen=np.mean(np.abs(y_per-y_pred))\n",
    "    print(feature ,\" - \", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf0deb4-aa00-4b26-a5e7-a3370c4b8d87",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3716389146.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Feature importance sensitivity analysis is a technique that helps identify the most\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Feature importance sensitivity analysis is a technique that helps identify the most \n",
    "important features in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01a585-dfae-4c78-a56b-d164862f1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging regressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bg_model=BaggingRegressor(estimator = XGBRegressor(),n_estimators=10,random_state=42)\n",
    "bg_model.fit(X_train,y_train)\n",
    "y_pred1=bg_model.predict(X_test)\n",
    "bg_mse=mean_squared_error(y_test,y_pred1,squared=False)\n",
    "print(bg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e92f5-b656-419e-9676-a39e9939ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_model = XGBRegressor(\n",
    "    n_estimators=200, \n",
    "    learning_rate=0.05, \n",
    "    max_depth=4, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8, \n",
    "    random_state=42\n",
    ")\n",
    "boosting_model.fit(X_train, y_train)\n",
    "y_boosting_pred = boosting_model.predict(X_test)\n",
    "boosting_rmse = mean_squared_error(y_test, y_boosting_pred, squared=False)\n",
    "print(f\"Boosting RMSE: {boosting_rmse:.4f}\")\n",
    "\n",
    "# Step 10: Plot Feature Importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_importance(model, importance_type=\"weight\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9d0b77-3746-43ce-aae4-336c29cfa15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ae6599070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_regression(n_samples=1000, n_features=5, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=X.shape[1], activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c718939-9d53-4a4a-b9fa-170bdfff3022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances (Garson): [0.1199988  0.11173499 0.11938599 0.00069652 0.1210194  0.1509683\n",
      " 0.1310856  0.1050675  0.13924736 0.00079549]\n"
     ]
    }
   ],
   "source": [
    "def garson_feature_importance(model):\n",
    "    \"\"\"\n",
    "    Calculates feature importance using the Garson algorithm.\n",
    "    Parameters:\n",
    "        model (keras.Sequential): A trained neural network model.\n",
    "    Returns:\n",
    "        numpy.ndarray: Feature importances.\n",
    "    \"\"\"\n",
    "    weights = [layer.get_weights()[0] for layer in model.layers if len(layer.get_weights()) > 0]\n",
    "\n",
    "    # Extract input-to-hidden and hidden-to-output weights\n",
    "    input_hidden_weights = weights[0]\n",
    "    hidden_output_weights = weights[1]\n",
    "    \n",
    "    # Compute absolute contributions\n",
    "    abs_input_hidden = np.abs(input_hidden_weights)\n",
    "    abs_hidden_output = np.abs(hidden_output_weights)\n",
    "    \n",
    "    # Contribution of each input feature\n",
    "    total_contribution = np.sum(abs_input_hidden, axis=0) * np.sum(abs_hidden_output, axis=1)\n",
    " \n",
    "    feature_importance = total_contribution / np.sum(total_contribution)\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "# Get feature importances\n",
    "importances = garson_feature_importance(model)\n",
    "print(\"Feature Importances (Garson):\", importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009bb5e3-450e-414b-a6d9-533712d037f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11101669 0.13238314 0.29257685 0.20841286 0.25561044]\n"
     ]
    }
   ],
   "source": [
    "def connection_weight_importance(model):\n",
    "    weights=[layer.get_weights()[0] for layer in model.layers if len(layer.get_weights())>0 ]\n",
    "    input_hidden_weights=weights[0]\n",
    "    hidden_output_weights=weights[1]\n",
    "\n",
    "    conection_weight=input_hidden_weights @ hidden_output_weights\n",
    "    feature_importance=np.sum(np.abs(conection_weight),axis=1)\n",
    "    feature_importance/= np.sum(feature_importance)\n",
    "    return feature_importance\n",
    "\n",
    "importance = connection_weight_importance(model)\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d99bd9-0d9a-4b19-80e2-dbd9284a9053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Coefficient Statistics:\n",
      "Feature 1: Mean = 28.8194, Std Dev = 0.4643, 95% CI = [27.9322, 29.7550]\n",
      "Feature 2: Mean = 81.5556, Std Dev = 0.4487, 95% CI = [80.6800, 82.4160]\n",
      "Feature 3: Mean = 31.0941, Std Dev = 0.4796, 95% CI = [30.1814, 32.1073]\n",
      "Feature 4: Mean = 68.6861, Std Dev = 0.4358, 95% CI = [67.8518, 69.5364]\n",
      "Feature 5: Mean = 10.6607, Std Dev = 0.4425, 95% CI = [9.7933, 11.4983]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Temp\\ipykernel_10704\\355315561.py:60: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(results[\"coefs\"], vert=False, labels=feature_names)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def bootstrap_regression(X, y, n_bootstraps=1000):\n",
    "    \"\"\"\n",
    "    Perform bootstrap regression to estimate variability of coefficients.\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Input features.\n",
    "        y (numpy.ndarray): Target values.\n",
    "        n_bootstraps (int): Number of bootstrap samples.\n",
    "    Returns:\n",
    "        dict: Contains mean, std, all coefficients, and confidence intervals.\n",
    "    \"\"\"\n",
    "    coefs = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # Create bootstrap sample\n",
    "        X_resampled, y_resampled = resample(X, y, random_state=i)\n",
    "\n",
    "        # Fit Linear Regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "\n",
    "        # Collect coefficients\n",
    "        coefs.append(model.coef_)\n",
    "\n",
    "    # Convert to numpy array for analysis\n",
    "    coefs = np.array(coefs)\n",
    "\n",
    "    # Calculate mean, std, and confidence intervals\n",
    "    mean_coefs = np.mean(coefs, axis=0)\n",
    "    std_coefs = np.std(coefs, axis=0)\n",
    "    lower_bounds = np.percentile(coefs, 2.5, axis=0)\n",
    "    upper_bounds = np.percentile(coefs, 97.5, axis=0)\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean_coefs,\n",
    "        \"std\": std_coefs,\n",
    "        \"coefs\": coefs,\n",
    "        \"lower_bounds\": lower_bounds,\n",
    "        \"upper_bounds\": upper_bounds\n",
    "    }\n",
    "\n",
    "\n",
    "def visualize_coefficients(results, feature_names=None):\n",
    "    \"\"\"\n",
    "    Visualize coefficient variability using a box plot.\n",
    "    Parameters:\n",
    "        results (dict): Output from bootstrap_regression.\n",
    "        feature_names (list, optional): Names of the features.\n",
    "    \"\"\"\n",
    "    # Generate labels for features\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'Feature {i+1}' for i in range(results['coefs'].shape[1])]\n",
    "\n",
    "    # Box plot for coefficients\n",
    "    plt.boxplot(results[\"coefs\"], vert=False, labels=feature_names)\n",
    "    plt.xlabel('Coefficient Values')\n",
    "    plt.title('Bootstrap Regression Coefficient Variability')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Step 1: Generate synthetic data\n",
    "X, y = make_regression(n_samples=500, n_features=5, noise=10, random_state=42)\n",
    "\n",
    "# Step 2: Perform bootstrap regression\n",
    "results = bootstrap_regression(X, y, n_bootstraps=1000)\n",
    "\n",
    "# Step 3: Display results\n",
    "print(\"Regression Coefficient Statistics:\")\n",
    "for i, (mean, std, low, high) in enumerate(zip(results['mean'], results['std'], results['lower_bounds'], results['upper_bounds'])):\n",
    "    print(f\"Feature {i+1}: Mean = {mean:.4f}, Std Dev = {std:.4f}, 95% CI = [{low:.4f}, {high:.4f}]\")\n",
    "\n",
    "# Step 4: Visualize results\n",
    "visualize_coefficients(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5171f-53d9-464e-bb2e-d8b62703d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "backpropogation, levenberg marqardt(LM) LMNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
