{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3048dea-ca69-4680-ab8e-cd4a51b9890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.6471 - mean_squared_error: 0.2902 - val_loss: 0.4349 - val_mean_squared_error: 0.0805\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.5498 - mean_squared_error: 0.1955 - val_loss: 0.3949 - val_mean_squared_error: 0.0426\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5129 - mean_squared_error: 0.1606 - val_loss: 0.3669 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4751 - mean_squared_error: 0.1247 - val_loss: 0.3602 - val_mean_squared_error: 0.0116\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.4731 - mean_squared_error: 0.1245 - val_loss: 0.3704 - val_mean_squared_error: 0.0235\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3859 - mean_squared_error: 0.0390 - val_loss: 0.3944 - val_mean_squared_error: 0.0491\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4024 - mean_squared_error: 0.0571 - val_loss: 0.4313 - val_mean_squared_error: 0.0876\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3656 - mean_squared_error: 0.0219 - val_loss: 0.4779 - val_mean_squared_error: 0.1357\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3716 - mean_squared_error: 0.0295 - val_loss: 0.5275 - val_mean_squared_error: 0.1869\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3545 - mean_squared_error: 0.0140 - val_loss: 0.5860 - val_mean_squared_error: 0.2471\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3689 - mean_squared_error: 0.0300 - val_loss: 0.6267 - val_mean_squared_error: 0.2894\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3446 - mean_squared_error: 0.0073 - val_loss: 0.6633 - val_mean_squared_error: 0.3277\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3872 - mean_squared_error: 0.0516 - val_loss: 0.6718 - val_mean_squared_error: 0.3378\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3723 - mean_squared_error: 0.0383 - val_loss: 0.6591 - val_mean_squared_error: 0.3268\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3773 - mean_squared_error: 0.0450 - val_loss: 0.6318 - val_mean_squared_error: 0.3011\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3568 - mean_squared_error: 0.0261 - val_loss: 0.5990 - val_mean_squared_error: 0.2699\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3545 - mean_squared_error: 0.0254 - val_loss: 0.5612 - val_mean_squared_error: 0.2337\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3476 - mean_squared_error: 0.0201 - val_loss: 0.5235 - val_mean_squared_error: 0.1977\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3529 - mean_squared_error: 0.0271 - val_loss: 0.4856 - val_mean_squared_error: 0.1614\n",
      "Epoch 20/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3576 - mean_squared_error: 0.0334 - val_loss: 0.4512 - val_mean_squared_error: 0.1287\n",
      "Epoch 21/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3574 - mean_squared_error: 0.0348 - val_loss: 0.4181 - val_mean_squared_error: 0.0972\n",
      "Epoch 22/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3321 - mean_squared_error: 0.0112 - val_loss: 0.3923 - val_mean_squared_error: 0.0729\n",
      "Epoch 23/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3341 - mean_squared_error: 0.0148 - val_loss: 0.3711 - val_mean_squared_error: 0.0533\n",
      "Epoch 24/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3327 - mean_squared_error: 0.0150 - val_loss: 0.3566 - val_mean_squared_error: 0.0405\n",
      "Epoch 25/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3304 - mean_squared_error: 0.0143 - val_loss: 0.3455 - val_mean_squared_error: 0.0310\n",
      "Epoch 26/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3276 - mean_squared_error: 0.0131 - val_loss: 0.3388 - val_mean_squared_error: 0.0258\n",
      "Epoch 27/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3180 - mean_squared_error: 0.0050 - val_loss: 0.3340 - val_mean_squared_error: 0.0227\n",
      "Epoch 28/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3211 - mean_squared_error: 0.0098 - val_loss: 0.3316 - val_mean_squared_error: 0.0219\n",
      "Epoch 29/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.3189 - mean_squared_error: 0.0092 - val_loss: 0.3306 - val_mean_squared_error: 0.0225\n",
      "Epoch 30/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3218 - mean_squared_error: 0.0136 - val_loss: 0.3314 - val_mean_squared_error: 0.0248\n",
      "Epoch 31/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3197 - mean_squared_error: 0.0131 - val_loss: 0.3327 - val_mean_squared_error: 0.0277\n",
      "Epoch 32/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3117 - mean_squared_error: 0.0067 - val_loss: 0.3336 - val_mean_squared_error: 0.0302\n",
      "Epoch 33/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3311 - mean_squared_error: 0.0276 - val_loss: 0.3356 - val_mean_squared_error: 0.0337\n",
      "Epoch 34/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3127 - mean_squared_error: 0.0108 - val_loss: 0.3389 - val_mean_squared_error: 0.0386\n",
      "Epoch 35/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3191 - mean_squared_error: 0.0188 - val_loss: 0.3426 - val_mean_squared_error: 0.0438\n",
      "Epoch 36/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3048 - mean_squared_error: 0.0060 - val_loss: 0.3468 - val_mean_squared_error: 0.0495\n",
      "Epoch 37/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3081 - mean_squared_error: 0.0109 - val_loss: 0.3510 - val_mean_squared_error: 0.0553\n",
      "Epoch 38/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3103 - mean_squared_error: 0.0146 - val_loss: 0.3544 - val_mean_squared_error: 0.0603\n",
      "Epoch 39/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3007 - mean_squared_error: 0.0065 - val_loss: 0.3580 - val_mean_squared_error: 0.0653\n",
      "Epoch 40/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3029 - mean_squared_error: 0.0103 - val_loss: 0.3596 - val_mean_squared_error: 0.0684\n",
      "Epoch 41/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3056 - mean_squared_error: 0.0144 - val_loss: 0.3587 - val_mean_squared_error: 0.0690\n",
      "Epoch 42/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2983 - mean_squared_error: 0.0086 - val_loss: 0.3568 - val_mean_squared_error: 0.0686\n",
      "Epoch 43/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2923 - mean_squared_error: 0.0042 - val_loss: 0.3549 - val_mean_squared_error: 0.0682\n",
      "Epoch 44/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2976 - mean_squared_error: 0.0109 - val_loss: 0.3519 - val_mean_squared_error: 0.0667\n",
      "Epoch 45/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2921 - mean_squared_error: 0.0070 - val_loss: 0.3511 - val_mean_squared_error: 0.0675\n",
      "Epoch 46/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2994 - mean_squared_error: 0.0158 - val_loss: 0.3496 - val_mean_squared_error: 0.0674\n",
      "Epoch 47/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.2991 - mean_squared_error: 0.0170 - val_loss: 0.3439 - val_mean_squared_error: 0.0632\n",
      "Epoch 48/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2963 - mean_squared_error: 0.0156 - val_loss: 0.3369 - val_mean_squared_error: 0.0577\n",
      "Epoch 49/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2868 - mean_squared_error: 0.0076 - val_loss: 0.3302 - val_mean_squared_error: 0.0524\n",
      "Epoch 50/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2825 - mean_squared_error: 0.0047 - val_loss: 0.3246 - val_mean_squared_error: 0.0483\n",
      "Epoch 51/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2866 - mean_squared_error: 0.0103 - val_loss: 0.3213 - val_mean_squared_error: 0.0465\n",
      "Epoch 52/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2772 - mean_squared_error: 0.0023 - val_loss: 0.3187 - val_mean_squared_error: 0.0453\n",
      "Epoch 53/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2759 - mean_squared_error: 0.0025 - val_loss: 0.3173 - val_mean_squared_error: 0.0454\n",
      "Epoch 54/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2754 - mean_squared_error: 0.0035 - val_loss: 0.3167 - val_mean_squared_error: 0.0462\n",
      "Epoch 55/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2797 - mean_squared_error: 0.0092 - val_loss: 0.3151 - val_mean_squared_error: 0.0460\n",
      "Epoch 56/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2749 - mean_squared_error: 0.0058 - val_loss: 0.3133 - val_mean_squared_error: 0.0456\n",
      "Epoch 57/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2738 - mean_squared_error: 0.0061 - val_loss: 0.3109 - val_mean_squared_error: 0.0446\n",
      "Epoch 58/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2775 - mean_squared_error: 0.0113 - val_loss: 0.3086 - val_mean_squared_error: 0.0438\n",
      "Epoch 59/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2718 - mean_squared_error: 0.0069 - val_loss: 0.3066 - val_mean_squared_error: 0.0432\n",
      "Epoch 60/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2722 - mean_squared_error: 0.0088 - val_loss: 0.3054 - val_mean_squared_error: 0.0433\n",
      "Epoch 61/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2673 - mean_squared_error: 0.0053 - val_loss: 0.3053 - val_mean_squared_error: 0.0447\n",
      "Epoch 62/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.2680 - mean_squared_error: 0.0073 - val_loss: 0.3044 - val_mean_squared_error: 0.0451\n",
      "Epoch 63/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2679 - mean_squared_error: 0.0086 - val_loss: 0.3049 - val_mean_squared_error: 0.0470\n",
      "Epoch 64/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2593 - mean_squared_error: 0.0014 - val_loss: 0.3049 - val_mean_squared_error: 0.0483\n",
      "Epoch 65/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2657 - mean_squared_error: 0.0092 - val_loss: 0.3052 - val_mean_squared_error: 0.0500\n",
      "Epoch 66/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2620 - mean_squared_error: 0.0068 - val_loss: 0.3059 - val_mean_squared_error: 0.0521\n",
      "Epoch 67/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2594 - mean_squared_error: 0.0056 - val_loss: 0.3072 - val_mean_squared_error: 0.0546\n",
      "Epoch 68/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2561 - mean_squared_error: 0.0036 - val_loss: 0.3097 - val_mean_squared_error: 0.0585\n",
      "Epoch 69/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2610 - mean_squared_error: 0.0098 - val_loss: 0.3139 - val_mean_squared_error: 0.0640\n",
      "Epoch 70/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2507 - mean_squared_error: 7.6314e-04 - val_loss: 0.3178 - val_mean_squared_error: 0.0692\n",
      "Epoch 71/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2526 - mean_squared_error: 0.0040 - val_loss: 0.3194 - val_mean_squared_error: 0.0721\n",
      "Epoch 72/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2521 - mean_squared_error: 0.0049 - val_loss: 0.3204 - val_mean_squared_error: 0.0744\n",
      "Epoch 73/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2542 - mean_squared_error: 0.0082 - val_loss: 0.3174 - val_mean_squared_error: 0.0728\n",
      "Epoch 74/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2491 - mean_squared_error: 0.0044 - val_loss: 0.3147 - val_mean_squared_error: 0.0713\n",
      "Epoch 75/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.2463 - mean_squared_error: 0.0029 - val_loss: 0.3100 - val_mean_squared_error: 0.0680\n",
      "Epoch 76/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2444 - mean_squared_error: 0.0024 - val_loss: 0.3053 - val_mean_squared_error: 0.0645\n",
      "Epoch 77/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2465 - mean_squared_error: 0.0058 - val_loss: 0.3000 - val_mean_squared_error: 0.0606\n",
      "Epoch 78/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2413 - mean_squared_error: 0.0019 - val_loss: 0.2959 - val_mean_squared_error: 0.0578\n",
      "Epoch 79/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2414 - mean_squared_error: 0.0032 - val_loss: 0.2908 - val_mean_squared_error: 0.0539\n",
      "Epoch 80/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2460 - mean_squared_error: 0.0091 - val_loss: 0.2883 - val_mean_squared_error: 0.0526\n",
      "Epoch 81/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2379 - mean_squared_error: 0.0022 - val_loss: 0.2849 - val_mean_squared_error: 0.0505\n",
      "Epoch 82/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2387 - mean_squared_error: 0.0043 - val_loss: 0.2829 - val_mean_squared_error: 0.0497\n",
      "Epoch 83/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2360 - mean_squared_error: 0.0028 - val_loss: 0.2812 - val_mean_squared_error: 0.0492\n",
      "Epoch 84/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2415 - mean_squared_error: 0.0096 - val_loss: 0.2800 - val_mean_squared_error: 0.0493\n",
      "Epoch 85/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2327 - mean_squared_error: 0.0020 - val_loss: 0.2793 - val_mean_squared_error: 0.0499\n",
      "Epoch 86/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2356 - mean_squared_error: 0.0061 - val_loss: 0.2792 - val_mean_squared_error: 0.0509\n",
      "Epoch 87/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2341 - mean_squared_error: 0.0058 - val_loss: 0.2799 - val_mean_squared_error: 0.0528\n",
      "Epoch 88/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2359 - mean_squared_error: 0.0089 - val_loss: 0.2824 - val_mean_squared_error: 0.0566\n",
      "Epoch 89/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2286 - mean_squared_error: 0.0027 - val_loss: 0.2848 - val_mean_squared_error: 0.0601\n",
      "Epoch 90/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2314 - mean_squared_error: 0.0067 - val_loss: 0.2869 - val_mean_squared_error: 0.0634\n",
      "Epoch 91/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.2250 - mean_squared_error: 0.0015 - val_loss: 0.2897 - val_mean_squared_error: 0.0674\n",
      "Epoch 92/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2289 - mean_squared_error: 0.0066 - val_loss: 0.2911 - val_mean_squared_error: 0.0700\n",
      "Epoch 93/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2267 - mean_squared_error: 0.0056 - val_loss: 0.2898 - val_mean_squared_error: 0.0698\n",
      "Epoch 94/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2241 - mean_squared_error: 0.0042 - val_loss: 0.2866 - val_mean_squared_error: 0.0679\n",
      "Epoch 95/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2211 - mean_squared_error: 0.0023 - val_loss: 0.2823 - val_mean_squared_error: 0.0647\n",
      "Epoch 96/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2200 - mean_squared_error: 0.0024 - val_loss: 0.2769 - val_mean_squared_error: 0.0605\n",
      "Epoch 97/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2182 - mean_squared_error: 0.0017 - val_loss: 0.2727 - val_mean_squared_error: 0.0574\n",
      "Epoch 98/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2185 - mean_squared_error: 0.0032 - val_loss: 0.2693 - val_mean_squared_error: 0.0551\n",
      "Epoch 99/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2156 - mean_squared_error: 0.0015 - val_loss: 0.2670 - val_mean_squared_error: 0.0541\n",
      "Epoch 100/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2168 - mean_squared_error: 0.0039 - val_loss: 0.2663 - val_mean_squared_error: 0.0544\n",
      "Epoch 101/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2140 - mean_squared_error: 0.0021 - val_loss: 0.2646 - val_mean_squared_error: 0.0539\n",
      "Epoch 102/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2120 - mean_squared_error: 0.0013 - val_loss: 0.2631 - val_mean_squared_error: 0.0536\n",
      "Epoch 103/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2115 - mean_squared_error: 0.0019 - val_loss: 0.2618 - val_mean_squared_error: 0.0534\n",
      "Epoch 104/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2110 - mean_squared_error: 0.0026 - val_loss: 0.2611 - val_mean_squared_error: 0.0538\n",
      "Epoch 105/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.2154 - mean_squared_error: 0.0081 - val_loss: 0.2607 - val_mean_squared_error: 0.0545\n",
      "Epoch 106/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2079 - mean_squared_error: 0.0016 - val_loss: 0.2605 - val_mean_squared_error: 0.0554\n",
      "Epoch 107/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2116 - mean_squared_error: 0.0065 - val_loss: 0.2611 - val_mean_squared_error: 0.0570\n",
      "Epoch 108/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2085 - mean_squared_error: 0.0045 - val_loss: 0.2617 - val_mean_squared_error: 0.0587\n",
      "Epoch 109/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2062 - mean_squared_error: 0.0032 - val_loss: 0.2627 - val_mean_squared_error: 0.0608\n",
      "Epoch 110/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2155 - mean_squared_error: 0.0137 - val_loss: 0.2637 - val_mean_squared_error: 0.0629\n",
      "Epoch 111/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2055 - mean_squared_error: 0.0047 - val_loss: 0.2655 - val_mean_squared_error: 0.0658\n",
      "Epoch 112/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2017 - mean_squared_error: 0.0019 - val_loss: 0.2664 - val_mean_squared_error: 0.0677\n",
      "Epoch 113/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2060 - mean_squared_error: 0.0072 - val_loss: 0.2660 - val_mean_squared_error: 0.0683\n",
      "Epoch 114/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.2005 - mean_squared_error: 0.0028 - val_loss: 0.2645 - val_mean_squared_error: 0.0678\n",
      "Epoch 115/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2021 - mean_squared_error: 0.0055 - val_loss: 0.2618 - val_mean_squared_error: 0.0662\n",
      "Epoch 116/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1985 - mean_squared_error: 0.0028 - val_loss: 0.2593 - val_mean_squared_error: 0.0647\n",
      "Epoch 117/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2060 - mean_squared_error: 0.0114 - val_loss: 0.2575 - val_mean_squared_error: 0.0639\n",
      "Epoch 118/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1992 - mean_squared_error: 0.0057 - val_loss: 0.2568 - val_mean_squared_error: 0.0643\n",
      "Epoch 119/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1934 - mean_squared_error: 8.7245e-04 - val_loss: 0.2570 - val_mean_squared_error: 0.0655\n",
      "Epoch 120/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2025 - mean_squared_error: 0.0110 - val_loss: 0.2570 - val_mean_squared_error: 0.0666\n",
      "Epoch 121/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1916 - mean_squared_error: 0.0011 - val_loss: 0.2567 - val_mean_squared_error: 0.0672\n",
      "Epoch 122/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1922 - mean_squared_error: 0.0027 - val_loss: 0.2576 - val_mean_squared_error: 0.0692\n",
      "Epoch 123/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1936 - mean_squared_error: 0.0051 - val_loss: 0.2582 - val_mean_squared_error: 0.0707\n",
      "Epoch 124/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1950 - mean_squared_error: 0.0076 - val_loss: 0.2578 - val_mean_squared_error: 0.0714\n",
      "Epoch 125/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1981 - mean_squared_error: 0.0117 - val_loss: 0.2545 - val_mean_squared_error: 0.0691\n",
      "Epoch 126/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1896 - mean_squared_error: 0.0041 - val_loss: 0.2501 - val_mean_squared_error: 0.0656\n",
      "Epoch 127/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1871 - mean_squared_error: 0.0026 - val_loss: 0.2451 - val_mean_squared_error: 0.0616\n",
      "Epoch 128/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1866 - mean_squared_error: 0.0031 - val_loss: 0.2408 - val_mean_squared_error: 0.0582\n",
      "Epoch 129/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1846 - mean_squared_error: 0.0021 - val_loss: 0.2371 - val_mean_squared_error: 0.0555\n",
      "Epoch 130/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1908 - mean_squared_error: 0.0092 - val_loss: 0.2341 - val_mean_squared_error: 0.0535\n",
      "Epoch 131/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1849 - mean_squared_error: 0.0042 - val_loss: 0.2322 - val_mean_squared_error: 0.0525\n",
      "Epoch 132/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1816 - mean_squared_error: 0.0019 - val_loss: 0.2297 - val_mean_squared_error: 0.0509\n",
      "Epoch 133/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1817 - mean_squared_error: 0.0030 - val_loss: 0.2285 - val_mean_squared_error: 0.0506\n",
      "Epoch 134/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1835 - mean_squared_error: 0.0057 - val_loss: 0.2254 - val_mean_squared_error: 0.0485\n",
      "Epoch 135/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1871 - mean_squared_error: 0.0102 - val_loss: 0.2229 - val_mean_squared_error: 0.0469\n",
      "Epoch 136/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1789 - mean_squared_error: 0.0029 - val_loss: 0.2214 - val_mean_squared_error: 0.0464\n",
      "Epoch 137/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1776 - mean_squared_error: 0.0026 - val_loss: 0.2206 - val_mean_squared_error: 0.0465\n",
      "Epoch 138/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1762 - mean_squared_error: 0.0021 - val_loss: 0.2205 - val_mean_squared_error: 0.0473\n",
      "Epoch 139/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1849 - mean_squared_error: 0.0117 - val_loss: 0.2208 - val_mean_squared_error: 0.0485\n",
      "Epoch 140/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1749 - mean_squared_error: 0.0027 - val_loss: 0.2202 - val_mean_squared_error: 0.0488\n",
      "Epoch 141/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1780 - mean_squared_error: 0.0067 - val_loss: 0.2209 - val_mean_squared_error: 0.0504\n",
      "Epoch 142/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1734 - mean_squared_error: 0.0029 - val_loss: 0.2217 - val_mean_squared_error: 0.0521\n",
      "Epoch 143/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1721 - mean_squared_error: 0.0025 - val_loss: 0.2216 - val_mean_squared_error: 0.0529\n",
      "Epoch 144/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1703 - mean_squared_error: 0.0016 - val_loss: 0.2218 - val_mean_squared_error: 0.0540\n",
      "Epoch 145/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1702 - mean_squared_error: 0.0023 - val_loss: 0.2214 - val_mean_squared_error: 0.0544\n",
      "Epoch 146/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1688 - mean_squared_error: 0.0019 - val_loss: 0.2212 - val_mean_squared_error: 0.0551\n",
      "Epoch 147/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1682 - mean_squared_error: 0.0021 - val_loss: 0.2203 - val_mean_squared_error: 0.0550\n",
      "Epoch 148/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1694 - mean_squared_error: 0.0042 - val_loss: 0.2185 - val_mean_squared_error: 0.0541\n",
      "Epoch 149/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1664 - mean_squared_error: 0.0020 - val_loss: 0.2171 - val_mean_squared_error: 0.0536\n",
      "Epoch 150/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1699 - mean_squared_error: 0.0063 - val_loss: 0.2140 - val_mean_squared_error: 0.0513\n",
      "Epoch 151/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1734 - mean_squared_error: 0.0107 - val_loss: 0.2087 - val_mean_squared_error: 0.0468\n",
      "Epoch 152/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1631 - mean_squared_error: 0.0012 - val_loss: 0.2048 - val_mean_squared_error: 0.0438\n",
      "Epoch 153/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1635 - mean_squared_error: 0.0024 - val_loss: 0.2019 - val_mean_squared_error: 0.0417\n",
      "Epoch 154/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1648 - mean_squared_error: 0.0046 - val_loss: 0.2002 - val_mean_squared_error: 0.0409\n",
      "Epoch 155/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1604 - mean_squared_error: 0.0010 - val_loss: 0.1993 - val_mean_squared_error: 0.0407\n",
      "Epoch 156/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1591 - mean_squared_error: 5.6227e-04 - val_loss: 0.1988 - val_mean_squared_error: 0.0411\n",
      "Epoch 157/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1612 - mean_squared_error: 0.0035 - val_loss: 0.1995 - val_mean_squared_error: 0.0426\n",
      "Epoch 158/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1617 - mean_squared_error: 0.0048 - val_loss: 0.2010 - val_mean_squared_error: 0.0449\n",
      "Epoch 159/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1633 - mean_squared_error: 0.0072 - val_loss: 0.2036 - val_mean_squared_error: 0.0483\n",
      "Epoch 160/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1569 - mean_squared_error: 0.0016 - val_loss: 0.2064 - val_mean_squared_error: 0.0519\n",
      "Epoch 161/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1581 - mean_squared_error: 0.0036 - val_loss: 0.2081 - val_mean_squared_error: 0.0544\n",
      "Epoch 162/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1565 - mean_squared_error: 0.0029 - val_loss: 0.2092 - val_mean_squared_error: 0.0563\n",
      "Epoch 163/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1557 - mean_squared_error: 0.0028 - val_loss: 0.2086 - val_mean_squared_error: 0.0565\n",
      "Epoch 164/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1553 - mean_squared_error: 0.0032 - val_loss: 0.2090 - val_mean_squared_error: 0.0576\n",
      "Epoch 165/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1545 - mean_squared_error: 0.0032 - val_loss: 0.2075 - val_mean_squared_error: 0.0570\n",
      "Epoch 166/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1590 - mean_squared_error: 0.0085 - val_loss: 0.2033 - val_mean_squared_error: 0.0535\n",
      "Epoch 167/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1511 - mean_squared_error: 0.0013 - val_loss: 0.2003 - val_mean_squared_error: 0.0513\n",
      "Epoch 168/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1494 - mean_squared_error: 4.5259e-04 - val_loss: 0.1980 - val_mean_squared_error: 0.0498\n",
      "Epoch 169/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1489 - mean_squared_error: 7.0580e-04 - val_loss: 0.1966 - val_mean_squared_error: 0.0492\n",
      "Epoch 170/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1493 - mean_squared_error: 0.0019 - val_loss: 0.1955 - val_mean_squared_error: 0.0488\n",
      "Epoch 171/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1477 - mean_squared_error: 0.0010 - val_loss: 0.1939 - val_mean_squared_error: 0.0479\n",
      "Epoch 172/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1506 - mean_squared_error: 0.0046 - val_loss: 0.1924 - val_mean_squared_error: 0.0472\n",
      "Epoch 173/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1457 - mean_squared_error: 4.8455e-04 - val_loss: 0.1915 - val_mean_squared_error: 0.0470\n",
      "Epoch 174/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1458 - mean_squared_error: 0.0013 - val_loss: 0.1903 - val_mean_squared_error: 0.0466\n",
      "Epoch 175/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1445 - mean_squared_error: 7.5939e-04 - val_loss: 0.1897 - val_mean_squared_error: 0.0467\n",
      "Epoch 176/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1437 - mean_squared_error: 6.9219e-04 - val_loss: 0.1896 - val_mean_squared_error: 0.0473\n",
      "Epoch 177/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1444 - mean_squared_error: 0.0022 - val_loss: 0.1904 - val_mean_squared_error: 0.0489\n",
      "Epoch 178/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1479 - mean_squared_error: 0.0064 - val_loss: 0.1900 - val_mean_squared_error: 0.0492\n",
      "Epoch 179/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1477 - mean_squared_error: 0.0069 - val_loss: 0.1911 - val_mean_squared_error: 0.0511\n",
      "Epoch 180/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1446 - mean_squared_error: 0.0045 - val_loss: 0.1927 - val_mean_squared_error: 0.0534\n",
      "Epoch 181/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1433 - mean_squared_error: 0.0040 - val_loss: 0.1935 - val_mean_squared_error: 0.0549\n",
      "Epoch 182/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1423 - mean_squared_error: 0.0036 - val_loss: 0.1951 - val_mean_squared_error: 0.0572\n",
      "Epoch 183/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1418 - mean_squared_error: 0.0039 - val_loss: 0.1943 - val_mean_squared_error: 0.0572\n",
      "Epoch 184/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1377 - mean_squared_error: 4.8116e-04 - val_loss: 0.1931 - val_mean_squared_error: 0.0567\n",
      "Epoch 185/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1408 - mean_squared_error: 0.0043 - val_loss: 0.1922 - val_mean_squared_error: 0.0565\n",
      "Epoch 186/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1436 - mean_squared_error: 0.0078 - val_loss: 0.1925 - val_mean_squared_error: 0.0574\n",
      "Epoch 187/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1416 - mean_squared_error: 0.0065 - val_loss: 0.1923 - val_mean_squared_error: 0.0579\n",
      "Epoch 188/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1427 - mean_squared_error: 0.0083 - val_loss: 0.1930 - val_mean_squared_error: 0.0593\n",
      "Epoch 189/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1352 - mean_squared_error: 0.0015 - val_loss: 0.1931 - val_mean_squared_error: 0.0600\n",
      "Epoch 190/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1346 - mean_squared_error: 0.0016 - val_loss: 0.1926 - val_mean_squared_error: 0.0602\n",
      "Epoch 191/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1330 - mean_squared_error: 6.2097e-04 - val_loss: 0.1924 - val_mean_squared_error: 0.0606\n",
      "Epoch 192/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1356 - mean_squared_error: 0.0039 - val_loss: 0.1906 - val_mean_squared_error: 0.0596\n",
      "Epoch 193/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1353 - mean_squared_error: 0.0043 - val_loss: 0.1881 - val_mean_squared_error: 0.0577\n",
      "Epoch 194/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1310 - mean_squared_error: 5.8953e-04 - val_loss: 0.1862 - val_mean_squared_error: 0.0564\n",
      "Epoch 195/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1357 - mean_squared_error: 0.0059 - val_loss: 0.1826 - val_mean_squared_error: 0.0535\n",
      "Epoch 196/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1387 - mean_squared_error: 0.0096 - val_loss: 0.1791 - val_mean_squared_error: 0.0506\n",
      "Epoch 197/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1348 - mean_squared_error: 0.0064 - val_loss: 0.1777 - val_mean_squared_error: 0.0499\n",
      "Epoch 198/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1285 - mean_squared_error: 7.4205e-04 - val_loss: 0.1767 - val_mean_squared_error: 0.0496\n",
      "Epoch 199/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1282 - mean_squared_error: 0.0011 - val_loss: 0.1762 - val_mean_squared_error: 0.0497\n",
      "Epoch 200/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1301 - mean_squared_error: 0.0036 - val_loss: 0.1762 - val_mean_squared_error: 0.0504\n",
      "Epoch 201/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1264 - mean_squared_error: 5.8210e-04 - val_loss: 0.1762 - val_mean_squared_error: 0.0510\n",
      "Epoch 202/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1301 - mean_squared_error: 0.0049 - val_loss: 0.1763 - val_mean_squared_error: 0.0518\n",
      "Epoch 203/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1264 - mean_squared_error: 0.0019 - val_loss: 0.1766 - val_mean_squared_error: 0.0527\n",
      "Epoch 204/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1290 - mean_squared_error: 0.0051 - val_loss: 0.1770 - val_mean_squared_error: 0.0537\n",
      "Epoch 205/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1257 - mean_squared_error: 0.0024 - val_loss: 0.1781 - val_mean_squared_error: 0.0554\n",
      "Epoch 206/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1235 - mean_squared_error: 8.1938e-04 - val_loss: 0.1790 - val_mean_squared_error: 0.0570\n",
      "Epoch 207/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1249 - mean_squared_error: 0.0029 - val_loss: 0.1812 - val_mean_squared_error: 0.0597\n",
      "Epoch 208/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1264 - mean_squared_error: 0.0050 - val_loss: 0.1845 - val_mean_squared_error: 0.0636\n",
      "Epoch 209/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1221 - mean_squared_error: 0.0012 - val_loss: 0.1875 - val_mean_squared_error: 0.0672\n",
      "Epoch 210/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1264 - mean_squared_error: 0.0062 - val_loss: 0.1899 - val_mean_squared_error: 0.0702\n",
      "Epoch 211/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1210 - mean_squared_error: 0.0013 - val_loss: 0.1919 - val_mean_squared_error: 0.0728\n",
      "Epoch 212/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1235 - mean_squared_error: 0.0044 - val_loss: 0.1928 - val_mean_squared_error: 0.0743\n",
      "Epoch 213/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1200 - mean_squared_error: 0.0015 - val_loss: 0.1946 - val_mean_squared_error: 0.0767\n",
      "Epoch 214/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1208 - mean_squared_error: 0.0029 - val_loss: 0.1939 - val_mean_squared_error: 0.0765\n",
      "Epoch 215/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1205 - mean_squared_error: 0.0031 - val_loss: 0.1930 - val_mean_squared_error: 0.0763\n",
      "Epoch 216/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1172 - mean_squared_error: 4.3836e-04 - val_loss: 0.1919 - val_mean_squared_error: 0.0757\n",
      "Epoch 217/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1203 - mean_squared_error: 0.0041 - val_loss: 0.1890 - val_mean_squared_error: 0.0734\n",
      "Epoch 218/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1167 - mean_squared_error: 0.0011 - val_loss: 0.1856 - val_mean_squared_error: 0.0706\n",
      "Epoch 219/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1165 - mean_squared_error: 0.0014 - val_loss: 0.1824 - val_mean_squared_error: 0.0680\n",
      "Mean Squared Error on test set: 0.04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      "Predictions vs Actual:\n",
      "   Actual  Predicted\n",
      "0    0.70   0.685623\n",
      "1    0.50   0.529537\n",
      "2   15.11  22.173840\n",
      "3    0.20   0.291533\n",
      "4    5.30   9.487015\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load and Prepare the Data\n",
    "data = pd.read_csv('data.csv')  # Load the dataset\n",
    "X = data.drop('cv', axis=1)  # Features\n",
    "y = data['cv']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Target Scaling\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Define the Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "# Compile the Model with Adam Optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# Early Stopping Callback to Avoid Overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=300,\n",
    "                    batch_size=8,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the Model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Denormalize Predictions and Actual Values\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred)\n",
    "y_test_original = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Display Predictions vs Actual\n",
    "results = pd.DataFrame({'Actual': y_test_original.flatten(), 'Predicted': y_pred_original.flatten()})\n",
    "print(\"\\nPredictions vs Actual:\")\n",
    "print(results.head())\n",
    "\n",
    "# Visualize Predictions vs Actual Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_original, label='Actual')\n",
    "plt.plot(y_pred_original, label='Predicted', linestyle='--')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('cv')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca2344-9b62-4e68-9cd8-3bb1040d2a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1310c-3380-483f-bafa-d8a499395572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. Load the saved Keras model\n",
    "model = load_model('keras_model.h5')\n",
    "\n",
    "# 2. Load the CSV file\n",
    "# Replace 'input_data.csv' with your actual file name\n",
    "data = pd.read_csv('input_data.csv')\n",
    "\n",
    "# Preview the loaded data\n",
    "print(\"Input Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# 3. Preprocess the data\n",
    "# Ensure the data has the same columns/features as the model was trained on\n",
    "# Example: Drop unnecessary columns or perform scaling if needed\n",
    "# Assuming the model was trained on specific columns ['feature1', 'feature2', ..., 'featureN']\n",
    "input_features = data[['feature1', 'feature2', 'feature3']]  # Update with actual column names\n",
    "\n",
    "# 4. Make predictions\n",
    "predictions = model.predict(input_features)\n",
    "\n",
    "# 5. Save the predictions to a new CSV file\n",
    "output_data = data.copy()\n",
    "output_data['Predicted_Values'] = predictions  # Add predictions as a new column\n",
    "\n",
    "# Save the updated data with predictions\n",
    "output_data.to_csv('output_with_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'output_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6531378-9d3e-47f3-87a1-4a6afa964723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.6596 - mse: 1.1035 - val_loss: 0.5671 - val_mse: 0.8808 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6338 - mse: 1.2942 - val_loss: 0.5258 - val_mse: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5323 - mse: 0.9998 - val_loss: 0.5156 - val_mse: 0.8428 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5329 - mse: 1.0018 - val_loss: 0.5087 - val_mse: 0.7776 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5033 - mse: 0.9195 - val_loss: 0.5231 - val_mse: 0.7374 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4997 - mse: 0.8531 - val_loss: 0.5150 - val_mse: 0.7219 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5402 - mse: 1.0284 - val_loss: 0.5070 - val_mse: 0.7196 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5106 - mse: 0.9324 - val_loss: 0.5096 - val_mse: 0.7191 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4849 - mse: 0.8583 - val_loss: 0.5090 - val_mse: 0.7189 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4980 - mse: 0.9007 - val_loss: 0.4989 - val_mse: 0.6914 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4887 - mse: 0.8643 - val_loss: 0.4917 - val_mse: 0.6511 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4527 - mse: 0.7456 - val_loss: 0.4860 - val_mse: 0.6265 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5228 - mse: 0.9280 - val_loss: 0.4778 - val_mse: 0.6230 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5042 - mse: 0.8651 - val_loss: 0.4721 - val_mse: 0.6242 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5356 - mse: 0.9821 - val_loss: 0.4759 - val_mse: 0.6127 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4972 - mse: 0.8732 - val_loss: 0.4744 - val_mse: 0.6083 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4404 - mse: 0.6719 - val_loss: 0.4687 - val_mse: 0.6279 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4591 - mse: 0.7537 - val_loss: 0.4710 - val_mse: 0.6600 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5191 - mse: 0.9268 - val_loss: 0.4637 - val_mse: 0.6503 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4551 - mse: 0.8359 - val_loss: 0.4501 - val_mse: 0.6242 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4040 - mse: 0.6173 - val_loss: 0.4571 - val_mse: 0.5928 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4772 - mse: 0.7249 - val_loss: 0.4679 - val_mse: 0.5767 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3932 - mse: 0.5339 - val_loss: 0.4557 - val_mse: 0.5828 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4126 - mse: 0.6157 - val_loss: 0.4460 - val_mse: 0.6006 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4375 - mse: 0.7268 - val_loss: 0.4404 - val_mse: 0.6005 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4113 - mse: 0.6667 - val_loss: 0.4452 - val_mse: 0.5780 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4360 - mse: 0.6962 - val_loss: 0.4532 - val_mse: 0.5450 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4335 - mse: 0.6076 - val_loss: 0.4455 - val_mse: 0.5271 - learning_rate: 0.0010\n",
      "Epoch 29/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4252 - mse: 0.6753 - val_loss: 0.4335 - val_mse: 0.5150 - learning_rate: 0.0010\n",
      "Epoch 30/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4402 - mse: 0.6279 - val_loss: 0.4245 - val_mse: 0.5231 - learning_rate: 0.0010\n",
      "Epoch 31/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3591 - mse: 0.4669 - val_loss: 0.4263 - val_mse: 0.5393 - learning_rate: 0.0010\n",
      "Epoch 32/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4366 - mse: 0.6520 - val_loss: 0.4163 - val_mse: 0.5305 - learning_rate: 0.0010\n",
      "Epoch 33/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3956 - mse: 0.5793 - val_loss: 0.4158 - val_mse: 0.5271 - learning_rate: 0.0010\n",
      "Epoch 34/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4100 - mse: 0.5556 - val_loss: 0.4221 - val_mse: 0.5217 - learning_rate: 0.0010\n",
      "Epoch 35/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4193 - mse: 0.5593 - val_loss: 0.4105 - val_mse: 0.5255 - learning_rate: 0.0010\n",
      "Epoch 36/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4657 - mse: 0.7411 - val_loss: 0.4009 - val_mse: 0.5375 - learning_rate: 0.0010\n",
      "Epoch 37/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3623 - mse: 0.5143 - val_loss: 0.4112 - val_mse: 0.5591 - learning_rate: 0.0010\n",
      "Epoch 38/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3882 - mse: 0.5870 - val_loss: 0.4142 - val_mse: 0.5375 - learning_rate: 0.0010\n",
      "Epoch 39/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3737 - mse: 0.5741 - val_loss: 0.4074 - val_mse: 0.4828 - learning_rate: 0.0010\n",
      "Epoch 40/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4205 - mse: 0.5808 - val_loss: 0.3988 - val_mse: 0.4542 - learning_rate: 0.0010\n",
      "Epoch 41/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4084 - mse: 0.5430 - val_loss: 0.3920 - val_mse: 0.4634 - learning_rate: 0.0010\n",
      "Epoch 42/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3654 - mse: 0.4740 - val_loss: 0.3869 - val_mse: 0.4631 - learning_rate: 0.0010\n",
      "Epoch 43/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3285 - mse: 0.4128 - val_loss: 0.3811 - val_mse: 0.4601 - learning_rate: 0.0010\n",
      "Epoch 44/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3826 - mse: 0.5030 - val_loss: 0.3832 - val_mse: 0.4604 - learning_rate: 0.0010\n",
      "Epoch 45/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4071 - mse: 0.5773 - val_loss: 0.3804 - val_mse: 0.4787 - learning_rate: 0.0010\n",
      "Epoch 46/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3944 - mse: 0.5897 - val_loss: 0.3735 - val_mse: 0.5394 - learning_rate: 0.0010\n",
      "Epoch 47/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3440 - mse: 0.4867 - val_loss: 0.3615 - val_mse: 0.5112 - learning_rate: 0.0010\n",
      "Epoch 48/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3344 - mse: 0.4656 - val_loss: 0.3531 - val_mse: 0.4664 - learning_rate: 0.0010\n",
      "Epoch 49/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3513 - mse: 0.4777 - val_loss: 0.3589 - val_mse: 0.4398 - learning_rate: 0.0010\n",
      "Epoch 50/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3546 - mse: 0.4414 - val_loss: 0.3695 - val_mse: 0.4170 - learning_rate: 0.0010\n",
      "Epoch 51/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3649 - mse: 0.4502 - val_loss: 0.3707 - val_mse: 0.4105 - learning_rate: 0.0010\n",
      "Epoch 52/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3761 - mse: 0.4446 - val_loss: 0.3715 - val_mse: 0.4335 - learning_rate: 0.0010\n",
      "Epoch 53/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3656 - mse: 0.4603 - val_loss: 0.3645 - val_mse: 0.4451 - learning_rate: 0.0010\n",
      "Epoch 54/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3188 - mse: 0.3364 - val_loss: 0.3506 - val_mse: 0.4323 - learning_rate: 5.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3109 - mse: 0.3450 - val_loss: 0.3415 - val_mse: 0.4132 - learning_rate: 5.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3820 - mse: 0.4749 - val_loss: 0.3364 - val_mse: 0.3843 - learning_rate: 5.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3531 - mse: 0.4055 - val_loss: 0.3338 - val_mse: 0.3678 - learning_rate: 5.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3128 - mse: 0.3274 - val_loss: 0.3346 - val_mse: 0.3748 - learning_rate: 5.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3335 - mse: 0.4017 - val_loss: 0.3367 - val_mse: 0.3651 - learning_rate: 5.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3198 - mse: 0.3414 - val_loss: 0.3348 - val_mse: 0.3535 - learning_rate: 5.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3081 - mse: 0.3313 - val_loss: 0.3335 - val_mse: 0.3658 - learning_rate: 5.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3184 - mse: 0.3882 - val_loss: 0.3324 - val_mse: 0.3676 - learning_rate: 5.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3101 - mse: 0.3713 - val_loss: 0.3291 - val_mse: 0.3780 - learning_rate: 5.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2898 - mse: 0.2865 - val_loss: 0.3327 - val_mse: 0.4021 - learning_rate: 5.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3300 - mse: 0.3830 - val_loss: 0.3189 - val_mse: 0.3692 - learning_rate: 5.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2920 - mse: 0.2906 - val_loss: 0.3112 - val_mse: 0.3239 - learning_rate: 5.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2542 - mse: 0.2015 - val_loss: 0.3094 - val_mse: 0.2984 - learning_rate: 5.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3436 - mse: 0.4101 - val_loss: 0.3045 - val_mse: 0.2843 - learning_rate: 5.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3514 - mse: 0.3412 - val_loss: 0.2976 - val_mse: 0.2732 - learning_rate: 5.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2878 - mse: 0.2496 - val_loss: 0.2948 - val_mse: 0.2714 - learning_rate: 5.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3009 - mse: 0.2927 - val_loss: 0.2934 - val_mse: 0.2712 - learning_rate: 5.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3278 - mse: 0.3063 - val_loss: 0.2927 - val_mse: 0.2768 - learning_rate: 5.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2926 - mse: 0.2822 - val_loss: 0.3044 - val_mse: 0.3104 - learning_rate: 5.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3172 - mse: 0.3343 - val_loss: 0.3213 - val_mse: 0.3322 - learning_rate: 5.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2926 - mse: 0.2802 - val_loss: 0.3252 - val_mse: 0.3284 - learning_rate: 5.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2456 - mse: 0.2226 - val_loss: 0.3105 - val_mse: 0.2962 - learning_rate: 5.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2871 - mse: 0.2767 - val_loss: 0.3008 - val_mse: 0.2699 - learning_rate: 5.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3335 - mse: 0.3380 - val_loss: 0.3007 - val_mse: 0.2669 - learning_rate: 2.5000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2844 - mse: 0.2230 - val_loss: 0.2987 - val_mse: 0.2583 - learning_rate: 2.5000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2693 - mse: 0.2171 - val_loss: 0.2985 - val_mse: 0.2531 - learning_rate: 2.5000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2806 - mse: 0.2049 - val_loss: 0.2952 - val_mse: 0.2619 - learning_rate: 2.5000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2684 - mse: 0.2234 - val_loss: 0.2926 - val_mse: 0.2602 - learning_rate: 2.5000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2810 - mse: 0.2190 - val_loss: 0.2909 - val_mse: 0.2581 - learning_rate: 1.2500e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2855 - mse: 0.2149 - val_loss: 0.2894 - val_mse: 0.2559 - learning_rate: 1.2500e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2602 - mse: 0.2014 - val_loss: 0.2874 - val_mse: 0.2520 - learning_rate: 1.2500e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2637 - mse: 0.2125 - val_loss: 0.2856 - val_mse: 0.2494 - learning_rate: 1.2500e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2617 - mse: 0.2088 - val_loss: 0.2846 - val_mse: 0.2467 - learning_rate: 1.2500e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2981 - mse: 0.2810 - val_loss: 0.2832 - val_mse: 0.2450 - learning_rate: 1.2500e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2440 - mse: 0.2040 - val_loss: 0.2828 - val_mse: 0.2473 - learning_rate: 1.2500e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2833 - mse: 0.2593 - val_loss: 0.2831 - val_mse: 0.2476 - learning_rate: 1.2500e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2560 - mse: 0.1968 - val_loss: 0.2835 - val_mse: 0.2477 - learning_rate: 1.2500e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2685 - mse: 0.2095 - val_loss: 0.2816 - val_mse: 0.2440 - learning_rate: 1.2500e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2970 - mse: 0.3019 - val_loss: 0.2814 - val_mse: 0.2432 - learning_rate: 1.2500e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2612 - mse: 0.2094 - val_loss: 0.2815 - val_mse: 0.2391 - learning_rate: 1.2500e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2533 - mse: 0.2287 - val_loss: 0.2816 - val_mse: 0.2360 - learning_rate: 1.2500e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2842 - mse: 0.2532 - val_loss: 0.2806 - val_mse: 0.2326 - learning_rate: 1.2500e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2777 - mse: 0.2321 - val_loss: 0.2782 - val_mse: 0.2284 - learning_rate: 1.2500e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2576 - mse: 0.1790 - val_loss: 0.2761 - val_mse: 0.2246 - learning_rate: 1.2500e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2418 - mse: 0.1666 - val_loss: 0.2749 - val_mse: 0.2254 - learning_rate: 1.2500e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2222 - mse: 0.1435 - val_loss: 0.2746 - val_mse: 0.2260 - learning_rate: 1.2500e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2496 - mse: 0.1836 - val_loss: 0.2771 - val_mse: 0.2309 - learning_rate: 1.2500e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2613 - mse: 0.2025 - val_loss: 0.2799 - val_mse: 0.2357 - learning_rate: 1.2500e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2524 - mse: 0.1969 - val_loss: 0.2809 - val_mse: 0.2365 - learning_rate: 1.2500e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2754 - mse: 0.2221 - val_loss: 0.2815 - val_mse: 0.2367 - learning_rate: 1.2500e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2584 - mse: 0.2093 - val_loss: 0.2795 - val_mse: 0.2319 - learning_rate: 1.2500e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2082 - mse: 0.1720 - val_loss: 0.2781 - val_mse: 0.2274 - learning_rate: 6.2500e-05\n",
      "Epoch 107/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2608 - mse: 0.2046 - val_loss: 0.2785 - val_mse: 0.2256 - learning_rate: 6.2500e-05\n",
      "Epoch 108/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2509 - mse: 0.2152 - val_loss: 0.2785 - val_mse: 0.2237 - learning_rate: 6.2500e-05\n",
      "Epoch 109/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2563 - mse: 0.1904 - val_loss: 0.2782 - val_mse: 0.2218 - learning_rate: 6.2500e-05\n",
      "Epoch 110/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2566 - mse: 0.2099 - val_loss: 0.2778 - val_mse: 0.2224 - learning_rate: 6.2500e-05\n",
      "Epoch 111/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2617 - mse: 0.1917 - val_loss: 0.2777 - val_mse: 0.2230 - learning_rate: 3.1250e-05\n",
      "Epoch 112/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2582 - mse: 0.2144 - val_loss: 0.2774 - val_mse: 0.2241 - learning_rate: 3.1250e-05\n",
      "Epoch 113/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2675 - mse: 0.2550 - val_loss: 0.2771 - val_mse: 0.2249 - learning_rate: 3.1250e-05\n",
      "Epoch 114/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2997 - mse: 0.2647 - val_loss: 0.2769 - val_mse: 0.2261 - learning_rate: 3.1250e-05\n",
      "Epoch 115/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2616 - mse: 0.1812 - val_loss: 0.2768 - val_mse: 0.2272 - learning_rate: 3.1250e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2746 - mse: 0.2260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Test MAE: 0.9301104242114037, R2 Score: 0.7536943705333322\n",
      "Custom Accuracy (within ±10% tolerance): 11.11%\n",
      "   Predicted Value  Actual Value\n",
      "0         0.267309      0.873547\n",
      "1         0.267251      0.220000\n",
      "2         5.728942      6.890951\n",
      "3         6.754466     12.152283\n",
      "4         0.587422      0.340000\n",
      "5         0.342820      0.440278\n",
      "6         0.485341      0.370000\n",
      "7         1.073821      0.360000\n",
      "8         0.441247      0.140000\n",
      "9         0.601355      0.266344\n"
     ]
    }
   ],
   "source": [
    "#ffnn\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data1.csv')  # Replace with your dataset path\n",
    "X = data.drop('Cv', axis=1)\n",
    "y = data['Cv']\n",
    "\n",
    "# Handle possible outliers in the target\n",
    "y = np.clip(y, y.quantile(0.05), y.quantile(0.95))  # Limit to 5th-95th percentile\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale the target variable\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Build the FFNN model without backpropagation\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1]))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "# Get the model's weights directly and propagate forward (no training)\n",
    "model.set_weights([np.random.randn(*w.shape) for w in model.get_weights()])  # Initialize weights manually (random initialization)\n",
    "\n",
    "# Forward pass to make predictions (no backpropagation)\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Reverse scaling to original range for predictions and actual values\n",
    "predictions_original = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate R2 Score and Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test_original, predictions_original)\n",
    "r2 = r2_score(y_test_original, predictions_original)\n",
    "\n",
    "print(f\"Test MAE: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# Combine predictions with actual values\n",
    "results = np.concatenate(\n",
    "    (predictions_original.reshape(-1, 1), y_test_original.reshape(-1, 1)),\n",
    "    axis=1\n",
    ")\n",
    "results_df = pd.DataFrame(results, columns=['Predicted Value', 'Actual Value'])\n",
    "\n",
    "# Calculate custom accuracy (e.g., within ±10% tolerance)\n",
    "tolerance = 0.1  # 10% tolerance\n",
    "correct_predictions = np.abs(predictions_original - y_test_original) <= tolerance * y_test_original\n",
    "accuracy = np.sum(correct_predictions) / len(y_test_original) * 100\n",
    "\n",
    "# Display predictions and accuracy\n",
    "print(f\"Custom Accuracy (within ±10% tolerance): {accuracy:.2f}%\")\n",
    "print(results_df.head(10))  # Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a8bc0c-c88b-476c-903f-0850355ba2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 4.1829 - mse: 3.4926 - val_loss: 3.3830 - val_mse: 0.8924 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.4743 - mse: 4.8820 - val_loss: 3.3851 - val_mse: 0.8686 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.3040 - mse: 3.8629 - val_loss: 3.3932 - val_mse: 0.8683 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1747 - mse: 3.4133 - val_loss: 3.3842 - val_mse: 0.8501 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1287 - mse: 3.1544 - val_loss: 3.3705 - val_mse: 0.8276 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0417 - mse: 3.1230 - val_loss: 3.3592 - val_mse: 0.8030 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0828 - mse: 2.9950 - val_loss: 3.3493 - val_mse: 0.7924 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.9872 - mse: 2.9758 - val_loss: 3.3450 - val_mse: 0.7879 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8845 - mse: 2.5064 - val_loss: 3.3267 - val_mse: 0.7699 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0526 - mse: 3.1606 - val_loss: 3.3153 - val_mse: 0.7678 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7610 - mse: 2.0998 - val_loss: 3.3106 - val_mse: 0.7683 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6956 - mse: 1.9986 - val_loss: 3.2959 - val_mse: 0.7597 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7234 - mse: 2.2785 - val_loss: 3.2841 - val_mse: 0.7604 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7161 - mse: 2.1285 - val_loss: 3.2760 - val_mse: 0.7626 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6932 - mse: 2.0438 - val_loss: 3.2720 - val_mse: 0.7698 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9387 - mse: 3.1945 - val_loss: 3.2619 - val_mse: 0.7680 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7544 - mse: 2.3931 - val_loss: 3.2541 - val_mse: 0.7668 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6057 - mse: 1.9358 - val_loss: 3.2397 - val_mse: 0.7611 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6468 - mse: 1.8972 - val_loss: 3.2228 - val_mse: 0.7488 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7145 - mse: 2.1735 - val_loss: 3.2008 - val_mse: 0.7271 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.6228 - mse: 2.0497 - val_loss: 3.1732 - val_mse: 0.7010 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6052 - mse: 2.2385 - val_loss: 3.1542 - val_mse: 0.6855 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5940 - mse: 1.7821 - val_loss: 3.1411 - val_mse: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5754 - mse: 1.8990 - val_loss: 3.1285 - val_mse: 0.6810 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5066 - mse: 1.9374 - val_loss: 3.1170 - val_mse: 0.6822 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5172 - mse: 1.8770 - val_loss: 3.1037 - val_mse: 0.6812 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4384 - mse: 1.7683 - val_loss: 3.0851 - val_mse: 0.6722 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5667 - mse: 1.8834 - val_loss: 3.0693 - val_mse: 0.6665 - learning_rate: 0.0010\n",
      "Epoch 29/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6830 - mse: 2.7245 - val_loss: 3.0623 - val_mse: 0.6678 - learning_rate: 0.0010\n",
      "Epoch 30/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3356 - mse: 1.3948 - val_loss: 3.0536 - val_mse: 0.6742 - learning_rate: 0.0010\n",
      "Epoch 31/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.4972 - mse: 1.8403 - val_loss: 3.0408 - val_mse: 0.6868 - learning_rate: 0.0010\n",
      "Epoch 32/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.5121 - mse: 2.0670 - val_loss: 3.0165 - val_mse: 0.6922 - learning_rate: 0.0010\n",
      "Epoch 33/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.3719 - mse: 1.5709 - val_loss: 2.9995 - val_mse: 0.7007 - learning_rate: 0.0010\n",
      "Epoch 34/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3891 - mse: 1.5697 - val_loss: 2.9765 - val_mse: 0.7042 - learning_rate: 0.0010\n",
      "Epoch 35/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3773 - mse: 1.6618 - val_loss: 2.9618 - val_mse: 0.7124 - learning_rate: 0.0010\n",
      "Epoch 36/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4193 - mse: 1.7665 - val_loss: 2.9560 - val_mse: 0.7042 - learning_rate: 0.0010\n",
      "Epoch 37/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3920 - mse: 1.9469 - val_loss: 2.9414 - val_mse: 0.6856 - learning_rate: 0.0010\n",
      "Epoch 38/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3907 - mse: 1.7717 - val_loss: 2.9269 - val_mse: 0.6714 - learning_rate: 0.0010\n",
      "Epoch 39/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2347 - mse: 1.3454 - val_loss: 2.9201 - val_mse: 0.6685 - learning_rate: 0.0010\n",
      "Epoch 40/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2617 - mse: 1.4522 - val_loss: 2.9201 - val_mse: 0.6699 - learning_rate: 0.0010\n",
      "Epoch 41/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2864 - mse: 1.4845 - val_loss: 2.9176 - val_mse: 0.6686 - learning_rate: 0.0010\n",
      "Epoch 42/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3805 - mse: 1.8542 - val_loss: 2.9098 - val_mse: 0.6645 - learning_rate: 0.0010\n",
      "Epoch 43/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1956 - mse: 1.4610 - val_loss: 2.8976 - val_mse: 0.6572 - learning_rate: 0.0010\n",
      "Epoch 44/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2277 - mse: 1.4190 - val_loss: 2.8878 - val_mse: 0.6526 - learning_rate: 0.0010\n",
      "Epoch 45/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.2734 - mse: 1.5463 - val_loss: 2.8763 - val_mse: 0.6512 - learning_rate: 0.0010\n",
      "Epoch 46/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1342 - mse: 1.2210 - val_loss: 2.8655 - val_mse: 0.6533 - learning_rate: 0.0010\n",
      "Epoch 47/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1546 - mse: 1.3488 - val_loss: 2.8551 - val_mse: 0.6592 - learning_rate: 0.0010\n",
      "Epoch 48/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1044 - mse: 1.2823 - val_loss: 2.8469 - val_mse: 0.6525 - learning_rate: 0.0010\n",
      "Epoch 49/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.1197 - mse: 1.5235 - val_loss: 2.8316 - val_mse: 0.6392 - learning_rate: 0.0010\n",
      "Epoch 50/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1947 - mse: 1.5215 - val_loss: 2.8193 - val_mse: 0.6288 - learning_rate: 0.0010\n",
      "Epoch 51/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.0345 - mse: 1.2854 - val_loss: 2.8000 - val_mse: 0.6218 - learning_rate: 0.0010\n",
      "Epoch 52/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0884 - mse: 1.4405 - val_loss: 2.7781 - val_mse: 0.6184 - learning_rate: 0.0010\n",
      "Epoch 53/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.0746 - mse: 1.3926 - val_loss: 2.7481 - val_mse: 0.6090 - learning_rate: 0.0010\n",
      "Epoch 54/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8971 - mse: 0.8731 - val_loss: 2.7283 - val_mse: 0.5971 - learning_rate: 0.0010\n",
      "Epoch 55/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9108 - mse: 0.9772 - val_loss: 2.7144 - val_mse: 0.5905 - learning_rate: 0.0010\n",
      "Epoch 56/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1080 - mse: 1.4333 - val_loss: 2.7117 - val_mse: 0.5911 - learning_rate: 0.0010\n",
      "Epoch 57/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9867 - mse: 1.4534 - val_loss: 2.7116 - val_mse: 0.6045 - learning_rate: 0.0010\n",
      "Epoch 58/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9167 - mse: 1.0572 - val_loss: 2.7107 - val_mse: 0.6197 - learning_rate: 0.0010\n",
      "Epoch 59/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8911 - mse: 0.9604 - val_loss: 2.7150 - val_mse: 0.6355 - learning_rate: 0.0010\n",
      "Epoch 60/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9311 - mse: 1.0914 - val_loss: 2.7072 - val_mse: 0.6353 - learning_rate: 0.0010\n",
      "Epoch 61/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9660 - mse: 1.2144 - val_loss: 2.6941 - val_mse: 0.6225 - learning_rate: 0.0010\n",
      "Epoch 62/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8667 - mse: 0.9986 - val_loss: 2.6771 - val_mse: 0.6096 - learning_rate: 0.0010\n",
      "Epoch 63/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9591 - mse: 1.2911 - val_loss: 2.6664 - val_mse: 0.6015 - learning_rate: 0.0010\n",
      "Epoch 64/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8249 - mse: 0.9029 - val_loss: 2.6631 - val_mse: 0.6104 - learning_rate: 0.0010\n",
      "Epoch 65/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.8050 - mse: 0.9840 - val_loss: 2.6534 - val_mse: 0.6120 - learning_rate: 0.0010\n",
      "Epoch 66/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9339 - mse: 1.3819 - val_loss: 2.6334 - val_mse: 0.6095 - learning_rate: 0.0010\n",
      "Epoch 67/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9055 - mse: 1.3569 - val_loss: 2.6155 - val_mse: 0.5927 - learning_rate: 0.0010\n",
      "Epoch 68/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8194 - mse: 1.0519 - val_loss: 2.6024 - val_mse: 0.5821 - learning_rate: 0.0010\n",
      "Epoch 69/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8615 - mse: 1.1588 - val_loss: 2.5825 - val_mse: 0.5703 - learning_rate: 0.0010\n",
      "Epoch 70/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8957 - mse: 1.4202 - val_loss: 2.5677 - val_mse: 0.5693 - learning_rate: 0.0010\n",
      "Epoch 71/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7611 - mse: 1.0226 - val_loss: 2.5551 - val_mse: 0.5711 - learning_rate: 0.0010\n",
      "Epoch 72/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7989 - mse: 1.0450 - val_loss: 2.5436 - val_mse: 0.5803 - learning_rate: 0.0010\n",
      "Epoch 73/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7765 - mse: 1.1103 - val_loss: 2.5290 - val_mse: 0.5885 - learning_rate: 0.0010\n",
      "Epoch 74/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8220 - mse: 1.1958 - val_loss: 2.5085 - val_mse: 0.5762 - learning_rate: 0.0010\n",
      "Epoch 75/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7701 - mse: 1.1286 - val_loss: 2.4964 - val_mse: 0.5741 - learning_rate: 0.0010\n",
      "Epoch 76/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7718 - mse: 1.1493 - val_loss: 2.4838 - val_mse: 0.5781 - learning_rate: 0.0010\n",
      "Epoch 77/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6789 - mse: 0.8183 - val_loss: 2.4661 - val_mse: 0.5834 - learning_rate: 0.0010\n",
      "Epoch 78/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7705 - mse: 1.2009 - val_loss: 2.4499 - val_mse: 0.5936 - learning_rate: 0.0010\n",
      "Epoch 79/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6552 - mse: 0.8722 - val_loss: 2.4344 - val_mse: 0.5995 - learning_rate: 0.0010\n",
      "Epoch 80/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.6832 - mse: 1.0149 - val_loss: 2.4213 - val_mse: 0.6053 - learning_rate: 0.0010\n",
      "Epoch 81/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.6900 - mse: 1.1122 - val_loss: 2.4183 - val_mse: 0.6303 - learning_rate: 0.0010\n",
      "Epoch 82/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.6843 - mse: 1.0686 - val_loss: 2.4126 - val_mse: 0.6431 - learning_rate: 0.0010\n",
      "Epoch 83/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6349 - mse: 1.0876 - val_loss: 2.3983 - val_mse: 0.6597 - learning_rate: 0.0010\n",
      "Epoch 84/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6737 - mse: 1.0927 - val_loss: 2.3836 - val_mse: 0.6550 - learning_rate: 0.0010\n",
      "Epoch 85/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6135 - mse: 0.8787 - val_loss: 2.3663 - val_mse: 0.6292 - learning_rate: 0.0010\n",
      "Epoch 86/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6000 - mse: 0.8936 - val_loss: 2.3576 - val_mse: 0.6171 - learning_rate: 0.0010\n",
      "Epoch 87/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.6252 - mse: 1.1058 - val_loss: 2.3472 - val_mse: 0.6087 - learning_rate: 0.0010\n",
      "Epoch 88/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5413 - mse: 0.8243 - val_loss: 2.3455 - val_mse: 0.6174 - learning_rate: 0.0010\n",
      "Epoch 89/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5457 - mse: 0.9126 - val_loss: 2.3415 - val_mse: 0.6237 - learning_rate: 0.0010\n",
      "Epoch 90/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4972 - mse: 0.8251 - val_loss: 2.3370 - val_mse: 0.6224 - learning_rate: 0.0010\n",
      "Epoch 91/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.4921 - mse: 0.9591 - val_loss: 2.3248 - val_mse: 0.6139 - learning_rate: 0.0010\n",
      "Epoch 92/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5205 - mse: 0.9042 - val_loss: 2.3070 - val_mse: 0.6070 - learning_rate: 0.0010\n",
      "Epoch 93/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.5032 - mse: 0.9231 - val_loss: 2.2815 - val_mse: 0.5915 - learning_rate: 0.0010\n",
      "Epoch 94/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4998 - mse: 0.8038 - val_loss: 2.2644 - val_mse: 0.5836 - learning_rate: 0.0010\n",
      "Epoch 95/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4207 - mse: 0.8234 - val_loss: 2.2453 - val_mse: 0.5784 - learning_rate: 0.0010\n",
      "Epoch 96/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3876 - mse: 0.6933 - val_loss: 2.2274 - val_mse: 0.5799 - learning_rate: 0.0010\n",
      "Epoch 97/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4380 - mse: 0.7989 - val_loss: 2.2010 - val_mse: 0.5512 - learning_rate: 0.0010\n",
      "Epoch 98/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.3470 - mse: 0.6230 - val_loss: 2.1911 - val_mse: 0.5207 - learning_rate: 0.0010\n",
      "Epoch 99/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.3677 - mse: 0.7576 - val_loss: 2.1803 - val_mse: 0.5204 - learning_rate: 0.0010\n",
      "Epoch 100/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3620 - mse: 0.6940 - val_loss: 2.1736 - val_mse: 0.5219 - learning_rate: 0.0010\n",
      "Epoch 101/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5129 - mse: 1.1903 - val_loss: 2.1676 - val_mse: 0.5266 - learning_rate: 0.0010\n",
      "Epoch 102/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3137 - mse: 0.7085 - val_loss: 2.1633 - val_mse: 0.5288 - learning_rate: 0.0010\n",
      "Epoch 103/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.3585 - mse: 0.7660 - val_loss: 2.1602 - val_mse: 0.5316 - learning_rate: 0.0010\n",
      "Epoch 104/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.3216 - mse: 0.6865 - val_loss: 2.1481 - val_mse: 0.5025 - learning_rate: 0.0010\n",
      "Epoch 105/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3352 - mse: 0.6609 - val_loss: 2.1343 - val_mse: 0.4849 - learning_rate: 0.0010\n",
      "Epoch 106/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2776 - mse: 0.6613 - val_loss: 2.1169 - val_mse: 0.4759 - learning_rate: 0.0010\n",
      "Epoch 107/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2643 - mse: 0.6880 - val_loss: 2.1007 - val_mse: 0.4735 - learning_rate: 0.0010\n",
      "Epoch 108/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2997 - mse: 0.7021 - val_loss: 2.0802 - val_mse: 0.4629 - learning_rate: 0.0010\n",
      "Epoch 109/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2793 - mse: 0.7803 - val_loss: 2.0699 - val_mse: 0.4576 - learning_rate: 0.0010\n",
      "Epoch 110/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3118 - mse: 0.9002 - val_loss: 2.0537 - val_mse: 0.4659 - learning_rate: 0.0010\n",
      "Epoch 111/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2269 - mse: 0.7074 - val_loss: 2.0393 - val_mse: 0.4788 - learning_rate: 0.0010\n",
      "Epoch 112/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2737 - mse: 0.7602 - val_loss: 2.0304 - val_mse: 0.4961 - learning_rate: 0.0010\n",
      "Epoch 113/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2046 - mse: 0.7190 - val_loss: 2.0203 - val_mse: 0.4935 - learning_rate: 0.0010\n",
      "Epoch 114/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2013 - mse: 0.7023 - val_loss: 2.0290 - val_mse: 0.4848 - learning_rate: 0.0010\n",
      "Epoch 115/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2687 - mse: 0.8109 - val_loss: 2.0308 - val_mse: 0.4671 - learning_rate: 0.0010\n",
      "Epoch 116/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2603 - mse: 0.8985 - val_loss: 2.0184 - val_mse: 0.4652 - learning_rate: 0.0010\n",
      "Epoch 117/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0861 - mse: 0.5157 - val_loss: 2.0085 - val_mse: 0.4633 - learning_rate: 0.0010\n",
      "Epoch 118/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2217 - mse: 0.7926 - val_loss: 1.9901 - val_mse: 0.4612 - learning_rate: 0.0010\n",
      "Epoch 119/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2064 - mse: 0.8327 - val_loss: 1.9724 - val_mse: 0.4725 - learning_rate: 0.0010\n",
      "Epoch 120/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1709 - mse: 0.7568 - val_loss: 1.9608 - val_mse: 0.4796 - learning_rate: 0.0010\n",
      "Epoch 121/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1115 - mse: 0.5242 - val_loss: 1.9541 - val_mse: 0.4847 - learning_rate: 0.0010\n",
      "Epoch 122/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1331 - mse: 0.6983 - val_loss: 1.9452 - val_mse: 0.4871 - learning_rate: 0.0010\n",
      "Epoch 123/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1475 - mse: 0.7014 - val_loss: 1.9433 - val_mse: 0.4866 - learning_rate: 0.0010\n",
      "Epoch 124/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1258 - mse: 0.6942 - val_loss: 1.9424 - val_mse: 0.4665 - learning_rate: 0.0010\n",
      "Epoch 125/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1162 - mse: 0.6643 - val_loss: 1.9394 - val_mse: 0.4536 - learning_rate: 0.0010\n",
      "Epoch 126/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0829 - mse: 0.6641 - val_loss: 1.9325 - val_mse: 0.4394 - learning_rate: 0.0010\n",
      "Epoch 127/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.0701 - mse: 0.7008 - val_loss: 1.9228 - val_mse: 0.4369 - learning_rate: 0.0010\n",
      "Epoch 128/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9877 - mse: 0.3797 - val_loss: 1.9105 - val_mse: 0.4338 - learning_rate: 0.0010\n",
      "Epoch 129/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0013 - mse: 0.5257 - val_loss: 1.9013 - val_mse: 0.4366 - learning_rate: 0.0010\n",
      "Epoch 130/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0437 - mse: 0.5730 - val_loss: 1.8954 - val_mse: 0.4363 - learning_rate: 0.0010\n",
      "Epoch 131/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9634 - mse: 0.5333 - val_loss: 1.8891 - val_mse: 0.4343 - learning_rate: 0.0010\n",
      "Epoch 132/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9677 - mse: 0.5088 - val_loss: 1.8816 - val_mse: 0.4380 - learning_rate: 0.0010\n",
      "Epoch 133/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0750 - mse: 0.8337 - val_loss: 1.8762 - val_mse: 0.4462 - learning_rate: 0.0010\n",
      "Epoch 134/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9171 - mse: 0.4940 - val_loss: 1.8731 - val_mse: 0.4700 - learning_rate: 0.0010\n",
      "Epoch 135/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9291 - mse: 0.5041 - val_loss: 1.8678 - val_mse: 0.4919 - learning_rate: 0.0010\n",
      "Epoch 136/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9894 - mse: 0.6049 - val_loss: 1.8586 - val_mse: 0.4976 - learning_rate: 0.0010\n",
      "Epoch 137/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.9467 - mse: 0.5319 - val_loss: 1.8351 - val_mse: 0.4775 - learning_rate: 0.0010\n",
      "Epoch 138/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9570 - mse: 0.6435 - val_loss: 1.8141 - val_mse: 0.4680 - learning_rate: 0.0010\n",
      "Epoch 139/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9040 - mse: 0.5649 - val_loss: 1.8022 - val_mse: 0.4729 - learning_rate: 0.0010\n",
      "Epoch 140/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9083 - mse: 0.5321 - val_loss: 1.7898 - val_mse: 0.4627 - learning_rate: 0.0010\n",
      "Epoch 141/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9335 - mse: 0.5907 - val_loss: 1.7794 - val_mse: 0.4568 - learning_rate: 0.0010\n",
      "Epoch 142/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8292 - mse: 0.4434 - val_loss: 1.7700 - val_mse: 0.4515 - learning_rate: 0.0010\n",
      "Epoch 143/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8673 - mse: 0.5166 - val_loss: 1.7780 - val_mse: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 144/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9398 - mse: 0.6284 - val_loss: 1.7799 - val_mse: 0.4785 - learning_rate: 0.0010\n",
      "Epoch 145/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8713 - mse: 0.5748 - val_loss: 1.7773 - val_mse: 0.4938 - learning_rate: 0.0010\n",
      "Epoch 146/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7748 - mse: 0.3562 - val_loss: 1.7689 - val_mse: 0.4926 - learning_rate: 0.0010\n",
      "Epoch 147/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8308 - mse: 0.5365 - val_loss: 1.7539 - val_mse: 0.4724 - learning_rate: 0.0010\n",
      "Epoch 148/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8291 - mse: 0.5513 - val_loss: 1.7386 - val_mse: 0.4695 - learning_rate: 0.0010\n",
      "Epoch 149/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7350 - mse: 0.3927 - val_loss: 1.7251 - val_mse: 0.4607 - learning_rate: 0.0010\n",
      "Epoch 150/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7459 - mse: 0.3737 - val_loss: 1.7020 - val_mse: 0.4323 - learning_rate: 0.0010\n",
      "Epoch 151/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7555 - mse: 0.5481 - val_loss: 1.6799 - val_mse: 0.4052 - learning_rate: 0.0010\n",
      "Epoch 152/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7418 - mse: 0.4806 - val_loss: 1.6719 - val_mse: 0.3975 - learning_rate: 0.0010\n",
      "Epoch 153/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7732 - mse: 0.4932 - val_loss: 1.6640 - val_mse: 0.4076 - learning_rate: 0.0010\n",
      "Epoch 154/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7649 - mse: 0.5199 - val_loss: 1.6578 - val_mse: 0.4163 - learning_rate: 0.0010\n",
      "Epoch 155/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8118 - mse: 0.6034 - val_loss: 1.6514 - val_mse: 0.4157 - learning_rate: 0.0010\n",
      "Epoch 156/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6987 - mse: 0.4100 - val_loss: 1.6402 - val_mse: 0.4138 - learning_rate: 0.0010\n",
      "Epoch 157/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7021 - mse: 0.4568 - val_loss: 1.6298 - val_mse: 0.4216 - learning_rate: 0.0010\n",
      "Epoch 158/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6747 - mse: 0.4066 - val_loss: 1.6309 - val_mse: 0.4404 - learning_rate: 0.0010\n",
      "Epoch 159/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7169 - mse: 0.4774 - val_loss: 1.6264 - val_mse: 0.4580 - learning_rate: 0.0010\n",
      "Epoch 160/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6659 - mse: 0.3465 - val_loss: 1.6142 - val_mse: 0.4542 - learning_rate: 0.0010\n",
      "Epoch 161/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6432 - mse: 0.3838 - val_loss: 1.5986 - val_mse: 0.4311 - learning_rate: 0.0010\n",
      "Epoch 162/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6408 - mse: 0.3432 - val_loss: 1.5967 - val_mse: 0.4615 - learning_rate: 0.0010\n",
      "Epoch 163/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7062 - mse: 0.5647 - val_loss: 1.5950 - val_mse: 0.5165 - learning_rate: 0.0010\n",
      "Epoch 164/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6453 - mse: 0.4258 - val_loss: 1.6039 - val_mse: 0.5690 - learning_rate: 0.0010\n",
      "Epoch 165/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6707 - mse: 0.5185 - val_loss: 1.6129 - val_mse: 0.5966 - learning_rate: 0.0010\n",
      "Epoch 166/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7172 - mse: 0.6249 - val_loss: 1.5934 - val_mse: 0.5674 - learning_rate: 0.0010\n",
      "Epoch 167/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6234 - mse: 0.4639 - val_loss: 1.5564 - val_mse: 0.5198 - learning_rate: 0.0010\n",
      "Epoch 168/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6097 - mse: 0.4285 - val_loss: 1.5351 - val_mse: 0.4937 - learning_rate: 0.0010\n",
      "Epoch 169/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5604 - mse: 0.3674 - val_loss: 1.5375 - val_mse: 0.5029 - learning_rate: 0.0010\n",
      "Epoch 170/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5322 - mse: 0.2917 - val_loss: 1.5250 - val_mse: 0.4772 - learning_rate: 0.0010\n",
      "Epoch 171/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6341 - mse: 0.5017 - val_loss: 1.5066 - val_mse: 0.4241 - learning_rate: 0.0010\n",
      "Epoch 172/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5677 - mse: 0.3713 - val_loss: 1.4959 - val_mse: 0.4063 - learning_rate: 0.0010\n",
      "Epoch 173/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5498 - mse: 0.3726 - val_loss: 1.4877 - val_mse: 0.4111 - learning_rate: 0.0010\n",
      "Epoch 174/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5985 - mse: 0.4374 - val_loss: 1.4930 - val_mse: 0.4336 - learning_rate: 0.0010\n",
      "Epoch 175/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5865 - mse: 0.4490 - val_loss: 1.4879 - val_mse: 0.4345 - learning_rate: 0.0010\n",
      "Epoch 176/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5491 - mse: 0.3947 - val_loss: 1.4764 - val_mse: 0.4173 - learning_rate: 0.0010\n",
      "Epoch 177/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4512 - mse: 0.2260 - val_loss: 1.4614 - val_mse: 0.4206 - learning_rate: 0.0010\n",
      "Epoch 178/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5591 - mse: 0.4248 - val_loss: 1.4444 - val_mse: 0.4252 - learning_rate: 0.0010\n",
      "Epoch 179/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5114 - mse: 0.3286 - val_loss: 1.4248 - val_mse: 0.4059 - learning_rate: 0.0010\n",
      "Epoch 180/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4931 - mse: 0.3358 - val_loss: 1.4083 - val_mse: 0.3967 - learning_rate: 0.0010\n",
      "Epoch 181/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5212 - mse: 0.3561 - val_loss: 1.4055 - val_mse: 0.4163 - learning_rate: 0.0010\n",
      "Epoch 182/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5190 - mse: 0.4455 - val_loss: 1.4162 - val_mse: 0.4501 - learning_rate: 0.0010\n",
      "Epoch 183/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4633 - mse: 0.3738 - val_loss: 1.4079 - val_mse: 0.4537 - learning_rate: 0.0010\n",
      "Epoch 184/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4567 - mse: 0.3676 - val_loss: 1.3946 - val_mse: 0.4133 - learning_rate: 0.0010\n",
      "Epoch 185/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4984 - mse: 0.4972 - val_loss: 1.4003 - val_mse: 0.4087 - learning_rate: 0.0010\n",
      "Epoch 186/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4822 - mse: 0.3749 - val_loss: 1.4003 - val_mse: 0.4307 - learning_rate: 0.0010\n",
      "Epoch 187/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4485 - mse: 0.3955 - val_loss: 1.3914 - val_mse: 0.4350 - learning_rate: 0.0010\n",
      "Epoch 188/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4833 - mse: 0.4408 - val_loss: 1.3823 - val_mse: 0.4046 - learning_rate: 0.0010\n",
      "Epoch 189/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4707 - mse: 0.4886 - val_loss: 1.3761 - val_mse: 0.3724 - learning_rate: 0.0010\n",
      "Epoch 190/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4256 - mse: 0.3507 - val_loss: 1.3670 - val_mse: 0.3417 - learning_rate: 0.0010\n",
      "Epoch 191/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3676 - mse: 0.2731 - val_loss: 1.3538 - val_mse: 0.3275 - learning_rate: 0.0010\n",
      "Epoch 192/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3735 - mse: 0.2948 - val_loss: 1.3431 - val_mse: 0.3206 - learning_rate: 0.0010\n",
      "Epoch 193/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4096 - mse: 0.3933 - val_loss: 1.3322 - val_mse: 0.3148 - learning_rate: 0.0010\n",
      "Epoch 194/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3740 - mse: 0.4062 - val_loss: 1.3220 - val_mse: 0.3119 - learning_rate: 0.0010\n",
      "Epoch 195/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3544 - mse: 0.3253 - val_loss: 1.3136 - val_mse: 0.3211 - learning_rate: 0.0010\n",
      "Epoch 196/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3412 - mse: 0.3473 - val_loss: 1.3012 - val_mse: 0.3422 - learning_rate: 0.0010\n",
      "Epoch 197/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3633 - mse: 0.3733 - val_loss: 1.2989 - val_mse: 0.3872 - learning_rate: 0.0010\n",
      "Epoch 198/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3149 - mse: 0.3241 - val_loss: 1.2918 - val_mse: 0.3931 - learning_rate: 0.0010\n",
      "Epoch 199/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3524 - mse: 0.3473 - val_loss: 1.2839 - val_mse: 0.4021 - learning_rate: 0.0010\n",
      "Epoch 200/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2607 - mse: 0.2443 - val_loss: 1.2714 - val_mse: 0.3902 - learning_rate: 0.0010\n",
      "Epoch 201/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2624 - mse: 0.2036 - val_loss: 1.2631 - val_mse: 0.3857 - learning_rate: 0.0010\n",
      "Epoch 202/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3070 - mse: 0.3083 - val_loss: 1.2494 - val_mse: 0.3790 - learning_rate: 0.0010\n",
      "Epoch 203/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2919 - mse: 0.3400 - val_loss: 1.2398 - val_mse: 0.3774 - learning_rate: 0.0010\n",
      "Epoch 204/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2971 - mse: 0.3285 - val_loss: 1.2355 - val_mse: 0.3675 - learning_rate: 0.0010\n",
      "Epoch 205/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2316 - mse: 0.2417 - val_loss: 1.2331 - val_mse: 0.3518 - learning_rate: 0.0010\n",
      "Epoch 206/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2433 - mse: 0.2564 - val_loss: 1.2252 - val_mse: 0.3138 - learning_rate: 0.0010\n",
      "Epoch 207/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2214 - mse: 0.2543 - val_loss: 1.2143 - val_mse: 0.3248 - learning_rate: 0.0010\n",
      "Epoch 208/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2139 - mse: 0.2128 - val_loss: 1.2097 - val_mse: 0.3604 - learning_rate: 0.0010\n",
      "Epoch 209/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2375 - mse: 0.2572 - val_loss: 1.2336 - val_mse: 0.4160 - learning_rate: 0.0010\n",
      "Epoch 210/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2185 - mse: 0.2537 - val_loss: 1.2358 - val_mse: 0.4381 - learning_rate: 0.0010\n",
      "Epoch 211/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2413 - mse: 0.2947 - val_loss: 1.2425 - val_mse: 0.4533 - learning_rate: 0.0010\n",
      "Epoch 212/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2255 - mse: 0.2860 - val_loss: 1.2570 - val_mse: 0.4883 - learning_rate: 0.0010\n",
      "Epoch 213/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2685 - mse: 0.4563 - val_loss: 1.2450 - val_mse: 0.4637 - learning_rate: 0.0010\n",
      "Epoch 214/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2392 - mse: 0.3846 - val_loss: 1.2275 - val_mse: 0.4302 - learning_rate: 5.0000e-04\n",
      "Epoch 215/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2321 - mse: 0.3500 - val_loss: 1.2116 - val_mse: 0.4042 - learning_rate: 5.0000e-04\n",
      "Epoch 216/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1816 - mse: 0.2216 - val_loss: 1.1899 - val_mse: 0.3689 - learning_rate: 5.0000e-04\n",
      "Epoch 217/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1588 - mse: 0.2565 - val_loss: 1.1767 - val_mse: 0.3515 - learning_rate: 5.0000e-04\n",
      "Epoch 218/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2178 - mse: 0.3533 - val_loss: 1.1737 - val_mse: 0.3523 - learning_rate: 5.0000e-04\n",
      "Epoch 219/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1586 - mse: 0.2621 - val_loss: 1.1675 - val_mse: 0.3499 - learning_rate: 5.0000e-04\n",
      "Epoch 220/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1049 - mse: 0.1396 - val_loss: 1.1716 - val_mse: 0.3603 - learning_rate: 5.0000e-04\n",
      "Epoch 221/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1618 - mse: 0.2527 - val_loss: 1.1814 - val_mse: 0.3805 - learning_rate: 5.0000e-04\n",
      "Epoch 222/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1562 - mse: 0.2128 - val_loss: 1.1735 - val_mse: 0.3684 - learning_rate: 5.0000e-04\n",
      "Epoch 223/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1854 - mse: 0.3246 - val_loss: 1.1542 - val_mse: 0.3382 - learning_rate: 5.0000e-04\n",
      "Epoch 224/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1736 - mse: 0.3111 - val_loss: 1.1440 - val_mse: 0.3223 - learning_rate: 5.0000e-04\n",
      "Epoch 225/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1742 - mse: 0.2644 - val_loss: 1.1437 - val_mse: 0.3120 - learning_rate: 5.0000e-04\n",
      "Epoch 226/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1684 - mse: 0.2683 - val_loss: 1.1480 - val_mse: 0.3162 - learning_rate: 5.0000e-04\n",
      "Epoch 227/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1843 - mse: 0.3657 - val_loss: 1.1501 - val_mse: 0.3162 - learning_rate: 5.0000e-04\n",
      "Epoch 228/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1430 - mse: 0.2442 - val_loss: 1.1485 - val_mse: 0.3271 - learning_rate: 5.0000e-04\n",
      "Epoch 229/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1446 - mse: 0.2569 - val_loss: 1.1474 - val_mse: 0.3403 - learning_rate: 5.0000e-04\n",
      "Epoch 230/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1672 - mse: 0.2991 - val_loss: 1.1428 - val_mse: 0.3531 - learning_rate: 5.0000e-04\n",
      "Epoch 231/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1885 - mse: 0.3254 - val_loss: 1.1363 - val_mse: 0.3580 - learning_rate: 5.0000e-04\n",
      "Epoch 232/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1179 - mse: 0.2725 - val_loss: 1.1382 - val_mse: 0.3749 - learning_rate: 5.0000e-04\n",
      "Epoch 233/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1449 - mse: 0.2380 - val_loss: 1.1463 - val_mse: 0.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 234/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1825 - mse: 0.3486 - val_loss: 1.1393 - val_mse: 0.3895 - learning_rate: 5.0000e-04\n",
      "Epoch 235/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1509 - mse: 0.3465 - val_loss: 1.1409 - val_mse: 0.3963 - learning_rate: 5.0000e-04\n",
      "Epoch 236/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1515 - mse: 0.2824 - val_loss: 1.1414 - val_mse: 0.4041 - learning_rate: 5.0000e-04\n",
      "Epoch 237/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0743 - mse: 0.1976 - val_loss: 1.1412 - val_mse: 0.4092 - learning_rate: 2.5000e-04\n",
      "Epoch 238/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1218 - mse: 0.3241 - val_loss: 1.1412 - val_mse: 0.4133 - learning_rate: 2.5000e-04\n",
      "Epoch 239/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1344 - mse: 0.2992 - val_loss: 1.1346 - val_mse: 0.4036 - learning_rate: 2.5000e-04\n",
      "Epoch 240/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1200 - mse: 0.3034 - val_loss: 1.1235 - val_mse: 0.3855 - learning_rate: 2.5000e-04\n",
      "Epoch 241/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1405 - mse: 0.3917 - val_loss: 1.1216 - val_mse: 0.3858 - learning_rate: 2.5000e-04\n",
      "Epoch 242/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2541 - mse: 0.5070 - val_loss: 1.1207 - val_mse: 0.3843 - learning_rate: 2.5000e-04\n",
      "Epoch 243/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0944 - mse: 0.2353 - val_loss: 1.1138 - val_mse: 0.3706 - learning_rate: 2.5000e-04\n",
      "Epoch 244/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0573 - mse: 0.2173 - val_loss: 1.1042 - val_mse: 0.3522 - learning_rate: 2.5000e-04\n",
      "Epoch 245/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0911 - mse: 0.2372 - val_loss: 1.0999 - val_mse: 0.3435 - learning_rate: 2.5000e-04\n",
      "Epoch 246/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1006 - mse: 0.2644 - val_loss: 1.0985 - val_mse: 0.3416 - learning_rate: 2.5000e-04\n",
      "Epoch 247/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1214 - mse: 0.3250 - val_loss: 1.0949 - val_mse: 0.3368 - learning_rate: 2.5000e-04\n",
      "Epoch 248/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0929 - mse: 0.2598 - val_loss: 1.0858 - val_mse: 0.3234 - learning_rate: 2.5000e-04\n",
      "Epoch 249/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0880 - mse: 0.2301 - val_loss: 1.0806 - val_mse: 0.3168 - learning_rate: 2.5000e-04\n",
      "Epoch 250/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0886 - mse: 0.3085 - val_loss: 1.0787 - val_mse: 0.3177 - learning_rate: 2.5000e-04\n",
      "Epoch 251/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0816 - mse: 0.2410 - val_loss: 1.0775 - val_mse: 0.3183 - learning_rate: 2.5000e-04\n",
      "Epoch 252/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1435 - mse: 0.3436 - val_loss: 1.0721 - val_mse: 0.3118 - learning_rate: 2.5000e-04\n",
      "Epoch 253/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0821 - mse: 0.2414 - val_loss: 1.0689 - val_mse: 0.3103 - learning_rate: 2.5000e-04\n",
      "Epoch 254/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1825 - mse: 0.4627 - val_loss: 1.0654 - val_mse: 0.3060 - learning_rate: 2.5000e-04\n",
      "Epoch 255/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0166 - mse: 0.1630 - val_loss: 1.0650 - val_mse: 0.3078 - learning_rate: 2.5000e-04\n",
      "Epoch 256/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0752 - mse: 0.2455 - val_loss: 1.0630 - val_mse: 0.3076 - learning_rate: 2.5000e-04\n",
      "Epoch 257/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0872 - mse: 0.2548 - val_loss: 1.0604 - val_mse: 0.3066 - learning_rate: 2.5000e-04\n",
      "Epoch 258/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0066 - mse: 0.1510 - val_loss: 1.0571 - val_mse: 0.3040 - learning_rate: 2.5000e-04\n",
      "Epoch 259/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0615 - mse: 0.2803 - val_loss: 1.0483 - val_mse: 0.2919 - learning_rate: 2.5000e-04\n",
      "Epoch 260/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0712 - mse: 0.1994 - val_loss: 1.0412 - val_mse: 0.2796 - learning_rate: 2.5000e-04\n",
      "Epoch 261/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0263 - mse: 0.1990 - val_loss: 1.0366 - val_mse: 0.2743 - learning_rate: 2.5000e-04\n",
      "Epoch 262/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0563 - mse: 0.2517 - val_loss: 1.0351 - val_mse: 0.2753 - learning_rate: 2.5000e-04\n",
      "Epoch 263/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0627 - mse: 0.2807 - val_loss: 1.0380 - val_mse: 0.2867 - learning_rate: 2.5000e-04\n",
      "Epoch 264/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0840 - mse: 0.3538 - val_loss: 1.0404 - val_mse: 0.2944 - learning_rate: 2.5000e-04\n",
      "Epoch 265/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0586 - mse: 0.2853 - val_loss: 1.0426 - val_mse: 0.3007 - learning_rate: 2.5000e-04\n",
      "Epoch 266/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0529 - mse: 0.2614 - val_loss: 1.0444 - val_mse: 0.3053 - learning_rate: 2.5000e-04\n",
      "Epoch 267/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0724 - mse: 0.2406 - val_loss: 1.0448 - val_mse: 0.3103 - learning_rate: 2.5000e-04\n",
      "Epoch 268/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9819 - mse: 0.1528 - val_loss: 1.0453 - val_mse: 0.3133 - learning_rate: 1.2500e-04\n",
      "Epoch 269/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0769 - mse: 0.2520 - val_loss: 1.0419 - val_mse: 0.3085 - learning_rate: 1.2500e-04\n",
      "Epoch 270/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0457 - mse: 0.2214 - val_loss: 1.0401 - val_mse: 0.3077 - learning_rate: 1.2500e-04\n",
      "Epoch 271/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0151 - mse: 0.1875 - val_loss: 1.0392 - val_mse: 0.3082 - learning_rate: 1.2500e-04\n",
      "Epoch 272/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0593 - mse: 0.2513 - val_loss: 1.0327 - val_mse: 0.2968 - learning_rate: 1.2500e-04\n",
      "Epoch 273/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0298 - mse: 0.2301 - val_loss: 1.0283 - val_mse: 0.2879 - learning_rate: 1.2500e-04\n",
      "Epoch 274/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0811 - mse: 0.2802 - val_loss: 1.0229 - val_mse: 0.2784 - learning_rate: 1.2500e-04\n",
      "Epoch 275/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0624 - mse: 0.3359 - val_loss: 1.0201 - val_mse: 0.2734 - learning_rate: 1.2500e-04\n",
      "Epoch 276/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0675 - mse: 0.2663 - val_loss: 1.0206 - val_mse: 0.2762 - learning_rate: 1.2500e-04\n",
      "Epoch 277/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0744 - mse: 0.2581 - val_loss: 1.0228 - val_mse: 0.2821 - learning_rate: 1.2500e-04\n",
      "Epoch 278/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0343 - mse: 0.1811 - val_loss: 1.0245 - val_mse: 0.2878 - learning_rate: 1.2500e-04\n",
      "Epoch 279/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9948 - mse: 0.1687 - val_loss: 1.0270 - val_mse: 0.2934 - learning_rate: 1.2500e-04\n",
      "Epoch 280/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0193 - mse: 0.2006 - val_loss: 1.0352 - val_mse: 0.3110 - learning_rate: 1.2500e-04\n",
      "Epoch 281/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0954 - mse: 0.2748 - val_loss: 1.0378 - val_mse: 0.3169 - learning_rate: 6.2500e-05\n",
      "Epoch 282/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0144 - mse: 0.1931 - val_loss: 1.0390 - val_mse: 0.3197 - learning_rate: 6.2500e-05\n",
      "Epoch 283/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0376 - mse: 0.2388 - val_loss: 1.0371 - val_mse: 0.3158 - learning_rate: 6.2500e-05\n",
      "Epoch 284/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0304 - mse: 0.2373 - val_loss: 1.0358 - val_mse: 0.3127 - learning_rate: 6.2500e-05\n",
      "Epoch 285/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0284 - mse: 0.2564 - val_loss: 1.0346 - val_mse: 0.3116 - learning_rate: 6.2500e-05\n",
      "Epoch 286/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0208 - mse: 0.2020 - val_loss: 1.0343 - val_mse: 0.3117 - learning_rate: 3.1250e-05\n",
      "Epoch 287/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0240 - mse: 0.3118 - val_loss: 1.0318 - val_mse: 0.3058 - learning_rate: 3.1250e-05\n",
      "Epoch 288/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9914 - mse: 0.1713 - val_loss: 1.0307 - val_mse: 0.3040 - learning_rate: 3.1250e-05\n",
      "Epoch 289/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0529 - mse: 0.2819 - val_loss: 1.0305 - val_mse: 0.3046 - learning_rate: 3.1250e-05\n",
      "Epoch 290/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0510 - mse: 0.2280 - val_loss: 1.0303 - val_mse: 0.3056 - learning_rate: 3.1250e-05\n",
      "Epoch 291/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1386 - mse: 0.3706 - val_loss: 1.0292 - val_mse: 0.3027 - learning_rate: 1.5625e-05\n",
      "Epoch 292/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0296 - mse: 0.2818 - val_loss: 1.0291 - val_mse: 0.3021 - learning_rate: 1.5625e-05\n",
      "Epoch 293/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0016 - mse: 0.1596 - val_loss: 1.0283 - val_mse: 0.3006 - learning_rate: 1.5625e-05\n",
      "Epoch 294/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0403 - mse: 0.2370 - val_loss: 1.0283 - val_mse: 0.3010 - learning_rate: 1.5625e-05\n",
      "Epoch 295/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0242 - mse: 0.1878 - val_loss: 1.0281 - val_mse: 0.3022 - learning_rate: 1.5625e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0201 - mse: 0.2734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "Test MAE: 0.9305831891465272, R2 Score: 0.7020436238397598\n",
      "Custom Accuracy (within ±10% tolerance): 7.41%\n",
      "   Predicted Value  Actual Value\n",
      "0         0.174434      0.873547\n",
      "1         0.456355      0.220000\n",
      "2         4.544136      6.890951\n",
      "3         5.485657     12.152283\n",
      "4         0.452799      0.340000\n",
      "5         0.432799      0.440278\n",
      "6         0.189704      0.370000\n",
      "7         0.622993      0.360000\n",
      "8         0.294844      0.140000\n",
      "9         0.295362      0.266344\n"
     ]
    }
   ],
   "source": [
    "#include back probagation\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data1.csv')  # Replace with your dataset path\n",
    "X = data.drop('Cv', axis=1)\n",
    "y = data['Cv']\n",
    "\n",
    "# Handle possible outliers in the target\n",
    "y = np.clip(y, y.quantile(0.05), y.quantile(0.95))  # Limit to 5th-95th percentile\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale the target variable\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Build the FFNN model with improvements\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], kernel_regularizer=l2(0.01)))  # L2 regularization\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())  # Batch Normalization\n",
    "model.add(Dropout(0.4))  # Increased dropout for better regularization\n",
    "\n",
    "# Additional hidden layers\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "# Compile the model with an advanced optimizer\n",
    "optimizer = Nadam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mae', metrics=['mse'])\n",
    "\n",
    "# Callbacks: Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Reverse scaling to original range for predictions and actual values\n",
    "predictions_original = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate R2 Score and Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test_original, predictions_original)\n",
    "r2 = r2_score(y_test_original, predictions_original)\n",
    "\n",
    "print(f\"Test MAE: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# Combine predictions with actual values\n",
    "results = np.concatenate(\n",
    "    (predictions_original.reshape(-1, 1), y_test_original.reshape(-1, 1)),\n",
    "    axis=1\n",
    ")\n",
    "results_df = pd.DataFrame(results, columns=['Predicted Value', 'Actual Value'])\n",
    "\n",
    "# Calculate custom accuracy (e.g., within ±10% tolerance)\n",
    "tolerance = 0.1  # 10% tolerance\n",
    "correct_predictions = np.abs(predictions_original - y_test_original) <= tolerance * y_test_original\n",
    "accuracy = np.sum(correct_predictions) / len(y_test_original) * 100\n",
    "\n",
    "# Display predictions and accuracy\n",
    "print(f\"Custom Accuracy (within ±10% tolerance): {accuracy:.2f}%\")\n",
    "print(results_df.head(10))  # Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70836f69-4018-4a6d-8d93-9884a576f838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
