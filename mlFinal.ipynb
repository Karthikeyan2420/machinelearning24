{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3048dea-ca69-4680-ab8e-cd4a51b9890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.6471 - mean_squared_error: 0.2902 - val_loss: 0.4349 - val_mean_squared_error: 0.0805\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.5498 - mean_squared_error: 0.1955 - val_loss: 0.3949 - val_mean_squared_error: 0.0426\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5129 - mean_squared_error: 0.1606 - val_loss: 0.3669 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4751 - mean_squared_error: 0.1247 - val_loss: 0.3602 - val_mean_squared_error: 0.0116\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.4731 - mean_squared_error: 0.1245 - val_loss: 0.3704 - val_mean_squared_error: 0.0235\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3859 - mean_squared_error: 0.0390 - val_loss: 0.3944 - val_mean_squared_error: 0.0491\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4024 - mean_squared_error: 0.0571 - val_loss: 0.4313 - val_mean_squared_error: 0.0876\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3656 - mean_squared_error: 0.0219 - val_loss: 0.4779 - val_mean_squared_error: 0.1357\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3716 - mean_squared_error: 0.0295 - val_loss: 0.5275 - val_mean_squared_error: 0.1869\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3545 - mean_squared_error: 0.0140 - val_loss: 0.5860 - val_mean_squared_error: 0.2471\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3689 - mean_squared_error: 0.0300 - val_loss: 0.6267 - val_mean_squared_error: 0.2894\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3446 - mean_squared_error: 0.0073 - val_loss: 0.6633 - val_mean_squared_error: 0.3277\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3872 - mean_squared_error: 0.0516 - val_loss: 0.6718 - val_mean_squared_error: 0.3378\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3723 - mean_squared_error: 0.0383 - val_loss: 0.6591 - val_mean_squared_error: 0.3268\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3773 - mean_squared_error: 0.0450 - val_loss: 0.6318 - val_mean_squared_error: 0.3011\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3568 - mean_squared_error: 0.0261 - val_loss: 0.5990 - val_mean_squared_error: 0.2699\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3545 - mean_squared_error: 0.0254 - val_loss: 0.5612 - val_mean_squared_error: 0.2337\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3476 - mean_squared_error: 0.0201 - val_loss: 0.5235 - val_mean_squared_error: 0.1977\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3529 - mean_squared_error: 0.0271 - val_loss: 0.4856 - val_mean_squared_error: 0.1614\n",
      "Epoch 20/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3576 - mean_squared_error: 0.0334 - val_loss: 0.4512 - val_mean_squared_error: 0.1287\n",
      "Epoch 21/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3574 - mean_squared_error: 0.0348 - val_loss: 0.4181 - val_mean_squared_error: 0.0972\n",
      "Epoch 22/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3321 - mean_squared_error: 0.0112 - val_loss: 0.3923 - val_mean_squared_error: 0.0729\n",
      "Epoch 23/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3341 - mean_squared_error: 0.0148 - val_loss: 0.3711 - val_mean_squared_error: 0.0533\n",
      "Epoch 24/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3327 - mean_squared_error: 0.0150 - val_loss: 0.3566 - val_mean_squared_error: 0.0405\n",
      "Epoch 25/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3304 - mean_squared_error: 0.0143 - val_loss: 0.3455 - val_mean_squared_error: 0.0310\n",
      "Epoch 26/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3276 - mean_squared_error: 0.0131 - val_loss: 0.3388 - val_mean_squared_error: 0.0258\n",
      "Epoch 27/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3180 - mean_squared_error: 0.0050 - val_loss: 0.3340 - val_mean_squared_error: 0.0227\n",
      "Epoch 28/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3211 - mean_squared_error: 0.0098 - val_loss: 0.3316 - val_mean_squared_error: 0.0219\n",
      "Epoch 29/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.3189 - mean_squared_error: 0.0092 - val_loss: 0.3306 - val_mean_squared_error: 0.0225\n",
      "Epoch 30/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3218 - mean_squared_error: 0.0136 - val_loss: 0.3314 - val_mean_squared_error: 0.0248\n",
      "Epoch 31/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3197 - mean_squared_error: 0.0131 - val_loss: 0.3327 - val_mean_squared_error: 0.0277\n",
      "Epoch 32/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3117 - mean_squared_error: 0.0067 - val_loss: 0.3336 - val_mean_squared_error: 0.0302\n",
      "Epoch 33/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3311 - mean_squared_error: 0.0276 - val_loss: 0.3356 - val_mean_squared_error: 0.0337\n",
      "Epoch 34/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3127 - mean_squared_error: 0.0108 - val_loss: 0.3389 - val_mean_squared_error: 0.0386\n",
      "Epoch 35/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3191 - mean_squared_error: 0.0188 - val_loss: 0.3426 - val_mean_squared_error: 0.0438\n",
      "Epoch 36/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3048 - mean_squared_error: 0.0060 - val_loss: 0.3468 - val_mean_squared_error: 0.0495\n",
      "Epoch 37/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3081 - mean_squared_error: 0.0109 - val_loss: 0.3510 - val_mean_squared_error: 0.0553\n",
      "Epoch 38/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3103 - mean_squared_error: 0.0146 - val_loss: 0.3544 - val_mean_squared_error: 0.0603\n",
      "Epoch 39/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3007 - mean_squared_error: 0.0065 - val_loss: 0.3580 - val_mean_squared_error: 0.0653\n",
      "Epoch 40/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3029 - mean_squared_error: 0.0103 - val_loss: 0.3596 - val_mean_squared_error: 0.0684\n",
      "Epoch 41/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3056 - mean_squared_error: 0.0144 - val_loss: 0.3587 - val_mean_squared_error: 0.0690\n",
      "Epoch 42/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2983 - mean_squared_error: 0.0086 - val_loss: 0.3568 - val_mean_squared_error: 0.0686\n",
      "Epoch 43/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2923 - mean_squared_error: 0.0042 - val_loss: 0.3549 - val_mean_squared_error: 0.0682\n",
      "Epoch 44/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2976 - mean_squared_error: 0.0109 - val_loss: 0.3519 - val_mean_squared_error: 0.0667\n",
      "Epoch 45/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2921 - mean_squared_error: 0.0070 - val_loss: 0.3511 - val_mean_squared_error: 0.0675\n",
      "Epoch 46/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2994 - mean_squared_error: 0.0158 - val_loss: 0.3496 - val_mean_squared_error: 0.0674\n",
      "Epoch 47/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.2991 - mean_squared_error: 0.0170 - val_loss: 0.3439 - val_mean_squared_error: 0.0632\n",
      "Epoch 48/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2963 - mean_squared_error: 0.0156 - val_loss: 0.3369 - val_mean_squared_error: 0.0577\n",
      "Epoch 49/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2868 - mean_squared_error: 0.0076 - val_loss: 0.3302 - val_mean_squared_error: 0.0524\n",
      "Epoch 50/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2825 - mean_squared_error: 0.0047 - val_loss: 0.3246 - val_mean_squared_error: 0.0483\n",
      "Epoch 51/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2866 - mean_squared_error: 0.0103 - val_loss: 0.3213 - val_mean_squared_error: 0.0465\n",
      "Epoch 52/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2772 - mean_squared_error: 0.0023 - val_loss: 0.3187 - val_mean_squared_error: 0.0453\n",
      "Epoch 53/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2759 - mean_squared_error: 0.0025 - val_loss: 0.3173 - val_mean_squared_error: 0.0454\n",
      "Epoch 54/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2754 - mean_squared_error: 0.0035 - val_loss: 0.3167 - val_mean_squared_error: 0.0462\n",
      "Epoch 55/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2797 - mean_squared_error: 0.0092 - val_loss: 0.3151 - val_mean_squared_error: 0.0460\n",
      "Epoch 56/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2749 - mean_squared_error: 0.0058 - val_loss: 0.3133 - val_mean_squared_error: 0.0456\n",
      "Epoch 57/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2738 - mean_squared_error: 0.0061 - val_loss: 0.3109 - val_mean_squared_error: 0.0446\n",
      "Epoch 58/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2775 - mean_squared_error: 0.0113 - val_loss: 0.3086 - val_mean_squared_error: 0.0438\n",
      "Epoch 59/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2718 - mean_squared_error: 0.0069 - val_loss: 0.3066 - val_mean_squared_error: 0.0432\n",
      "Epoch 60/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2722 - mean_squared_error: 0.0088 - val_loss: 0.3054 - val_mean_squared_error: 0.0433\n",
      "Epoch 61/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2673 - mean_squared_error: 0.0053 - val_loss: 0.3053 - val_mean_squared_error: 0.0447\n",
      "Epoch 62/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.2680 - mean_squared_error: 0.0073 - val_loss: 0.3044 - val_mean_squared_error: 0.0451\n",
      "Epoch 63/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2679 - mean_squared_error: 0.0086 - val_loss: 0.3049 - val_mean_squared_error: 0.0470\n",
      "Epoch 64/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2593 - mean_squared_error: 0.0014 - val_loss: 0.3049 - val_mean_squared_error: 0.0483\n",
      "Epoch 65/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2657 - mean_squared_error: 0.0092 - val_loss: 0.3052 - val_mean_squared_error: 0.0500\n",
      "Epoch 66/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2620 - mean_squared_error: 0.0068 - val_loss: 0.3059 - val_mean_squared_error: 0.0521\n",
      "Epoch 67/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2594 - mean_squared_error: 0.0056 - val_loss: 0.3072 - val_mean_squared_error: 0.0546\n",
      "Epoch 68/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2561 - mean_squared_error: 0.0036 - val_loss: 0.3097 - val_mean_squared_error: 0.0585\n",
      "Epoch 69/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2610 - mean_squared_error: 0.0098 - val_loss: 0.3139 - val_mean_squared_error: 0.0640\n",
      "Epoch 70/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2507 - mean_squared_error: 7.6314e-04 - val_loss: 0.3178 - val_mean_squared_error: 0.0692\n",
      "Epoch 71/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2526 - mean_squared_error: 0.0040 - val_loss: 0.3194 - val_mean_squared_error: 0.0721\n",
      "Epoch 72/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2521 - mean_squared_error: 0.0049 - val_loss: 0.3204 - val_mean_squared_error: 0.0744\n",
      "Epoch 73/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2542 - mean_squared_error: 0.0082 - val_loss: 0.3174 - val_mean_squared_error: 0.0728\n",
      "Epoch 74/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2491 - mean_squared_error: 0.0044 - val_loss: 0.3147 - val_mean_squared_error: 0.0713\n",
      "Epoch 75/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.2463 - mean_squared_error: 0.0029 - val_loss: 0.3100 - val_mean_squared_error: 0.0680\n",
      "Epoch 76/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2444 - mean_squared_error: 0.0024 - val_loss: 0.3053 - val_mean_squared_error: 0.0645\n",
      "Epoch 77/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2465 - mean_squared_error: 0.0058 - val_loss: 0.3000 - val_mean_squared_error: 0.0606\n",
      "Epoch 78/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2413 - mean_squared_error: 0.0019 - val_loss: 0.2959 - val_mean_squared_error: 0.0578\n",
      "Epoch 79/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2414 - mean_squared_error: 0.0032 - val_loss: 0.2908 - val_mean_squared_error: 0.0539\n",
      "Epoch 80/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2460 - mean_squared_error: 0.0091 - val_loss: 0.2883 - val_mean_squared_error: 0.0526\n",
      "Epoch 81/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2379 - mean_squared_error: 0.0022 - val_loss: 0.2849 - val_mean_squared_error: 0.0505\n",
      "Epoch 82/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2387 - mean_squared_error: 0.0043 - val_loss: 0.2829 - val_mean_squared_error: 0.0497\n",
      "Epoch 83/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2360 - mean_squared_error: 0.0028 - val_loss: 0.2812 - val_mean_squared_error: 0.0492\n",
      "Epoch 84/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2415 - mean_squared_error: 0.0096 - val_loss: 0.2800 - val_mean_squared_error: 0.0493\n",
      "Epoch 85/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2327 - mean_squared_error: 0.0020 - val_loss: 0.2793 - val_mean_squared_error: 0.0499\n",
      "Epoch 86/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2356 - mean_squared_error: 0.0061 - val_loss: 0.2792 - val_mean_squared_error: 0.0509\n",
      "Epoch 87/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2341 - mean_squared_error: 0.0058 - val_loss: 0.2799 - val_mean_squared_error: 0.0528\n",
      "Epoch 88/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2359 - mean_squared_error: 0.0089 - val_loss: 0.2824 - val_mean_squared_error: 0.0566\n",
      "Epoch 89/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2286 - mean_squared_error: 0.0027 - val_loss: 0.2848 - val_mean_squared_error: 0.0601\n",
      "Epoch 90/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2314 - mean_squared_error: 0.0067 - val_loss: 0.2869 - val_mean_squared_error: 0.0634\n",
      "Epoch 91/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.2250 - mean_squared_error: 0.0015 - val_loss: 0.2897 - val_mean_squared_error: 0.0674\n",
      "Epoch 92/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2289 - mean_squared_error: 0.0066 - val_loss: 0.2911 - val_mean_squared_error: 0.0700\n",
      "Epoch 93/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2267 - mean_squared_error: 0.0056 - val_loss: 0.2898 - val_mean_squared_error: 0.0698\n",
      "Epoch 94/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2241 - mean_squared_error: 0.0042 - val_loss: 0.2866 - val_mean_squared_error: 0.0679\n",
      "Epoch 95/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2211 - mean_squared_error: 0.0023 - val_loss: 0.2823 - val_mean_squared_error: 0.0647\n",
      "Epoch 96/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2200 - mean_squared_error: 0.0024 - val_loss: 0.2769 - val_mean_squared_error: 0.0605\n",
      "Epoch 97/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2182 - mean_squared_error: 0.0017 - val_loss: 0.2727 - val_mean_squared_error: 0.0574\n",
      "Epoch 98/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2185 - mean_squared_error: 0.0032 - val_loss: 0.2693 - val_mean_squared_error: 0.0551\n",
      "Epoch 99/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2156 - mean_squared_error: 0.0015 - val_loss: 0.2670 - val_mean_squared_error: 0.0541\n",
      "Epoch 100/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2168 - mean_squared_error: 0.0039 - val_loss: 0.2663 - val_mean_squared_error: 0.0544\n",
      "Epoch 101/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2140 - mean_squared_error: 0.0021 - val_loss: 0.2646 - val_mean_squared_error: 0.0539\n",
      "Epoch 102/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2120 - mean_squared_error: 0.0013 - val_loss: 0.2631 - val_mean_squared_error: 0.0536\n",
      "Epoch 103/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2115 - mean_squared_error: 0.0019 - val_loss: 0.2618 - val_mean_squared_error: 0.0534\n",
      "Epoch 104/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2110 - mean_squared_error: 0.0026 - val_loss: 0.2611 - val_mean_squared_error: 0.0538\n",
      "Epoch 105/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.2154 - mean_squared_error: 0.0081 - val_loss: 0.2607 - val_mean_squared_error: 0.0545\n",
      "Epoch 106/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2079 - mean_squared_error: 0.0016 - val_loss: 0.2605 - val_mean_squared_error: 0.0554\n",
      "Epoch 107/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2116 - mean_squared_error: 0.0065 - val_loss: 0.2611 - val_mean_squared_error: 0.0570\n",
      "Epoch 108/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2085 - mean_squared_error: 0.0045 - val_loss: 0.2617 - val_mean_squared_error: 0.0587\n",
      "Epoch 109/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2062 - mean_squared_error: 0.0032 - val_loss: 0.2627 - val_mean_squared_error: 0.0608\n",
      "Epoch 110/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2155 - mean_squared_error: 0.0137 - val_loss: 0.2637 - val_mean_squared_error: 0.0629\n",
      "Epoch 111/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2055 - mean_squared_error: 0.0047 - val_loss: 0.2655 - val_mean_squared_error: 0.0658\n",
      "Epoch 112/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2017 - mean_squared_error: 0.0019 - val_loss: 0.2664 - val_mean_squared_error: 0.0677\n",
      "Epoch 113/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2060 - mean_squared_error: 0.0072 - val_loss: 0.2660 - val_mean_squared_error: 0.0683\n",
      "Epoch 114/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.2005 - mean_squared_error: 0.0028 - val_loss: 0.2645 - val_mean_squared_error: 0.0678\n",
      "Epoch 115/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2021 - mean_squared_error: 0.0055 - val_loss: 0.2618 - val_mean_squared_error: 0.0662\n",
      "Epoch 116/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1985 - mean_squared_error: 0.0028 - val_loss: 0.2593 - val_mean_squared_error: 0.0647\n",
      "Epoch 117/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2060 - mean_squared_error: 0.0114 - val_loss: 0.2575 - val_mean_squared_error: 0.0639\n",
      "Epoch 118/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1992 - mean_squared_error: 0.0057 - val_loss: 0.2568 - val_mean_squared_error: 0.0643\n",
      "Epoch 119/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1934 - mean_squared_error: 8.7245e-04 - val_loss: 0.2570 - val_mean_squared_error: 0.0655\n",
      "Epoch 120/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2025 - mean_squared_error: 0.0110 - val_loss: 0.2570 - val_mean_squared_error: 0.0666\n",
      "Epoch 121/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1916 - mean_squared_error: 0.0011 - val_loss: 0.2567 - val_mean_squared_error: 0.0672\n",
      "Epoch 122/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1922 - mean_squared_error: 0.0027 - val_loss: 0.2576 - val_mean_squared_error: 0.0692\n",
      "Epoch 123/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1936 - mean_squared_error: 0.0051 - val_loss: 0.2582 - val_mean_squared_error: 0.0707\n",
      "Epoch 124/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1950 - mean_squared_error: 0.0076 - val_loss: 0.2578 - val_mean_squared_error: 0.0714\n",
      "Epoch 125/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1981 - mean_squared_error: 0.0117 - val_loss: 0.2545 - val_mean_squared_error: 0.0691\n",
      "Epoch 126/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1896 - mean_squared_error: 0.0041 - val_loss: 0.2501 - val_mean_squared_error: 0.0656\n",
      "Epoch 127/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1871 - mean_squared_error: 0.0026 - val_loss: 0.2451 - val_mean_squared_error: 0.0616\n",
      "Epoch 128/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1866 - mean_squared_error: 0.0031 - val_loss: 0.2408 - val_mean_squared_error: 0.0582\n",
      "Epoch 129/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1846 - mean_squared_error: 0.0021 - val_loss: 0.2371 - val_mean_squared_error: 0.0555\n",
      "Epoch 130/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1908 - mean_squared_error: 0.0092 - val_loss: 0.2341 - val_mean_squared_error: 0.0535\n",
      "Epoch 131/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1849 - mean_squared_error: 0.0042 - val_loss: 0.2322 - val_mean_squared_error: 0.0525\n",
      "Epoch 132/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1816 - mean_squared_error: 0.0019 - val_loss: 0.2297 - val_mean_squared_error: 0.0509\n",
      "Epoch 133/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1817 - mean_squared_error: 0.0030 - val_loss: 0.2285 - val_mean_squared_error: 0.0506\n",
      "Epoch 134/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1835 - mean_squared_error: 0.0057 - val_loss: 0.2254 - val_mean_squared_error: 0.0485\n",
      "Epoch 135/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1871 - mean_squared_error: 0.0102 - val_loss: 0.2229 - val_mean_squared_error: 0.0469\n",
      "Epoch 136/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1789 - mean_squared_error: 0.0029 - val_loss: 0.2214 - val_mean_squared_error: 0.0464\n",
      "Epoch 137/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1776 - mean_squared_error: 0.0026 - val_loss: 0.2206 - val_mean_squared_error: 0.0465\n",
      "Epoch 138/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1762 - mean_squared_error: 0.0021 - val_loss: 0.2205 - val_mean_squared_error: 0.0473\n",
      "Epoch 139/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1849 - mean_squared_error: 0.0117 - val_loss: 0.2208 - val_mean_squared_error: 0.0485\n",
      "Epoch 140/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1749 - mean_squared_error: 0.0027 - val_loss: 0.2202 - val_mean_squared_error: 0.0488\n",
      "Epoch 141/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1780 - mean_squared_error: 0.0067 - val_loss: 0.2209 - val_mean_squared_error: 0.0504\n",
      "Epoch 142/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1734 - mean_squared_error: 0.0029 - val_loss: 0.2217 - val_mean_squared_error: 0.0521\n",
      "Epoch 143/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1721 - mean_squared_error: 0.0025 - val_loss: 0.2216 - val_mean_squared_error: 0.0529\n",
      "Epoch 144/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1703 - mean_squared_error: 0.0016 - val_loss: 0.2218 - val_mean_squared_error: 0.0540\n",
      "Epoch 145/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1702 - mean_squared_error: 0.0023 - val_loss: 0.2214 - val_mean_squared_error: 0.0544\n",
      "Epoch 146/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1688 - mean_squared_error: 0.0019 - val_loss: 0.2212 - val_mean_squared_error: 0.0551\n",
      "Epoch 147/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1682 - mean_squared_error: 0.0021 - val_loss: 0.2203 - val_mean_squared_error: 0.0550\n",
      "Epoch 148/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1694 - mean_squared_error: 0.0042 - val_loss: 0.2185 - val_mean_squared_error: 0.0541\n",
      "Epoch 149/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1664 - mean_squared_error: 0.0020 - val_loss: 0.2171 - val_mean_squared_error: 0.0536\n",
      "Epoch 150/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1699 - mean_squared_error: 0.0063 - val_loss: 0.2140 - val_mean_squared_error: 0.0513\n",
      "Epoch 151/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1734 - mean_squared_error: 0.0107 - val_loss: 0.2087 - val_mean_squared_error: 0.0468\n",
      "Epoch 152/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1631 - mean_squared_error: 0.0012 - val_loss: 0.2048 - val_mean_squared_error: 0.0438\n",
      "Epoch 153/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1635 - mean_squared_error: 0.0024 - val_loss: 0.2019 - val_mean_squared_error: 0.0417\n",
      "Epoch 154/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1648 - mean_squared_error: 0.0046 - val_loss: 0.2002 - val_mean_squared_error: 0.0409\n",
      "Epoch 155/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1604 - mean_squared_error: 0.0010 - val_loss: 0.1993 - val_mean_squared_error: 0.0407\n",
      "Epoch 156/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1591 - mean_squared_error: 5.6227e-04 - val_loss: 0.1988 - val_mean_squared_error: 0.0411\n",
      "Epoch 157/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1612 - mean_squared_error: 0.0035 - val_loss: 0.1995 - val_mean_squared_error: 0.0426\n",
      "Epoch 158/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1617 - mean_squared_error: 0.0048 - val_loss: 0.2010 - val_mean_squared_error: 0.0449\n",
      "Epoch 159/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1633 - mean_squared_error: 0.0072 - val_loss: 0.2036 - val_mean_squared_error: 0.0483\n",
      "Epoch 160/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1569 - mean_squared_error: 0.0016 - val_loss: 0.2064 - val_mean_squared_error: 0.0519\n",
      "Epoch 161/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1581 - mean_squared_error: 0.0036 - val_loss: 0.2081 - val_mean_squared_error: 0.0544\n",
      "Epoch 162/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1565 - mean_squared_error: 0.0029 - val_loss: 0.2092 - val_mean_squared_error: 0.0563\n",
      "Epoch 163/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1557 - mean_squared_error: 0.0028 - val_loss: 0.2086 - val_mean_squared_error: 0.0565\n",
      "Epoch 164/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1553 - mean_squared_error: 0.0032 - val_loss: 0.2090 - val_mean_squared_error: 0.0576\n",
      "Epoch 165/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1545 - mean_squared_error: 0.0032 - val_loss: 0.2075 - val_mean_squared_error: 0.0570\n",
      "Epoch 166/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1590 - mean_squared_error: 0.0085 - val_loss: 0.2033 - val_mean_squared_error: 0.0535\n",
      "Epoch 167/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1511 - mean_squared_error: 0.0013 - val_loss: 0.2003 - val_mean_squared_error: 0.0513\n",
      "Epoch 168/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1494 - mean_squared_error: 4.5259e-04 - val_loss: 0.1980 - val_mean_squared_error: 0.0498\n",
      "Epoch 169/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1489 - mean_squared_error: 7.0580e-04 - val_loss: 0.1966 - val_mean_squared_error: 0.0492\n",
      "Epoch 170/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1493 - mean_squared_error: 0.0019 - val_loss: 0.1955 - val_mean_squared_error: 0.0488\n",
      "Epoch 171/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1477 - mean_squared_error: 0.0010 - val_loss: 0.1939 - val_mean_squared_error: 0.0479\n",
      "Epoch 172/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1506 - mean_squared_error: 0.0046 - val_loss: 0.1924 - val_mean_squared_error: 0.0472\n",
      "Epoch 173/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1457 - mean_squared_error: 4.8455e-04 - val_loss: 0.1915 - val_mean_squared_error: 0.0470\n",
      "Epoch 174/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1458 - mean_squared_error: 0.0013 - val_loss: 0.1903 - val_mean_squared_error: 0.0466\n",
      "Epoch 175/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1445 - mean_squared_error: 7.5939e-04 - val_loss: 0.1897 - val_mean_squared_error: 0.0467\n",
      "Epoch 176/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1437 - mean_squared_error: 6.9219e-04 - val_loss: 0.1896 - val_mean_squared_error: 0.0473\n",
      "Epoch 177/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1444 - mean_squared_error: 0.0022 - val_loss: 0.1904 - val_mean_squared_error: 0.0489\n",
      "Epoch 178/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1479 - mean_squared_error: 0.0064 - val_loss: 0.1900 - val_mean_squared_error: 0.0492\n",
      "Epoch 179/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1477 - mean_squared_error: 0.0069 - val_loss: 0.1911 - val_mean_squared_error: 0.0511\n",
      "Epoch 180/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1446 - mean_squared_error: 0.0045 - val_loss: 0.1927 - val_mean_squared_error: 0.0534\n",
      "Epoch 181/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1433 - mean_squared_error: 0.0040 - val_loss: 0.1935 - val_mean_squared_error: 0.0549\n",
      "Epoch 182/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1423 - mean_squared_error: 0.0036 - val_loss: 0.1951 - val_mean_squared_error: 0.0572\n",
      "Epoch 183/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1418 - mean_squared_error: 0.0039 - val_loss: 0.1943 - val_mean_squared_error: 0.0572\n",
      "Epoch 184/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1377 - mean_squared_error: 4.8116e-04 - val_loss: 0.1931 - val_mean_squared_error: 0.0567\n",
      "Epoch 185/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1408 - mean_squared_error: 0.0043 - val_loss: 0.1922 - val_mean_squared_error: 0.0565\n",
      "Epoch 186/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1436 - mean_squared_error: 0.0078 - val_loss: 0.1925 - val_mean_squared_error: 0.0574\n",
      "Epoch 187/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1416 - mean_squared_error: 0.0065 - val_loss: 0.1923 - val_mean_squared_error: 0.0579\n",
      "Epoch 188/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1427 - mean_squared_error: 0.0083 - val_loss: 0.1930 - val_mean_squared_error: 0.0593\n",
      "Epoch 189/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1352 - mean_squared_error: 0.0015 - val_loss: 0.1931 - val_mean_squared_error: 0.0600\n",
      "Epoch 190/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1346 - mean_squared_error: 0.0016 - val_loss: 0.1926 - val_mean_squared_error: 0.0602\n",
      "Epoch 191/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1330 - mean_squared_error: 6.2097e-04 - val_loss: 0.1924 - val_mean_squared_error: 0.0606\n",
      "Epoch 192/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1356 - mean_squared_error: 0.0039 - val_loss: 0.1906 - val_mean_squared_error: 0.0596\n",
      "Epoch 193/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1353 - mean_squared_error: 0.0043 - val_loss: 0.1881 - val_mean_squared_error: 0.0577\n",
      "Epoch 194/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1310 - mean_squared_error: 5.8953e-04 - val_loss: 0.1862 - val_mean_squared_error: 0.0564\n",
      "Epoch 195/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1357 - mean_squared_error: 0.0059 - val_loss: 0.1826 - val_mean_squared_error: 0.0535\n",
      "Epoch 196/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1387 - mean_squared_error: 0.0096 - val_loss: 0.1791 - val_mean_squared_error: 0.0506\n",
      "Epoch 197/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1348 - mean_squared_error: 0.0064 - val_loss: 0.1777 - val_mean_squared_error: 0.0499\n",
      "Epoch 198/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1285 - mean_squared_error: 7.4205e-04 - val_loss: 0.1767 - val_mean_squared_error: 0.0496\n",
      "Epoch 199/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1282 - mean_squared_error: 0.0011 - val_loss: 0.1762 - val_mean_squared_error: 0.0497\n",
      "Epoch 200/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1301 - mean_squared_error: 0.0036 - val_loss: 0.1762 - val_mean_squared_error: 0.0504\n",
      "Epoch 201/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1264 - mean_squared_error: 5.8210e-04 - val_loss: 0.1762 - val_mean_squared_error: 0.0510\n",
      "Epoch 202/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1301 - mean_squared_error: 0.0049 - val_loss: 0.1763 - val_mean_squared_error: 0.0518\n",
      "Epoch 203/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1264 - mean_squared_error: 0.0019 - val_loss: 0.1766 - val_mean_squared_error: 0.0527\n",
      "Epoch 204/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1290 - mean_squared_error: 0.0051 - val_loss: 0.1770 - val_mean_squared_error: 0.0537\n",
      "Epoch 205/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1257 - mean_squared_error: 0.0024 - val_loss: 0.1781 - val_mean_squared_error: 0.0554\n",
      "Epoch 206/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1235 - mean_squared_error: 8.1938e-04 - val_loss: 0.1790 - val_mean_squared_error: 0.0570\n",
      "Epoch 207/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1249 - mean_squared_error: 0.0029 - val_loss: 0.1812 - val_mean_squared_error: 0.0597\n",
      "Epoch 208/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1264 - mean_squared_error: 0.0050 - val_loss: 0.1845 - val_mean_squared_error: 0.0636\n",
      "Epoch 209/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1221 - mean_squared_error: 0.0012 - val_loss: 0.1875 - val_mean_squared_error: 0.0672\n",
      "Epoch 210/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1264 - mean_squared_error: 0.0062 - val_loss: 0.1899 - val_mean_squared_error: 0.0702\n",
      "Epoch 211/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1210 - mean_squared_error: 0.0013 - val_loss: 0.1919 - val_mean_squared_error: 0.0728\n",
      "Epoch 212/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1235 - mean_squared_error: 0.0044 - val_loss: 0.1928 - val_mean_squared_error: 0.0743\n",
      "Epoch 213/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1200 - mean_squared_error: 0.0015 - val_loss: 0.1946 - val_mean_squared_error: 0.0767\n",
      "Epoch 214/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1208 - mean_squared_error: 0.0029 - val_loss: 0.1939 - val_mean_squared_error: 0.0765\n",
      "Epoch 215/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1205 - mean_squared_error: 0.0031 - val_loss: 0.1930 - val_mean_squared_error: 0.0763\n",
      "Epoch 216/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1172 - mean_squared_error: 4.3836e-04 - val_loss: 0.1919 - val_mean_squared_error: 0.0757\n",
      "Epoch 217/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1203 - mean_squared_error: 0.0041 - val_loss: 0.1890 - val_mean_squared_error: 0.0734\n",
      "Epoch 218/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1167 - mean_squared_error: 0.0011 - val_loss: 0.1856 - val_mean_squared_error: 0.0706\n",
      "Epoch 219/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1165 - mean_squared_error: 0.0014 - val_loss: 0.1824 - val_mean_squared_error: 0.0680\n",
      "Mean Squared Error on test set: 0.04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      "Predictions vs Actual:\n",
      "   Actual  Predicted\n",
      "0    0.70   0.685623\n",
      "1    0.50   0.529537\n",
      "2   15.11  22.173840\n",
      "3    0.20   0.291533\n",
      "4    5.30   9.487015\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load and Prepare the Data\n",
    "data = pd.read_csv('data.csv')  # Load the dataset\n",
    "X = data.drop('cv', axis=1)  # Features\n",
    "y = data['cv']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Target Scaling\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Define the Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "# Compile the Model with Adam Optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# Early Stopping Callback to Avoid Overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=300,\n",
    "                    batch_size=8,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the Model\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Mean Squared Error on test set: {mse:.2f}')\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Denormalize Predictions and Actual Values\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred)\n",
    "y_test_original = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Display Predictions vs Actual\n",
    "results = pd.DataFrame({'Actual': y_test_original.flatten(), 'Predicted': y_pred_original.flatten()})\n",
    "print(\"\\nPredictions vs Actual:\")\n",
    "print(results.head())\n",
    "\n",
    "# Visualize Predictions vs Actual Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_original, label='Actual')\n",
    "plt.plot(y_pred_original, label='Predicted', linestyle='--')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('cv')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca2344-9b62-4e68-9cd8-3bb1040d2a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1310c-3380-483f-bafa-d8a499395572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. Load the saved Keras model\n",
    "model = load_model('keras_model.h5')\n",
    "\n",
    "# 2. Load the CSV file\n",
    "# Replace 'input_data.csv' with your actual file name\n",
    "data = pd.read_csv('input_data.csv')\n",
    "\n",
    "# Preview the loaded data\n",
    "print(\"Input Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# 3. Preprocess the data\n",
    "# Ensure the data has the same columns/features as the model was trained on\n",
    "# Example: Drop unnecessary columns or perform scaling if needed\n",
    "# Assuming the model was trained on specific columns ['feature1', 'feature2', ..., 'featureN']\n",
    "input_features = data[['feature1', 'feature2', 'feature3']]  # Update with actual column names\n",
    "\n",
    "# 4. Make predictions\n",
    "predictions = model.predict(input_features)\n",
    "\n",
    "# 5. Save the predictions to a new CSV file\n",
    "output_data = data.copy()\n",
    "output_data['Predicted_Values'] = predictions  # Add predictions as a new column\n",
    "\n",
    "# Save the updated data with predictions\n",
    "output_data.to_csv('output_with_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'output_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6531378-9d3e-47f3-87a1-4a6afa964723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.6596 - mse: 1.1035 - val_loss: 0.5671 - val_mse: 0.8808 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6338 - mse: 1.2942 - val_loss: 0.5258 - val_mse: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5323 - mse: 0.9998 - val_loss: 0.5156 - val_mse: 0.8428 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5329 - mse: 1.0018 - val_loss: 0.5087 - val_mse: 0.7776 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5033 - mse: 0.9195 - val_loss: 0.5231 - val_mse: 0.7374 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4997 - mse: 0.8531 - val_loss: 0.5150 - val_mse: 0.7219 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5402 - mse: 1.0284 - val_loss: 0.5070 - val_mse: 0.7196 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5106 - mse: 0.9324 - val_loss: 0.5096 - val_mse: 0.7191 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4849 - mse: 0.8583 - val_loss: 0.5090 - val_mse: 0.7189 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4980 - mse: 0.9007 - val_loss: 0.4989 - val_mse: 0.6914 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4887 - mse: 0.8643 - val_loss: 0.4917 - val_mse: 0.6511 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4527 - mse: 0.7456 - val_loss: 0.4860 - val_mse: 0.6265 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5228 - mse: 0.9280 - val_loss: 0.4778 - val_mse: 0.6230 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5042 - mse: 0.8651 - val_loss: 0.4721 - val_mse: 0.6242 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5356 - mse: 0.9821 - val_loss: 0.4759 - val_mse: 0.6127 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4972 - mse: 0.8732 - val_loss: 0.4744 - val_mse: 0.6083 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4404 - mse: 0.6719 - val_loss: 0.4687 - val_mse: 0.6279 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4591 - mse: 0.7537 - val_loss: 0.4710 - val_mse: 0.6600 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5191 - mse: 0.9268 - val_loss: 0.4637 - val_mse: 0.6503 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4551 - mse: 0.8359 - val_loss: 0.4501 - val_mse: 0.6242 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4040 - mse: 0.6173 - val_loss: 0.4571 - val_mse: 0.5928 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4772 - mse: 0.7249 - val_loss: 0.4679 - val_mse: 0.5767 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3932 - mse: 0.5339 - val_loss: 0.4557 - val_mse: 0.5828 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4126 - mse: 0.6157 - val_loss: 0.4460 - val_mse: 0.6006 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4375 - mse: 0.7268 - val_loss: 0.4404 - val_mse: 0.6005 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4113 - mse: 0.6667 - val_loss: 0.4452 - val_mse: 0.5780 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4360 - mse: 0.6962 - val_loss: 0.4532 - val_mse: 0.5450 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4335 - mse: 0.6076 - val_loss: 0.4455 - val_mse: 0.5271 - learning_rate: 0.0010\n",
      "Epoch 29/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4252 - mse: 0.6753 - val_loss: 0.4335 - val_mse: 0.5150 - learning_rate: 0.0010\n",
      "Epoch 30/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4402 - mse: 0.6279 - val_loss: 0.4245 - val_mse: 0.5231 - learning_rate: 0.0010\n",
      "Epoch 31/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3591 - mse: 0.4669 - val_loss: 0.4263 - val_mse: 0.5393 - learning_rate: 0.0010\n",
      "Epoch 32/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4366 - mse: 0.6520 - val_loss: 0.4163 - val_mse: 0.5305 - learning_rate: 0.0010\n",
      "Epoch 33/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3956 - mse: 0.5793 - val_loss: 0.4158 - val_mse: 0.5271 - learning_rate: 0.0010\n",
      "Epoch 34/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4100 - mse: 0.5556 - val_loss: 0.4221 - val_mse: 0.5217 - learning_rate: 0.0010\n",
      "Epoch 35/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4193 - mse: 0.5593 - val_loss: 0.4105 - val_mse: 0.5255 - learning_rate: 0.0010\n",
      "Epoch 36/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4657 - mse: 0.7411 - val_loss: 0.4009 - val_mse: 0.5375 - learning_rate: 0.0010\n",
      "Epoch 37/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3623 - mse: 0.5143 - val_loss: 0.4112 - val_mse: 0.5591 - learning_rate: 0.0010\n",
      "Epoch 38/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3882 - mse: 0.5870 - val_loss: 0.4142 - val_mse: 0.5375 - learning_rate: 0.0010\n",
      "Epoch 39/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3737 - mse: 0.5741 - val_loss: 0.4074 - val_mse: 0.4828 - learning_rate: 0.0010\n",
      "Epoch 40/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4205 - mse: 0.5808 - val_loss: 0.3988 - val_mse: 0.4542 - learning_rate: 0.0010\n",
      "Epoch 41/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4084 - mse: 0.5430 - val_loss: 0.3920 - val_mse: 0.4634 - learning_rate: 0.0010\n",
      "Epoch 42/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3654 - mse: 0.4740 - val_loss: 0.3869 - val_mse: 0.4631 - learning_rate: 0.0010\n",
      "Epoch 43/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3285 - mse: 0.4128 - val_loss: 0.3811 - val_mse: 0.4601 - learning_rate: 0.0010\n",
      "Epoch 44/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3826 - mse: 0.5030 - val_loss: 0.3832 - val_mse: 0.4604 - learning_rate: 0.0010\n",
      "Epoch 45/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4071 - mse: 0.5773 - val_loss: 0.3804 - val_mse: 0.4787 - learning_rate: 0.0010\n",
      "Epoch 46/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3944 - mse: 0.5897 - val_loss: 0.3735 - val_mse: 0.5394 - learning_rate: 0.0010\n",
      "Epoch 47/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3440 - mse: 0.4867 - val_loss: 0.3615 - val_mse: 0.5112 - learning_rate: 0.0010\n",
      "Epoch 48/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3344 - mse: 0.4656 - val_loss: 0.3531 - val_mse: 0.4664 - learning_rate: 0.0010\n",
      "Epoch 49/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3513 - mse: 0.4777 - val_loss: 0.3589 - val_mse: 0.4398 - learning_rate: 0.0010\n",
      "Epoch 50/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3546 - mse: 0.4414 - val_loss: 0.3695 - val_mse: 0.4170 - learning_rate: 0.0010\n",
      "Epoch 51/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3649 - mse: 0.4502 - val_loss: 0.3707 - val_mse: 0.4105 - learning_rate: 0.0010\n",
      "Epoch 52/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3761 - mse: 0.4446 - val_loss: 0.3715 - val_mse: 0.4335 - learning_rate: 0.0010\n",
      "Epoch 53/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3656 - mse: 0.4603 - val_loss: 0.3645 - val_mse: 0.4451 - learning_rate: 0.0010\n",
      "Epoch 54/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3188 - mse: 0.3364 - val_loss: 0.3506 - val_mse: 0.4323 - learning_rate: 5.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3109 - mse: 0.3450 - val_loss: 0.3415 - val_mse: 0.4132 - learning_rate: 5.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3820 - mse: 0.4749 - val_loss: 0.3364 - val_mse: 0.3843 - learning_rate: 5.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3531 - mse: 0.4055 - val_loss: 0.3338 - val_mse: 0.3678 - learning_rate: 5.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3128 - mse: 0.3274 - val_loss: 0.3346 - val_mse: 0.3748 - learning_rate: 5.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3335 - mse: 0.4017 - val_loss: 0.3367 - val_mse: 0.3651 - learning_rate: 5.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3198 - mse: 0.3414 - val_loss: 0.3348 - val_mse: 0.3535 - learning_rate: 5.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3081 - mse: 0.3313 - val_loss: 0.3335 - val_mse: 0.3658 - learning_rate: 5.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3184 - mse: 0.3882 - val_loss: 0.3324 - val_mse: 0.3676 - learning_rate: 5.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3101 - mse: 0.3713 - val_loss: 0.3291 - val_mse: 0.3780 - learning_rate: 5.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2898 - mse: 0.2865 - val_loss: 0.3327 - val_mse: 0.4021 - learning_rate: 5.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3300 - mse: 0.3830 - val_loss: 0.3189 - val_mse: 0.3692 - learning_rate: 5.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2920 - mse: 0.2906 - val_loss: 0.3112 - val_mse: 0.3239 - learning_rate: 5.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2542 - mse: 0.2015 - val_loss: 0.3094 - val_mse: 0.2984 - learning_rate: 5.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3436 - mse: 0.4101 - val_loss: 0.3045 - val_mse: 0.2843 - learning_rate: 5.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3514 - mse: 0.3412 - val_loss: 0.2976 - val_mse: 0.2732 - learning_rate: 5.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2878 - mse: 0.2496 - val_loss: 0.2948 - val_mse: 0.2714 - learning_rate: 5.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3009 - mse: 0.2927 - val_loss: 0.2934 - val_mse: 0.2712 - learning_rate: 5.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3278 - mse: 0.3063 - val_loss: 0.2927 - val_mse: 0.2768 - learning_rate: 5.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2926 - mse: 0.2822 - val_loss: 0.3044 - val_mse: 0.3104 - learning_rate: 5.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3172 - mse: 0.3343 - val_loss: 0.3213 - val_mse: 0.3322 - learning_rate: 5.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2926 - mse: 0.2802 - val_loss: 0.3252 - val_mse: 0.3284 - learning_rate: 5.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2456 - mse: 0.2226 - val_loss: 0.3105 - val_mse: 0.2962 - learning_rate: 5.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2871 - mse: 0.2767 - val_loss: 0.3008 - val_mse: 0.2699 - learning_rate: 5.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3335 - mse: 0.3380 - val_loss: 0.3007 - val_mse: 0.2669 - learning_rate: 2.5000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2844 - mse: 0.2230 - val_loss: 0.2987 - val_mse: 0.2583 - learning_rate: 2.5000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2693 - mse: 0.2171 - val_loss: 0.2985 - val_mse: 0.2531 - learning_rate: 2.5000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2806 - mse: 0.2049 - val_loss: 0.2952 - val_mse: 0.2619 - learning_rate: 2.5000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2684 - mse: 0.2234 - val_loss: 0.2926 - val_mse: 0.2602 - learning_rate: 2.5000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2810 - mse: 0.2190 - val_loss: 0.2909 - val_mse: 0.2581 - learning_rate: 1.2500e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2855 - mse: 0.2149 - val_loss: 0.2894 - val_mse: 0.2559 - learning_rate: 1.2500e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2602 - mse: 0.2014 - val_loss: 0.2874 - val_mse: 0.2520 - learning_rate: 1.2500e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2637 - mse: 0.2125 - val_loss: 0.2856 - val_mse: 0.2494 - learning_rate: 1.2500e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2617 - mse: 0.2088 - val_loss: 0.2846 - val_mse: 0.2467 - learning_rate: 1.2500e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2981 - mse: 0.2810 - val_loss: 0.2832 - val_mse: 0.2450 - learning_rate: 1.2500e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2440 - mse: 0.2040 - val_loss: 0.2828 - val_mse: 0.2473 - learning_rate: 1.2500e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2833 - mse: 0.2593 - val_loss: 0.2831 - val_mse: 0.2476 - learning_rate: 1.2500e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2560 - mse: 0.1968 - val_loss: 0.2835 - val_mse: 0.2477 - learning_rate: 1.2500e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2685 - mse: 0.2095 - val_loss: 0.2816 - val_mse: 0.2440 - learning_rate: 1.2500e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2970 - mse: 0.3019 - val_loss: 0.2814 - val_mse: 0.2432 - learning_rate: 1.2500e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2612 - mse: 0.2094 - val_loss: 0.2815 - val_mse: 0.2391 - learning_rate: 1.2500e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2533 - mse: 0.2287 - val_loss: 0.2816 - val_mse: 0.2360 - learning_rate: 1.2500e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2842 - mse: 0.2532 - val_loss: 0.2806 - val_mse: 0.2326 - learning_rate: 1.2500e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2777 - mse: 0.2321 - val_loss: 0.2782 - val_mse: 0.2284 - learning_rate: 1.2500e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2576 - mse: 0.1790 - val_loss: 0.2761 - val_mse: 0.2246 - learning_rate: 1.2500e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2418 - mse: 0.1666 - val_loss: 0.2749 - val_mse: 0.2254 - learning_rate: 1.2500e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2222 - mse: 0.1435 - val_loss: 0.2746 - val_mse: 0.2260 - learning_rate: 1.2500e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2496 - mse: 0.1836 - val_loss: 0.2771 - val_mse: 0.2309 - learning_rate: 1.2500e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2613 - mse: 0.2025 - val_loss: 0.2799 - val_mse: 0.2357 - learning_rate: 1.2500e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2524 - mse: 0.1969 - val_loss: 0.2809 - val_mse: 0.2365 - learning_rate: 1.2500e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2754 - mse: 0.2221 - val_loss: 0.2815 - val_mse: 0.2367 - learning_rate: 1.2500e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2584 - mse: 0.2093 - val_loss: 0.2795 - val_mse: 0.2319 - learning_rate: 1.2500e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2082 - mse: 0.1720 - val_loss: 0.2781 - val_mse: 0.2274 - learning_rate: 6.2500e-05\n",
      "Epoch 107/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2608 - mse: 0.2046 - val_loss: 0.2785 - val_mse: 0.2256 - learning_rate: 6.2500e-05\n",
      "Epoch 108/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2509 - mse: 0.2152 - val_loss: 0.2785 - val_mse: 0.2237 - learning_rate: 6.2500e-05\n",
      "Epoch 109/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2563 - mse: 0.1904 - val_loss: 0.2782 - val_mse: 0.2218 - learning_rate: 6.2500e-05\n",
      "Epoch 110/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2566 - mse: 0.2099 - val_loss: 0.2778 - val_mse: 0.2224 - learning_rate: 6.2500e-05\n",
      "Epoch 111/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2617 - mse: 0.1917 - val_loss: 0.2777 - val_mse: 0.2230 - learning_rate: 3.1250e-05\n",
      "Epoch 112/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2582 - mse: 0.2144 - val_loss: 0.2774 - val_mse: 0.2241 - learning_rate: 3.1250e-05\n",
      "Epoch 113/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2675 - mse: 0.2550 - val_loss: 0.2771 - val_mse: 0.2249 - learning_rate: 3.1250e-05\n",
      "Epoch 114/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2997 - mse: 0.2647 - val_loss: 0.2769 - val_mse: 0.2261 - learning_rate: 3.1250e-05\n",
      "Epoch 115/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2616 - mse: 0.1812 - val_loss: 0.2768 - val_mse: 0.2272 - learning_rate: 3.1250e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2746 - mse: 0.2260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Test MAE: 0.9301104242114037, R2 Score: 0.7536943705333322\n",
      "Custom Accuracy (within ±10% tolerance): 11.11%\n",
      "   Predicted Value  Actual Value\n",
      "0         0.267309      0.873547\n",
      "1         0.267251      0.220000\n",
      "2         5.728942      6.890951\n",
      "3         6.754466     12.152283\n",
      "4         0.587422      0.340000\n",
      "5         0.342820      0.440278\n",
      "6         0.485341      0.370000\n",
      "7         1.073821      0.360000\n",
      "8         0.441247      0.140000\n",
      "9         0.601355      0.266344\n"
     ]
    }
   ],
   "source": [
    "#ffnn\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data1.csv')  # Replace with your dataset path\n",
    "X = data.drop('Cv', axis=1)\n",
    "y = data['Cv']\n",
    "\n",
    "# Handle possible outliers in the target\n",
    "y = np.clip(y, y.quantile(0.05), y.quantile(0.95))  # Limit to 5th-95th percentile\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale the target variable\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Build the FFNN model without backpropagation\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1]))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "# Get the model's weights directly and propagate forward (no training)\n",
    "model.set_weights([np.random.randn(*w.shape) for w in model.get_weights()])  # Initialize weights manually (random initialization)\n",
    "\n",
    "# Forward pass to make predictions (no backpropagation)\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Reverse scaling to original range for predictions and actual values\n",
    "predictions_original = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate R2 Score and Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test_original, predictions_original)\n",
    "r2 = r2_score(y_test_original, predictions_original)\n",
    "\n",
    "print(f\"Test MAE: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# Combine predictions with actual values\n",
    "results = np.concatenate(\n",
    "    (predictions_original.reshape(-1, 1), y_test_original.reshape(-1, 1)),\n",
    "    axis=1\n",
    ")\n",
    "results_df = pd.DataFrame(results, columns=['Predicted Value', 'Actual Value'])\n",
    "\n",
    "# Calculate custom accuracy (e.g., within ±10% tolerance)\n",
    "tolerance = 0.1  # 10% tolerance\n",
    "correct_predictions = np.abs(predictions_original - y_test_original) <= tolerance * y_test_original\n",
    "accuracy = np.sum(correct_predictions) / len(y_test_original) * 100\n",
    "\n",
    "# Display predictions and accuracy\n",
    "print(f\"Custom Accuracy (within ±10% tolerance): {accuracy:.2f}%\")\n",
    "print(results_df.head(10))  # Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a8bc0c-c88b-476c-903f-0850355ba2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 4.1829 - mse: 3.4926 - val_loss: 3.3830 - val_mse: 0.8924 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.4743 - mse: 4.8820 - val_loss: 3.3851 - val_mse: 0.8686 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.3040 - mse: 3.8629 - val_loss: 3.3932 - val_mse: 0.8683 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1747 - mse: 3.4133 - val_loss: 3.3842 - val_mse: 0.8501 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1287 - mse: 3.1544 - val_loss: 3.3705 - val_mse: 0.8276 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0417 - mse: 3.1230 - val_loss: 3.3592 - val_mse: 0.8030 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0828 - mse: 2.9950 - val_loss: 3.3493 - val_mse: 0.7924 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.9872 - mse: 2.9758 - val_loss: 3.3450 - val_mse: 0.7879 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8845 - mse: 2.5064 - val_loss: 3.3267 - val_mse: 0.7699 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0526 - mse: 3.1606 - val_loss: 3.3153 - val_mse: 0.7678 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7610 - mse: 2.0998 - val_loss: 3.3106 - val_mse: 0.7683 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6956 - mse: 1.9986 - val_loss: 3.2959 - val_mse: 0.7597 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7234 - mse: 2.2785 - val_loss: 3.2841 - val_mse: 0.7604 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7161 - mse: 2.1285 - val_loss: 3.2760 - val_mse: 0.7626 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6932 - mse: 2.0438 - val_loss: 3.2720 - val_mse: 0.7698 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9387 - mse: 3.1945 - val_loss: 3.2619 - val_mse: 0.7680 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7544 - mse: 2.3931 - val_loss: 3.2541 - val_mse: 0.7668 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6057 - mse: 1.9358 - val_loss: 3.2397 - val_mse: 0.7611 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6468 - mse: 1.8972 - val_loss: 3.2228 - val_mse: 0.7488 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7145 - mse: 2.1735 - val_loss: 3.2008 - val_mse: 0.7271 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.6228 - mse: 2.0497 - val_loss: 3.1732 - val_mse: 0.7010 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6052 - mse: 2.2385 - val_loss: 3.1542 - val_mse: 0.6855 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5940 - mse: 1.7821 - val_loss: 3.1411 - val_mse: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5754 - mse: 1.8990 - val_loss: 3.1285 - val_mse: 0.6810 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5066 - mse: 1.9374 - val_loss: 3.1170 - val_mse: 0.6822 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5172 - mse: 1.8770 - val_loss: 3.1037 - val_mse: 0.6812 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4384 - mse: 1.7683 - val_loss: 3.0851 - val_mse: 0.6722 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5667 - mse: 1.8834 - val_loss: 3.0693 - val_mse: 0.6665 - learning_rate: 0.0010\n",
      "Epoch 29/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6830 - mse: 2.7245 - val_loss: 3.0623 - val_mse: 0.6678 - learning_rate: 0.0010\n",
      "Epoch 30/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3356 - mse: 1.3948 - val_loss: 3.0536 - val_mse: 0.6742 - learning_rate: 0.0010\n",
      "Epoch 31/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.4972 - mse: 1.8403 - val_loss: 3.0408 - val_mse: 0.6868 - learning_rate: 0.0010\n",
      "Epoch 32/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.5121 - mse: 2.0670 - val_loss: 3.0165 - val_mse: 0.6922 - learning_rate: 0.0010\n",
      "Epoch 33/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.3719 - mse: 1.5709 - val_loss: 2.9995 - val_mse: 0.7007 - learning_rate: 0.0010\n",
      "Epoch 34/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3891 - mse: 1.5697 - val_loss: 2.9765 - val_mse: 0.7042 - learning_rate: 0.0010\n",
      "Epoch 35/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3773 - mse: 1.6618 - val_loss: 2.9618 - val_mse: 0.7124 - learning_rate: 0.0010\n",
      "Epoch 36/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4193 - mse: 1.7665 - val_loss: 2.9560 - val_mse: 0.7042 - learning_rate: 0.0010\n",
      "Epoch 37/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3920 - mse: 1.9469 - val_loss: 2.9414 - val_mse: 0.6856 - learning_rate: 0.0010\n",
      "Epoch 38/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3907 - mse: 1.7717 - val_loss: 2.9269 - val_mse: 0.6714 - learning_rate: 0.0010\n",
      "Epoch 39/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2347 - mse: 1.3454 - val_loss: 2.9201 - val_mse: 0.6685 - learning_rate: 0.0010\n",
      "Epoch 40/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2617 - mse: 1.4522 - val_loss: 2.9201 - val_mse: 0.6699 - learning_rate: 0.0010\n",
      "Epoch 41/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2864 - mse: 1.4845 - val_loss: 2.9176 - val_mse: 0.6686 - learning_rate: 0.0010\n",
      "Epoch 42/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3805 - mse: 1.8542 - val_loss: 2.9098 - val_mse: 0.6645 - learning_rate: 0.0010\n",
      "Epoch 43/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1956 - mse: 1.4610 - val_loss: 2.8976 - val_mse: 0.6572 - learning_rate: 0.0010\n",
      "Epoch 44/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2277 - mse: 1.4190 - val_loss: 2.8878 - val_mse: 0.6526 - learning_rate: 0.0010\n",
      "Epoch 45/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.2734 - mse: 1.5463 - val_loss: 2.8763 - val_mse: 0.6512 - learning_rate: 0.0010\n",
      "Epoch 46/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1342 - mse: 1.2210 - val_loss: 2.8655 - val_mse: 0.6533 - learning_rate: 0.0010\n",
      "Epoch 47/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1546 - mse: 1.3488 - val_loss: 2.8551 - val_mse: 0.6592 - learning_rate: 0.0010\n",
      "Epoch 48/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1044 - mse: 1.2823 - val_loss: 2.8469 - val_mse: 0.6525 - learning_rate: 0.0010\n",
      "Epoch 49/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.1197 - mse: 1.5235 - val_loss: 2.8316 - val_mse: 0.6392 - learning_rate: 0.0010\n",
      "Epoch 50/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1947 - mse: 1.5215 - val_loss: 2.8193 - val_mse: 0.6288 - learning_rate: 0.0010\n",
      "Epoch 51/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.0345 - mse: 1.2854 - val_loss: 2.8000 - val_mse: 0.6218 - learning_rate: 0.0010\n",
      "Epoch 52/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0884 - mse: 1.4405 - val_loss: 2.7781 - val_mse: 0.6184 - learning_rate: 0.0010\n",
      "Epoch 53/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.0746 - mse: 1.3926 - val_loss: 2.7481 - val_mse: 0.6090 - learning_rate: 0.0010\n",
      "Epoch 54/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8971 - mse: 0.8731 - val_loss: 2.7283 - val_mse: 0.5971 - learning_rate: 0.0010\n",
      "Epoch 55/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9108 - mse: 0.9772 - val_loss: 2.7144 - val_mse: 0.5905 - learning_rate: 0.0010\n",
      "Epoch 56/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1080 - mse: 1.4333 - val_loss: 2.7117 - val_mse: 0.5911 - learning_rate: 0.0010\n",
      "Epoch 57/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9867 - mse: 1.4534 - val_loss: 2.7116 - val_mse: 0.6045 - learning_rate: 0.0010\n",
      "Epoch 58/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9167 - mse: 1.0572 - val_loss: 2.7107 - val_mse: 0.6197 - learning_rate: 0.0010\n",
      "Epoch 59/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8911 - mse: 0.9604 - val_loss: 2.7150 - val_mse: 0.6355 - learning_rate: 0.0010\n",
      "Epoch 60/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9311 - mse: 1.0914 - val_loss: 2.7072 - val_mse: 0.6353 - learning_rate: 0.0010\n",
      "Epoch 61/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9660 - mse: 1.2144 - val_loss: 2.6941 - val_mse: 0.6225 - learning_rate: 0.0010\n",
      "Epoch 62/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8667 - mse: 0.9986 - val_loss: 2.6771 - val_mse: 0.6096 - learning_rate: 0.0010\n",
      "Epoch 63/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9591 - mse: 1.2911 - val_loss: 2.6664 - val_mse: 0.6015 - learning_rate: 0.0010\n",
      "Epoch 64/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8249 - mse: 0.9029 - val_loss: 2.6631 - val_mse: 0.6104 - learning_rate: 0.0010\n",
      "Epoch 65/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.8050 - mse: 0.9840 - val_loss: 2.6534 - val_mse: 0.6120 - learning_rate: 0.0010\n",
      "Epoch 66/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9339 - mse: 1.3819 - val_loss: 2.6334 - val_mse: 0.6095 - learning_rate: 0.0010\n",
      "Epoch 67/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9055 - mse: 1.3569 - val_loss: 2.6155 - val_mse: 0.5927 - learning_rate: 0.0010\n",
      "Epoch 68/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8194 - mse: 1.0519 - val_loss: 2.6024 - val_mse: 0.5821 - learning_rate: 0.0010\n",
      "Epoch 69/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8615 - mse: 1.1588 - val_loss: 2.5825 - val_mse: 0.5703 - learning_rate: 0.0010\n",
      "Epoch 70/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8957 - mse: 1.4202 - val_loss: 2.5677 - val_mse: 0.5693 - learning_rate: 0.0010\n",
      "Epoch 71/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7611 - mse: 1.0226 - val_loss: 2.5551 - val_mse: 0.5711 - learning_rate: 0.0010\n",
      "Epoch 72/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7989 - mse: 1.0450 - val_loss: 2.5436 - val_mse: 0.5803 - learning_rate: 0.0010\n",
      "Epoch 73/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7765 - mse: 1.1103 - val_loss: 2.5290 - val_mse: 0.5885 - learning_rate: 0.0010\n",
      "Epoch 74/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8220 - mse: 1.1958 - val_loss: 2.5085 - val_mse: 0.5762 - learning_rate: 0.0010\n",
      "Epoch 75/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7701 - mse: 1.1286 - val_loss: 2.4964 - val_mse: 0.5741 - learning_rate: 0.0010\n",
      "Epoch 76/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7718 - mse: 1.1493 - val_loss: 2.4838 - val_mse: 0.5781 - learning_rate: 0.0010\n",
      "Epoch 77/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6789 - mse: 0.8183 - val_loss: 2.4661 - val_mse: 0.5834 - learning_rate: 0.0010\n",
      "Epoch 78/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7705 - mse: 1.2009 - val_loss: 2.4499 - val_mse: 0.5936 - learning_rate: 0.0010\n",
      "Epoch 79/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6552 - mse: 0.8722 - val_loss: 2.4344 - val_mse: 0.5995 - learning_rate: 0.0010\n",
      "Epoch 80/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.6832 - mse: 1.0149 - val_loss: 2.4213 - val_mse: 0.6053 - learning_rate: 0.0010\n",
      "Epoch 81/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.6900 - mse: 1.1122 - val_loss: 2.4183 - val_mse: 0.6303 - learning_rate: 0.0010\n",
      "Epoch 82/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.6843 - mse: 1.0686 - val_loss: 2.4126 - val_mse: 0.6431 - learning_rate: 0.0010\n",
      "Epoch 83/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6349 - mse: 1.0876 - val_loss: 2.3983 - val_mse: 0.6597 - learning_rate: 0.0010\n",
      "Epoch 84/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6737 - mse: 1.0927 - val_loss: 2.3836 - val_mse: 0.6550 - learning_rate: 0.0010\n",
      "Epoch 85/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6135 - mse: 0.8787 - val_loss: 2.3663 - val_mse: 0.6292 - learning_rate: 0.0010\n",
      "Epoch 86/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6000 - mse: 0.8936 - val_loss: 2.3576 - val_mse: 0.6171 - learning_rate: 0.0010\n",
      "Epoch 87/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.6252 - mse: 1.1058 - val_loss: 2.3472 - val_mse: 0.6087 - learning_rate: 0.0010\n",
      "Epoch 88/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5413 - mse: 0.8243 - val_loss: 2.3455 - val_mse: 0.6174 - learning_rate: 0.0010\n",
      "Epoch 89/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5457 - mse: 0.9126 - val_loss: 2.3415 - val_mse: 0.6237 - learning_rate: 0.0010\n",
      "Epoch 90/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4972 - mse: 0.8251 - val_loss: 2.3370 - val_mse: 0.6224 - learning_rate: 0.0010\n",
      "Epoch 91/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.4921 - mse: 0.9591 - val_loss: 2.3248 - val_mse: 0.6139 - learning_rate: 0.0010\n",
      "Epoch 92/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5205 - mse: 0.9042 - val_loss: 2.3070 - val_mse: 0.6070 - learning_rate: 0.0010\n",
      "Epoch 93/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.5032 - mse: 0.9231 - val_loss: 2.2815 - val_mse: 0.5915 - learning_rate: 0.0010\n",
      "Epoch 94/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4998 - mse: 0.8038 - val_loss: 2.2644 - val_mse: 0.5836 - learning_rate: 0.0010\n",
      "Epoch 95/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4207 - mse: 0.8234 - val_loss: 2.2453 - val_mse: 0.5784 - learning_rate: 0.0010\n",
      "Epoch 96/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3876 - mse: 0.6933 - val_loss: 2.2274 - val_mse: 0.5799 - learning_rate: 0.0010\n",
      "Epoch 97/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4380 - mse: 0.7989 - val_loss: 2.2010 - val_mse: 0.5512 - learning_rate: 0.0010\n",
      "Epoch 98/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.3470 - mse: 0.6230 - val_loss: 2.1911 - val_mse: 0.5207 - learning_rate: 0.0010\n",
      "Epoch 99/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.3677 - mse: 0.7576 - val_loss: 2.1803 - val_mse: 0.5204 - learning_rate: 0.0010\n",
      "Epoch 100/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3620 - mse: 0.6940 - val_loss: 2.1736 - val_mse: 0.5219 - learning_rate: 0.0010\n",
      "Epoch 101/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5129 - mse: 1.1903 - val_loss: 2.1676 - val_mse: 0.5266 - learning_rate: 0.0010\n",
      "Epoch 102/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3137 - mse: 0.7085 - val_loss: 2.1633 - val_mse: 0.5288 - learning_rate: 0.0010\n",
      "Epoch 103/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.3585 - mse: 0.7660 - val_loss: 2.1602 - val_mse: 0.5316 - learning_rate: 0.0010\n",
      "Epoch 104/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.3216 - mse: 0.6865 - val_loss: 2.1481 - val_mse: 0.5025 - learning_rate: 0.0010\n",
      "Epoch 105/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3352 - mse: 0.6609 - val_loss: 2.1343 - val_mse: 0.4849 - learning_rate: 0.0010\n",
      "Epoch 106/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2776 - mse: 0.6613 - val_loss: 2.1169 - val_mse: 0.4759 - learning_rate: 0.0010\n",
      "Epoch 107/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2643 - mse: 0.6880 - val_loss: 2.1007 - val_mse: 0.4735 - learning_rate: 0.0010\n",
      "Epoch 108/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2997 - mse: 0.7021 - val_loss: 2.0802 - val_mse: 0.4629 - learning_rate: 0.0010\n",
      "Epoch 109/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2793 - mse: 0.7803 - val_loss: 2.0699 - val_mse: 0.4576 - learning_rate: 0.0010\n",
      "Epoch 110/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3118 - mse: 0.9002 - val_loss: 2.0537 - val_mse: 0.4659 - learning_rate: 0.0010\n",
      "Epoch 111/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2269 - mse: 0.7074 - val_loss: 2.0393 - val_mse: 0.4788 - learning_rate: 0.0010\n",
      "Epoch 112/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2737 - mse: 0.7602 - val_loss: 2.0304 - val_mse: 0.4961 - learning_rate: 0.0010\n",
      "Epoch 113/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2046 - mse: 0.7190 - val_loss: 2.0203 - val_mse: 0.4935 - learning_rate: 0.0010\n",
      "Epoch 114/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2013 - mse: 0.7023 - val_loss: 2.0290 - val_mse: 0.4848 - learning_rate: 0.0010\n",
      "Epoch 115/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2687 - mse: 0.8109 - val_loss: 2.0308 - val_mse: 0.4671 - learning_rate: 0.0010\n",
      "Epoch 116/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2603 - mse: 0.8985 - val_loss: 2.0184 - val_mse: 0.4652 - learning_rate: 0.0010\n",
      "Epoch 117/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0861 - mse: 0.5157 - val_loss: 2.0085 - val_mse: 0.4633 - learning_rate: 0.0010\n",
      "Epoch 118/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2217 - mse: 0.7926 - val_loss: 1.9901 - val_mse: 0.4612 - learning_rate: 0.0010\n",
      "Epoch 119/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2064 - mse: 0.8327 - val_loss: 1.9724 - val_mse: 0.4725 - learning_rate: 0.0010\n",
      "Epoch 120/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1709 - mse: 0.7568 - val_loss: 1.9608 - val_mse: 0.4796 - learning_rate: 0.0010\n",
      "Epoch 121/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1115 - mse: 0.5242 - val_loss: 1.9541 - val_mse: 0.4847 - learning_rate: 0.0010\n",
      "Epoch 122/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1331 - mse: 0.6983 - val_loss: 1.9452 - val_mse: 0.4871 - learning_rate: 0.0010\n",
      "Epoch 123/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1475 - mse: 0.7014 - val_loss: 1.9433 - val_mse: 0.4866 - learning_rate: 0.0010\n",
      "Epoch 124/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1258 - mse: 0.6942 - val_loss: 1.9424 - val_mse: 0.4665 - learning_rate: 0.0010\n",
      "Epoch 125/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1162 - mse: 0.6643 - val_loss: 1.9394 - val_mse: 0.4536 - learning_rate: 0.0010\n",
      "Epoch 126/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0829 - mse: 0.6641 - val_loss: 1.9325 - val_mse: 0.4394 - learning_rate: 0.0010\n",
      "Epoch 127/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.0701 - mse: 0.7008 - val_loss: 1.9228 - val_mse: 0.4369 - learning_rate: 0.0010\n",
      "Epoch 128/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9877 - mse: 0.3797 - val_loss: 1.9105 - val_mse: 0.4338 - learning_rate: 0.0010\n",
      "Epoch 129/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0013 - mse: 0.5257 - val_loss: 1.9013 - val_mse: 0.4366 - learning_rate: 0.0010\n",
      "Epoch 130/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0437 - mse: 0.5730 - val_loss: 1.8954 - val_mse: 0.4363 - learning_rate: 0.0010\n",
      "Epoch 131/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9634 - mse: 0.5333 - val_loss: 1.8891 - val_mse: 0.4343 - learning_rate: 0.0010\n",
      "Epoch 132/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9677 - mse: 0.5088 - val_loss: 1.8816 - val_mse: 0.4380 - learning_rate: 0.0010\n",
      "Epoch 133/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0750 - mse: 0.8337 - val_loss: 1.8762 - val_mse: 0.4462 - learning_rate: 0.0010\n",
      "Epoch 134/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9171 - mse: 0.4940 - val_loss: 1.8731 - val_mse: 0.4700 - learning_rate: 0.0010\n",
      "Epoch 135/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9291 - mse: 0.5041 - val_loss: 1.8678 - val_mse: 0.4919 - learning_rate: 0.0010\n",
      "Epoch 136/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9894 - mse: 0.6049 - val_loss: 1.8586 - val_mse: 0.4976 - learning_rate: 0.0010\n",
      "Epoch 137/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.9467 - mse: 0.5319 - val_loss: 1.8351 - val_mse: 0.4775 - learning_rate: 0.0010\n",
      "Epoch 138/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9570 - mse: 0.6435 - val_loss: 1.8141 - val_mse: 0.4680 - learning_rate: 0.0010\n",
      "Epoch 139/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9040 - mse: 0.5649 - val_loss: 1.8022 - val_mse: 0.4729 - learning_rate: 0.0010\n",
      "Epoch 140/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9083 - mse: 0.5321 - val_loss: 1.7898 - val_mse: 0.4627 - learning_rate: 0.0010\n",
      "Epoch 141/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9335 - mse: 0.5907 - val_loss: 1.7794 - val_mse: 0.4568 - learning_rate: 0.0010\n",
      "Epoch 142/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8292 - mse: 0.4434 - val_loss: 1.7700 - val_mse: 0.4515 - learning_rate: 0.0010\n",
      "Epoch 143/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8673 - mse: 0.5166 - val_loss: 1.7780 - val_mse: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 144/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9398 - mse: 0.6284 - val_loss: 1.7799 - val_mse: 0.4785 - learning_rate: 0.0010\n",
      "Epoch 145/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8713 - mse: 0.5748 - val_loss: 1.7773 - val_mse: 0.4938 - learning_rate: 0.0010\n",
      "Epoch 146/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7748 - mse: 0.3562 - val_loss: 1.7689 - val_mse: 0.4926 - learning_rate: 0.0010\n",
      "Epoch 147/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8308 - mse: 0.5365 - val_loss: 1.7539 - val_mse: 0.4724 - learning_rate: 0.0010\n",
      "Epoch 148/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8291 - mse: 0.5513 - val_loss: 1.7386 - val_mse: 0.4695 - learning_rate: 0.0010\n",
      "Epoch 149/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7350 - mse: 0.3927 - val_loss: 1.7251 - val_mse: 0.4607 - learning_rate: 0.0010\n",
      "Epoch 150/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7459 - mse: 0.3737 - val_loss: 1.7020 - val_mse: 0.4323 - learning_rate: 0.0010\n",
      "Epoch 151/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7555 - mse: 0.5481 - val_loss: 1.6799 - val_mse: 0.4052 - learning_rate: 0.0010\n",
      "Epoch 152/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7418 - mse: 0.4806 - val_loss: 1.6719 - val_mse: 0.3975 - learning_rate: 0.0010\n",
      "Epoch 153/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7732 - mse: 0.4932 - val_loss: 1.6640 - val_mse: 0.4076 - learning_rate: 0.0010\n",
      "Epoch 154/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7649 - mse: 0.5199 - val_loss: 1.6578 - val_mse: 0.4163 - learning_rate: 0.0010\n",
      "Epoch 155/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8118 - mse: 0.6034 - val_loss: 1.6514 - val_mse: 0.4157 - learning_rate: 0.0010\n",
      "Epoch 156/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6987 - mse: 0.4100 - val_loss: 1.6402 - val_mse: 0.4138 - learning_rate: 0.0010\n",
      "Epoch 157/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7021 - mse: 0.4568 - val_loss: 1.6298 - val_mse: 0.4216 - learning_rate: 0.0010\n",
      "Epoch 158/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6747 - mse: 0.4066 - val_loss: 1.6309 - val_mse: 0.4404 - learning_rate: 0.0010\n",
      "Epoch 159/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7169 - mse: 0.4774 - val_loss: 1.6264 - val_mse: 0.4580 - learning_rate: 0.0010\n",
      "Epoch 160/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6659 - mse: 0.3465 - val_loss: 1.6142 - val_mse: 0.4542 - learning_rate: 0.0010\n",
      "Epoch 161/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6432 - mse: 0.3838 - val_loss: 1.5986 - val_mse: 0.4311 - learning_rate: 0.0010\n",
      "Epoch 162/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6408 - mse: 0.3432 - val_loss: 1.5967 - val_mse: 0.4615 - learning_rate: 0.0010\n",
      "Epoch 163/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7062 - mse: 0.5647 - val_loss: 1.5950 - val_mse: 0.5165 - learning_rate: 0.0010\n",
      "Epoch 164/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6453 - mse: 0.4258 - val_loss: 1.6039 - val_mse: 0.5690 - learning_rate: 0.0010\n",
      "Epoch 165/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6707 - mse: 0.5185 - val_loss: 1.6129 - val_mse: 0.5966 - learning_rate: 0.0010\n",
      "Epoch 166/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7172 - mse: 0.6249 - val_loss: 1.5934 - val_mse: 0.5674 - learning_rate: 0.0010\n",
      "Epoch 167/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6234 - mse: 0.4639 - val_loss: 1.5564 - val_mse: 0.5198 - learning_rate: 0.0010\n",
      "Epoch 168/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6097 - mse: 0.4285 - val_loss: 1.5351 - val_mse: 0.4937 - learning_rate: 0.0010\n",
      "Epoch 169/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5604 - mse: 0.3674 - val_loss: 1.5375 - val_mse: 0.5029 - learning_rate: 0.0010\n",
      "Epoch 170/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5322 - mse: 0.2917 - val_loss: 1.5250 - val_mse: 0.4772 - learning_rate: 0.0010\n",
      "Epoch 171/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6341 - mse: 0.5017 - val_loss: 1.5066 - val_mse: 0.4241 - learning_rate: 0.0010\n",
      "Epoch 172/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5677 - mse: 0.3713 - val_loss: 1.4959 - val_mse: 0.4063 - learning_rate: 0.0010\n",
      "Epoch 173/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5498 - mse: 0.3726 - val_loss: 1.4877 - val_mse: 0.4111 - learning_rate: 0.0010\n",
      "Epoch 174/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5985 - mse: 0.4374 - val_loss: 1.4930 - val_mse: 0.4336 - learning_rate: 0.0010\n",
      "Epoch 175/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5865 - mse: 0.4490 - val_loss: 1.4879 - val_mse: 0.4345 - learning_rate: 0.0010\n",
      "Epoch 176/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5491 - mse: 0.3947 - val_loss: 1.4764 - val_mse: 0.4173 - learning_rate: 0.0010\n",
      "Epoch 177/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4512 - mse: 0.2260 - val_loss: 1.4614 - val_mse: 0.4206 - learning_rate: 0.0010\n",
      "Epoch 178/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5591 - mse: 0.4248 - val_loss: 1.4444 - val_mse: 0.4252 - learning_rate: 0.0010\n",
      "Epoch 179/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5114 - mse: 0.3286 - val_loss: 1.4248 - val_mse: 0.4059 - learning_rate: 0.0010\n",
      "Epoch 180/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4931 - mse: 0.3358 - val_loss: 1.4083 - val_mse: 0.3967 - learning_rate: 0.0010\n",
      "Epoch 181/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5212 - mse: 0.3561 - val_loss: 1.4055 - val_mse: 0.4163 - learning_rate: 0.0010\n",
      "Epoch 182/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5190 - mse: 0.4455 - val_loss: 1.4162 - val_mse: 0.4501 - learning_rate: 0.0010\n",
      "Epoch 183/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4633 - mse: 0.3738 - val_loss: 1.4079 - val_mse: 0.4537 - learning_rate: 0.0010\n",
      "Epoch 184/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4567 - mse: 0.3676 - val_loss: 1.3946 - val_mse: 0.4133 - learning_rate: 0.0010\n",
      "Epoch 185/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4984 - mse: 0.4972 - val_loss: 1.4003 - val_mse: 0.4087 - learning_rate: 0.0010\n",
      "Epoch 186/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4822 - mse: 0.3749 - val_loss: 1.4003 - val_mse: 0.4307 - learning_rate: 0.0010\n",
      "Epoch 187/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4485 - mse: 0.3955 - val_loss: 1.3914 - val_mse: 0.4350 - learning_rate: 0.0010\n",
      "Epoch 188/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4833 - mse: 0.4408 - val_loss: 1.3823 - val_mse: 0.4046 - learning_rate: 0.0010\n",
      "Epoch 189/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4707 - mse: 0.4886 - val_loss: 1.3761 - val_mse: 0.3724 - learning_rate: 0.0010\n",
      "Epoch 190/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4256 - mse: 0.3507 - val_loss: 1.3670 - val_mse: 0.3417 - learning_rate: 0.0010\n",
      "Epoch 191/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3676 - mse: 0.2731 - val_loss: 1.3538 - val_mse: 0.3275 - learning_rate: 0.0010\n",
      "Epoch 192/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3735 - mse: 0.2948 - val_loss: 1.3431 - val_mse: 0.3206 - learning_rate: 0.0010\n",
      "Epoch 193/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4096 - mse: 0.3933 - val_loss: 1.3322 - val_mse: 0.3148 - learning_rate: 0.0010\n",
      "Epoch 194/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3740 - mse: 0.4062 - val_loss: 1.3220 - val_mse: 0.3119 - learning_rate: 0.0010\n",
      "Epoch 195/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3544 - mse: 0.3253 - val_loss: 1.3136 - val_mse: 0.3211 - learning_rate: 0.0010\n",
      "Epoch 196/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3412 - mse: 0.3473 - val_loss: 1.3012 - val_mse: 0.3422 - learning_rate: 0.0010\n",
      "Epoch 197/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3633 - mse: 0.3733 - val_loss: 1.2989 - val_mse: 0.3872 - learning_rate: 0.0010\n",
      "Epoch 198/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3149 - mse: 0.3241 - val_loss: 1.2918 - val_mse: 0.3931 - learning_rate: 0.0010\n",
      "Epoch 199/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3524 - mse: 0.3473 - val_loss: 1.2839 - val_mse: 0.4021 - learning_rate: 0.0010\n",
      "Epoch 200/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2607 - mse: 0.2443 - val_loss: 1.2714 - val_mse: 0.3902 - learning_rate: 0.0010\n",
      "Epoch 201/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2624 - mse: 0.2036 - val_loss: 1.2631 - val_mse: 0.3857 - learning_rate: 0.0010\n",
      "Epoch 202/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3070 - mse: 0.3083 - val_loss: 1.2494 - val_mse: 0.3790 - learning_rate: 0.0010\n",
      "Epoch 203/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2919 - mse: 0.3400 - val_loss: 1.2398 - val_mse: 0.3774 - learning_rate: 0.0010\n",
      "Epoch 204/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2971 - mse: 0.3285 - val_loss: 1.2355 - val_mse: 0.3675 - learning_rate: 0.0010\n",
      "Epoch 205/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2316 - mse: 0.2417 - val_loss: 1.2331 - val_mse: 0.3518 - learning_rate: 0.0010\n",
      "Epoch 206/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2433 - mse: 0.2564 - val_loss: 1.2252 - val_mse: 0.3138 - learning_rate: 0.0010\n",
      "Epoch 207/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2214 - mse: 0.2543 - val_loss: 1.2143 - val_mse: 0.3248 - learning_rate: 0.0010\n",
      "Epoch 208/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2139 - mse: 0.2128 - val_loss: 1.2097 - val_mse: 0.3604 - learning_rate: 0.0010\n",
      "Epoch 209/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2375 - mse: 0.2572 - val_loss: 1.2336 - val_mse: 0.4160 - learning_rate: 0.0010\n",
      "Epoch 210/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2185 - mse: 0.2537 - val_loss: 1.2358 - val_mse: 0.4381 - learning_rate: 0.0010\n",
      "Epoch 211/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2413 - mse: 0.2947 - val_loss: 1.2425 - val_mse: 0.4533 - learning_rate: 0.0010\n",
      "Epoch 212/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2255 - mse: 0.2860 - val_loss: 1.2570 - val_mse: 0.4883 - learning_rate: 0.0010\n",
      "Epoch 213/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2685 - mse: 0.4563 - val_loss: 1.2450 - val_mse: 0.4637 - learning_rate: 0.0010\n",
      "Epoch 214/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2392 - mse: 0.3846 - val_loss: 1.2275 - val_mse: 0.4302 - learning_rate: 5.0000e-04\n",
      "Epoch 215/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2321 - mse: 0.3500 - val_loss: 1.2116 - val_mse: 0.4042 - learning_rate: 5.0000e-04\n",
      "Epoch 216/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1816 - mse: 0.2216 - val_loss: 1.1899 - val_mse: 0.3689 - learning_rate: 5.0000e-04\n",
      "Epoch 217/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1588 - mse: 0.2565 - val_loss: 1.1767 - val_mse: 0.3515 - learning_rate: 5.0000e-04\n",
      "Epoch 218/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2178 - mse: 0.3533 - val_loss: 1.1737 - val_mse: 0.3523 - learning_rate: 5.0000e-04\n",
      "Epoch 219/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1586 - mse: 0.2621 - val_loss: 1.1675 - val_mse: 0.3499 - learning_rate: 5.0000e-04\n",
      "Epoch 220/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1049 - mse: 0.1396 - val_loss: 1.1716 - val_mse: 0.3603 - learning_rate: 5.0000e-04\n",
      "Epoch 221/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1618 - mse: 0.2527 - val_loss: 1.1814 - val_mse: 0.3805 - learning_rate: 5.0000e-04\n",
      "Epoch 222/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1562 - mse: 0.2128 - val_loss: 1.1735 - val_mse: 0.3684 - learning_rate: 5.0000e-04\n",
      "Epoch 223/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1854 - mse: 0.3246 - val_loss: 1.1542 - val_mse: 0.3382 - learning_rate: 5.0000e-04\n",
      "Epoch 224/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1736 - mse: 0.3111 - val_loss: 1.1440 - val_mse: 0.3223 - learning_rate: 5.0000e-04\n",
      "Epoch 225/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1742 - mse: 0.2644 - val_loss: 1.1437 - val_mse: 0.3120 - learning_rate: 5.0000e-04\n",
      "Epoch 226/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1684 - mse: 0.2683 - val_loss: 1.1480 - val_mse: 0.3162 - learning_rate: 5.0000e-04\n",
      "Epoch 227/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1843 - mse: 0.3657 - val_loss: 1.1501 - val_mse: 0.3162 - learning_rate: 5.0000e-04\n",
      "Epoch 228/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1430 - mse: 0.2442 - val_loss: 1.1485 - val_mse: 0.3271 - learning_rate: 5.0000e-04\n",
      "Epoch 229/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1446 - mse: 0.2569 - val_loss: 1.1474 - val_mse: 0.3403 - learning_rate: 5.0000e-04\n",
      "Epoch 230/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1672 - mse: 0.2991 - val_loss: 1.1428 - val_mse: 0.3531 - learning_rate: 5.0000e-04\n",
      "Epoch 231/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1885 - mse: 0.3254 - val_loss: 1.1363 - val_mse: 0.3580 - learning_rate: 5.0000e-04\n",
      "Epoch 232/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1179 - mse: 0.2725 - val_loss: 1.1382 - val_mse: 0.3749 - learning_rate: 5.0000e-04\n",
      "Epoch 233/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1449 - mse: 0.2380 - val_loss: 1.1463 - val_mse: 0.3955 - learning_rate: 5.0000e-04\n",
      "Epoch 234/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1825 - mse: 0.3486 - val_loss: 1.1393 - val_mse: 0.3895 - learning_rate: 5.0000e-04\n",
      "Epoch 235/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1509 - mse: 0.3465 - val_loss: 1.1409 - val_mse: 0.3963 - learning_rate: 5.0000e-04\n",
      "Epoch 236/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1515 - mse: 0.2824 - val_loss: 1.1414 - val_mse: 0.4041 - learning_rate: 5.0000e-04\n",
      "Epoch 237/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0743 - mse: 0.1976 - val_loss: 1.1412 - val_mse: 0.4092 - learning_rate: 2.5000e-04\n",
      "Epoch 238/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1218 - mse: 0.3241 - val_loss: 1.1412 - val_mse: 0.4133 - learning_rate: 2.5000e-04\n",
      "Epoch 239/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1344 - mse: 0.2992 - val_loss: 1.1346 - val_mse: 0.4036 - learning_rate: 2.5000e-04\n",
      "Epoch 240/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1200 - mse: 0.3034 - val_loss: 1.1235 - val_mse: 0.3855 - learning_rate: 2.5000e-04\n",
      "Epoch 241/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1405 - mse: 0.3917 - val_loss: 1.1216 - val_mse: 0.3858 - learning_rate: 2.5000e-04\n",
      "Epoch 242/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2541 - mse: 0.5070 - val_loss: 1.1207 - val_mse: 0.3843 - learning_rate: 2.5000e-04\n",
      "Epoch 243/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0944 - mse: 0.2353 - val_loss: 1.1138 - val_mse: 0.3706 - learning_rate: 2.5000e-04\n",
      "Epoch 244/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0573 - mse: 0.2173 - val_loss: 1.1042 - val_mse: 0.3522 - learning_rate: 2.5000e-04\n",
      "Epoch 245/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0911 - mse: 0.2372 - val_loss: 1.0999 - val_mse: 0.3435 - learning_rate: 2.5000e-04\n",
      "Epoch 246/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1006 - mse: 0.2644 - val_loss: 1.0985 - val_mse: 0.3416 - learning_rate: 2.5000e-04\n",
      "Epoch 247/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1214 - mse: 0.3250 - val_loss: 1.0949 - val_mse: 0.3368 - learning_rate: 2.5000e-04\n",
      "Epoch 248/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0929 - mse: 0.2598 - val_loss: 1.0858 - val_mse: 0.3234 - learning_rate: 2.5000e-04\n",
      "Epoch 249/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0880 - mse: 0.2301 - val_loss: 1.0806 - val_mse: 0.3168 - learning_rate: 2.5000e-04\n",
      "Epoch 250/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0886 - mse: 0.3085 - val_loss: 1.0787 - val_mse: 0.3177 - learning_rate: 2.5000e-04\n",
      "Epoch 251/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0816 - mse: 0.2410 - val_loss: 1.0775 - val_mse: 0.3183 - learning_rate: 2.5000e-04\n",
      "Epoch 252/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1435 - mse: 0.3436 - val_loss: 1.0721 - val_mse: 0.3118 - learning_rate: 2.5000e-04\n",
      "Epoch 253/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0821 - mse: 0.2414 - val_loss: 1.0689 - val_mse: 0.3103 - learning_rate: 2.5000e-04\n",
      "Epoch 254/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1825 - mse: 0.4627 - val_loss: 1.0654 - val_mse: 0.3060 - learning_rate: 2.5000e-04\n",
      "Epoch 255/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0166 - mse: 0.1630 - val_loss: 1.0650 - val_mse: 0.3078 - learning_rate: 2.5000e-04\n",
      "Epoch 256/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0752 - mse: 0.2455 - val_loss: 1.0630 - val_mse: 0.3076 - learning_rate: 2.5000e-04\n",
      "Epoch 257/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0872 - mse: 0.2548 - val_loss: 1.0604 - val_mse: 0.3066 - learning_rate: 2.5000e-04\n",
      "Epoch 258/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0066 - mse: 0.1510 - val_loss: 1.0571 - val_mse: 0.3040 - learning_rate: 2.5000e-04\n",
      "Epoch 259/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0615 - mse: 0.2803 - val_loss: 1.0483 - val_mse: 0.2919 - learning_rate: 2.5000e-04\n",
      "Epoch 260/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0712 - mse: 0.1994 - val_loss: 1.0412 - val_mse: 0.2796 - learning_rate: 2.5000e-04\n",
      "Epoch 261/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0263 - mse: 0.1990 - val_loss: 1.0366 - val_mse: 0.2743 - learning_rate: 2.5000e-04\n",
      "Epoch 262/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0563 - mse: 0.2517 - val_loss: 1.0351 - val_mse: 0.2753 - learning_rate: 2.5000e-04\n",
      "Epoch 263/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0627 - mse: 0.2807 - val_loss: 1.0380 - val_mse: 0.2867 - learning_rate: 2.5000e-04\n",
      "Epoch 264/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0840 - mse: 0.3538 - val_loss: 1.0404 - val_mse: 0.2944 - learning_rate: 2.5000e-04\n",
      "Epoch 265/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0586 - mse: 0.2853 - val_loss: 1.0426 - val_mse: 0.3007 - learning_rate: 2.5000e-04\n",
      "Epoch 266/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0529 - mse: 0.2614 - val_loss: 1.0444 - val_mse: 0.3053 - learning_rate: 2.5000e-04\n",
      "Epoch 267/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0724 - mse: 0.2406 - val_loss: 1.0448 - val_mse: 0.3103 - learning_rate: 2.5000e-04\n",
      "Epoch 268/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9819 - mse: 0.1528 - val_loss: 1.0453 - val_mse: 0.3133 - learning_rate: 1.2500e-04\n",
      "Epoch 269/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0769 - mse: 0.2520 - val_loss: 1.0419 - val_mse: 0.3085 - learning_rate: 1.2500e-04\n",
      "Epoch 270/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0457 - mse: 0.2214 - val_loss: 1.0401 - val_mse: 0.3077 - learning_rate: 1.2500e-04\n",
      "Epoch 271/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0151 - mse: 0.1875 - val_loss: 1.0392 - val_mse: 0.3082 - learning_rate: 1.2500e-04\n",
      "Epoch 272/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0593 - mse: 0.2513 - val_loss: 1.0327 - val_mse: 0.2968 - learning_rate: 1.2500e-04\n",
      "Epoch 273/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0298 - mse: 0.2301 - val_loss: 1.0283 - val_mse: 0.2879 - learning_rate: 1.2500e-04\n",
      "Epoch 274/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0811 - mse: 0.2802 - val_loss: 1.0229 - val_mse: 0.2784 - learning_rate: 1.2500e-04\n",
      "Epoch 275/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0624 - mse: 0.3359 - val_loss: 1.0201 - val_mse: 0.2734 - learning_rate: 1.2500e-04\n",
      "Epoch 276/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0675 - mse: 0.2663 - val_loss: 1.0206 - val_mse: 0.2762 - learning_rate: 1.2500e-04\n",
      "Epoch 277/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0744 - mse: 0.2581 - val_loss: 1.0228 - val_mse: 0.2821 - learning_rate: 1.2500e-04\n",
      "Epoch 278/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0343 - mse: 0.1811 - val_loss: 1.0245 - val_mse: 0.2878 - learning_rate: 1.2500e-04\n",
      "Epoch 279/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9948 - mse: 0.1687 - val_loss: 1.0270 - val_mse: 0.2934 - learning_rate: 1.2500e-04\n",
      "Epoch 280/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0193 - mse: 0.2006 - val_loss: 1.0352 - val_mse: 0.3110 - learning_rate: 1.2500e-04\n",
      "Epoch 281/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0954 - mse: 0.2748 - val_loss: 1.0378 - val_mse: 0.3169 - learning_rate: 6.2500e-05\n",
      "Epoch 282/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0144 - mse: 0.1931 - val_loss: 1.0390 - val_mse: 0.3197 - learning_rate: 6.2500e-05\n",
      "Epoch 283/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0376 - mse: 0.2388 - val_loss: 1.0371 - val_mse: 0.3158 - learning_rate: 6.2500e-05\n",
      "Epoch 284/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0304 - mse: 0.2373 - val_loss: 1.0358 - val_mse: 0.3127 - learning_rate: 6.2500e-05\n",
      "Epoch 285/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0284 - mse: 0.2564 - val_loss: 1.0346 - val_mse: 0.3116 - learning_rate: 6.2500e-05\n",
      "Epoch 286/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0208 - mse: 0.2020 - val_loss: 1.0343 - val_mse: 0.3117 - learning_rate: 3.1250e-05\n",
      "Epoch 287/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0240 - mse: 0.3118 - val_loss: 1.0318 - val_mse: 0.3058 - learning_rate: 3.1250e-05\n",
      "Epoch 288/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9914 - mse: 0.1713 - val_loss: 1.0307 - val_mse: 0.3040 - learning_rate: 3.1250e-05\n",
      "Epoch 289/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0529 - mse: 0.2819 - val_loss: 1.0305 - val_mse: 0.3046 - learning_rate: 3.1250e-05\n",
      "Epoch 290/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0510 - mse: 0.2280 - val_loss: 1.0303 - val_mse: 0.3056 - learning_rate: 3.1250e-05\n",
      "Epoch 291/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1386 - mse: 0.3706 - val_loss: 1.0292 - val_mse: 0.3027 - learning_rate: 1.5625e-05\n",
      "Epoch 292/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0296 - mse: 0.2818 - val_loss: 1.0291 - val_mse: 0.3021 - learning_rate: 1.5625e-05\n",
      "Epoch 293/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0016 - mse: 0.1596 - val_loss: 1.0283 - val_mse: 0.3006 - learning_rate: 1.5625e-05\n",
      "Epoch 294/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0403 - mse: 0.2370 - val_loss: 1.0283 - val_mse: 0.3010 - learning_rate: 1.5625e-05\n",
      "Epoch 295/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0242 - mse: 0.1878 - val_loss: 1.0281 - val_mse: 0.3022 - learning_rate: 1.5625e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0201 - mse: 0.2734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "Test MAE: 0.9305831891465272, R2 Score: 0.7020436238397598\n",
      "Custom Accuracy (within ±10% tolerance): 7.41%\n",
      "   Predicted Value  Actual Value\n",
      "0         0.174434      0.873547\n",
      "1         0.456355      0.220000\n",
      "2         4.544136      6.890951\n",
      "3         5.485657     12.152283\n",
      "4         0.452799      0.340000\n",
      "5         0.432799      0.440278\n",
      "6         0.189704      0.370000\n",
      "7         0.622993      0.360000\n",
      "8         0.294844      0.140000\n",
      "9         0.295362      0.266344\n"
     ]
    }
   ],
   "source": [
    "#include back probagation\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data1.csv')  # Replace with your dataset path\n",
    "X = data.drop('Cv', axis=1)\n",
    "y = data['Cv']\n",
    "\n",
    "# Handle possible outliers in the target\n",
    "y = np.clip(y, y.quantile(0.05), y.quantile(0.95))  # Limit to 5th-95th percentile\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale the target variable\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Build the FFNN model with improvements\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], kernel_regularizer=l2(0.01)))  # L2 regularization\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())  # Batch Normalization\n",
    "model.add(Dropout(0.4))  # Increased dropout for better regularization\n",
    "\n",
    "# Additional hidden layers\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "# Compile the model with an advanced optimizer\n",
    "optimizer = Nadam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mae', metrics=['mse'])\n",
    "\n",
    "# Callbacks: Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Reverse scaling to original range for predictions and actual values\n",
    "predictions_original = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate R2 Score and Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test_original, predictions_original)\n",
    "r2 = r2_score(y_test_original, predictions_original)\n",
    "\n",
    "print(f\"Test MAE: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# Combine predictions with actual values\n",
    "results = np.concatenate(\n",
    "    (predictions_original.reshape(-1, 1), y_test_original.reshape(-1, 1)),\n",
    "    axis=1\n",
    ")\n",
    "results_df = pd.DataFrame(results, columns=['Predicted Value', 'Actual Value'])\n",
    "\n",
    "# Calculate custom accuracy (e.g., within ±10% tolerance)\n",
    "tolerance = 0.1  # 10% tolerance\n",
    "correct_predictions = np.abs(predictions_original - y_test_original) <= tolerance * y_test_original\n",
    "accuracy = np.sum(correct_predictions) / len(y_test_original) * 100\n",
    "\n",
    "# Display predictions and accuracy\n",
    "print(f\"Custom Accuracy (within ±10% tolerance): {accuracy:.2f}%\")\n",
    "print(results_df.head(10))  # Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70836f69-4018-4a6d-8d93-9884a576f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.8338207343335283, R2 Score: 0.7785638638644596\n",
      "Custom Accuracy (within ±10% tolerance): 77.78%\n",
      "   Predicted Value  Actual Value\n",
      "0         0.290310      0.873547\n",
      "1         0.342604      0.220000\n",
      "2         4.661028      6.890951\n",
      "3         6.147208     12.152283\n",
      "4         0.360666      0.340000\n",
      "5         0.547820      0.440278\n",
      "6         0.395860      0.370000\n",
      "7         2.767772      0.360000\n",
      "8         0.075518      0.140000\n",
      "9         0.264877      0.266344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data1.csv')  # Replace with your dataset path\n",
    "X = data.drop('Cv', axis=1)\n",
    "y = data['Cv']\n",
    "\n",
    "# Handle possible outliers in the target\n",
    "y = np.clip(y, y.quantile(0.05), y.quantile(0.95))  # Limit to 5th-95th percentile\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable on the test data\n",
    "predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Test MAE: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# Combine predictions with actual values for a comparison\n",
    "results = np.concatenate((predictions.reshape(-1, 1), y_test.values.reshape(-1, 1)), axis=1)\n",
    "results_df = pd.DataFrame(results, columns=['Predicted Value', 'Actual Value'])\n",
    "\n",
    "# Calculate custom accuracy (e.g., within ±10% tolerance)\n",
    "tolerance = 0.6  # 10% tolerance\n",
    "correct_predictions = np.abs(predictions - y_test) <= tolerance * y_test\n",
    "accuracy = np.sum(correct_predictions) / len(y_test) * 100\n",
    "\n",
    "# Display predictions and accuracy\n",
    "print(f\"Custom Accuracy (within ±10% tolerance): {accuracy:.2f}%\")\n",
    "print(results_df.head(10))  # Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acaa4d26-b599-4c22-b36d-3401027989ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkpr2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 48.6826 - mae: 49.1791 - val_loss: 53.7955 - val_mae: 54.2955\n",
      "Epoch 2/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.8843 - mae: 47.3827 - val_loss: 53.1254 - val_mae: 53.6254\n",
      "Epoch 3/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.7916 - mae: 45.2903 - val_loss: 51.8079 - val_mae: 52.3063\n",
      "Epoch 4/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.0594 - mae: 41.5511 - val_loss: 49.6428 - val_mae: 50.1395\n",
      "Epoch 5/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.9399 - mae: 37.4370 - val_loss: 46.5026 - val_mae: 47.0010\n",
      "Epoch 6/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.9419 - mae: 33.4409 - val_loss: 42.6119 - val_mae: 43.1100\n",
      "Epoch 7/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.8492 - mae: 30.3463 - val_loss: 38.4048 - val_mae: 38.9023\n",
      "Epoch 8/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.3776 - mae: 26.8741 - val_loss: 34.0868 - val_mae: 34.5795\n",
      "Epoch 9/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.9088 - mae: 25.4047 - val_loss: 30.5825 - val_mae: 31.0783\n",
      "Epoch 10/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.0436 - mae: 24.5419 - val_loss: 28.2476 - val_mae: 28.7447\n",
      "Epoch 11/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.0782 - mae: 23.5737 - val_loss: 26.7488 - val_mae: 27.2472\n",
      "Epoch 12/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.2781 - mae: 23.7733 - val_loss: 26.0451 - val_mae: 26.5440\n",
      "Epoch 13/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.0092 - mae: 23.5045 - val_loss: 25.4995 - val_mae: 25.9952\n",
      "Epoch 14/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.9762 - mae: 23.4705 - val_loss: 25.2083 - val_mae: 25.7044\n",
      "Epoch 15/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.7425 - mae: 23.2387 - val_loss: 25.1391 - val_mae: 25.6363\n",
      "Epoch 16/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.3204 - mae: 22.8135 - val_loss: 24.9505 - val_mae: 25.4442\n",
      "Epoch 17/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.5883 - mae: 23.0842 - val_loss: 24.8541 - val_mae: 25.3520\n",
      "Epoch 18/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.7755 - mae: 21.2688 - val_loss: 25.0323 - val_mae: 25.5312\n",
      "Epoch 19/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.9547 - mae: 22.4492 - val_loss: 24.7816 - val_mae: 25.2788\n",
      "Epoch 20/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.2467 - mae: 21.7397 - val_loss: 24.6487 - val_mae: 25.1423\n",
      "Epoch 21/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.8116 - mae: 22.3062 - val_loss: 24.7542 - val_mae: 25.2538\n",
      "Epoch 22/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.9807 - mae: 22.4760 - val_loss: 24.7616 - val_mae: 25.2611\n",
      "Epoch 23/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.7252 - mae: 20.2171 - val_loss: 24.9390 - val_mae: 25.4355\n",
      "Epoch 24/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.7792 - mae: 21.2729 - val_loss: 25.1666 - val_mae: 25.6592\n",
      "Epoch 25/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.7455 - mae: 22.2394 - val_loss: 25.2545 - val_mae: 25.7545\n",
      "Epoch 26/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.7434 - mae: 21.2382 - val_loss: 25.4075 - val_mae: 25.9053\n",
      "Epoch 27/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.4538 - mae: 21.9500 - val_loss: 25.3284 - val_mae: 25.8259\n",
      "Epoch 28/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.5483 - mae: 22.0418 - val_loss: 25.4286 - val_mae: 25.9252\n",
      "Epoch 29/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.5112 - mae: 22.0045 - val_loss: 25.6278 - val_mae: 26.1226\n",
      "Epoch 30/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.2240 - mae: 21.7163 - val_loss: 25.5888 - val_mae: 26.0849\n",
      "Epoch 31/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.3885 - mae: 21.8827 - val_loss: 25.7832 - val_mae: 26.2787\n",
      "Epoch 32/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.5657 - mae: 21.0612 - val_loss: 25.6844 - val_mae: 26.1808\n",
      "Epoch 33/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.5318 - mae: 21.0219 - val_loss: 25.8508 - val_mae: 26.3470\n",
      "Epoch 34/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.9564 - mae: 21.4445 - val_loss: 25.9839 - val_mae: 26.4804\n",
      "Epoch 35/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.5487 - mae: 21.0452 - val_loss: 26.0618 - val_mae: 26.5596\n",
      "Epoch 36/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.1217 - mae: 20.6134 - val_loss: 25.8825 - val_mae: 26.3780\n",
      "Epoch 37/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19.9507 - mae: 20.4431 - val_loss: 25.9907 - val_mae: 26.4872\n",
      "Epoch 38/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.9689 - mae: 20.4598 - val_loss: 25.7535 - val_mae: 26.2503\n",
      "Epoch 39/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.3932 - mae: 20.8901 - val_loss: 26.0650 - val_mae: 26.5567\n",
      "Epoch 40/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.2388 - mae: 20.7333 - val_loss: 26.0318 - val_mae: 26.5243\n",
      "Epoch 41/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.2254 - mae: 20.7207 - val_loss: 26.1565 - val_mae: 26.6533\n",
      "Epoch 42/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.1134 - mae: 20.6067 - val_loss: 26.0701 - val_mae: 26.5675\n",
      "Epoch 43/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.9245 - mae: 19.4190 - val_loss: 26.2117 - val_mae: 26.7055\n",
      "Epoch 44/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.7139 - mae: 21.2073 - val_loss: 26.1568 - val_mae: 26.6531\n",
      "Epoch 45/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.0808 - mae: 19.5729 - val_loss: 26.3254 - val_mae: 26.8224\n",
      "Epoch 46/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20.4071 - mae: 20.9029 - val_loss: 26.4788 - val_mae: 26.9764\n",
      "Epoch 47/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.2619 - mae: 19.7526 - val_loss: 26.2809 - val_mae: 26.7749\n",
      "Epoch 48/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.8977 - mae: 20.3926 - val_loss: 26.4529 - val_mae: 26.9452\n",
      "Epoch 49/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.9986 - mae: 20.4939 - val_loss: 26.6905 - val_mae: 27.1828\n",
      "Epoch 50/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.6705 - mae: 20.1632 - val_loss: 26.5722 - val_mae: 27.0678\n",
      "Epoch 51/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.9108 - mae: 20.4058 - val_loss: 26.3525 - val_mae: 26.8450\n",
      "Epoch 52/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.6269 - mae: 20.1218 - val_loss: 26.4162 - val_mae: 26.9071\n",
      "Epoch 53/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.4477 - mae: 20.9378 - val_loss: 26.4432 - val_mae: 26.9388\n",
      "Epoch 54/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.2580 - mae: 18.7503 - val_loss: 26.7214 - val_mae: 27.2167\n",
      "Epoch 55/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.9138 - mae: 19.4062 - val_loss: 26.6662 - val_mae: 27.1596\n",
      "Epoch 56/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.5072 - mae: 19.0000 - val_loss: 26.2649 - val_mae: 26.7579\n",
      "Epoch 57/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.9739 - mae: 19.4698 - val_loss: 26.5278 - val_mae: 27.0200\n",
      "Epoch 58/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.4020 - mae: 18.8912 - val_loss: 26.8457 - val_mae: 27.3397\n",
      "Epoch 59/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.9675 - mae: 19.4612 - val_loss: 26.3990 - val_mae: 26.8947\n",
      "Epoch 60/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.6356 - mae: 19.1288 - val_loss: 26.5974 - val_mae: 27.0924\n",
      "Epoch 61/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.5804 - mae: 19.0746 - val_loss: 26.3685 - val_mae: 26.8644\n",
      "Epoch 62/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.0479 - mae: 19.5415 - val_loss: 26.7985 - val_mae: 27.2934\n",
      "Epoch 63/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.9503 - mae: 18.4418 - val_loss: 26.5818 - val_mae: 27.0771\n",
      "Epoch 64/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.8081 - mae: 19.3037 - val_loss: 26.6910 - val_mae: 27.1829\n",
      "Epoch 65/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.0750 - mae: 18.5694 - val_loss: 26.8524 - val_mae: 27.3399\n",
      "Epoch 66/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.9192 - mae: 18.4118 - val_loss: 26.8718 - val_mae: 27.3576\n",
      "Epoch 67/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18.3789 - mae: 18.8718 - val_loss: 26.7975 - val_mae: 27.2895\n",
      "Epoch 68/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.0632 - mae: 18.5593 - val_loss: 27.0533 - val_mae: 27.5484\n",
      "Epoch 69/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.6559 - mae: 18.1491 - val_loss: 27.3818 - val_mae: 27.8729\n",
      "Epoch 70/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.5946 - mae: 18.0852 - val_loss: 27.1232 - val_mae: 27.6212\n",
      "Epoch 71/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.0940 - mae: 18.5813 - val_loss: 27.1689 - val_mae: 27.6602\n",
      "Epoch 72/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.2784 - mae: 17.7720 - val_loss: 27.4240 - val_mae: 27.9149\n",
      "Epoch 73/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17.0513 - mae: 17.5386 - val_loss: 27.2206 - val_mae: 27.7178\n",
      "Epoch 74/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.5367 - mae: 18.0288 - val_loss: 27.5736 - val_mae: 28.0699\n",
      "Epoch 75/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.3254 - mae: 19.8182 - val_loss: 27.3184 - val_mae: 27.8091\n",
      "Epoch 76/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.5982 - mae: 17.0881 - val_loss: 27.2092 - val_mae: 27.7046\n",
      "Epoch 77/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.4398 - mae: 17.9334 - val_loss: 27.2278 - val_mae: 27.7169\n",
      "Epoch 78/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.1164 - mae: 16.6082 - val_loss: 27.4751 - val_mae: 27.9669\n",
      "Epoch 79/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.3990 - mae: 18.8872 - val_loss: 27.4877 - val_mae: 27.9849\n",
      "Epoch 80/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.7312 - mae: 18.2260 - val_loss: 27.4894 - val_mae: 27.9838\n",
      "Epoch 81/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.2289 - mae: 17.7213 - val_loss: 27.5900 - val_mae: 28.0832\n",
      "Epoch 82/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.9528 - mae: 17.4447 - val_loss: 27.5103 - val_mae: 28.0049\n",
      "Epoch 83/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.4222 - mae: 17.9160 - val_loss: 27.2509 - val_mae: 27.7442\n",
      "Epoch 84/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.6514 - mae: 17.1424 - val_loss: 27.1758 - val_mae: 27.6720\n",
      "Epoch 85/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.8720 - mae: 16.3659 - val_loss: 27.3469 - val_mae: 27.8367\n",
      "Epoch 86/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.6019 - mae: 17.0901 - val_loss: 27.6306 - val_mae: 28.1251\n",
      "Epoch 87/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.9184 - mae: 17.4127 - val_loss: 27.8000 - val_mae: 28.2985\n",
      "Epoch 88/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.5652 - mae: 17.0573 - val_loss: 27.4342 - val_mae: 27.9294\n",
      "Epoch 89/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.2837 - mae: 17.7746 - val_loss: 27.5034 - val_mae: 28.0004\n",
      "Epoch 90/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.5017 - mae: 16.9964 - val_loss: 27.9966 - val_mae: 28.4916\n",
      "Epoch 91/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.9881 - mae: 16.4820 - val_loss: 27.6822 - val_mae: 28.1783\n",
      "Epoch 92/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.7980 - mae: 17.2878 - val_loss: 27.3848 - val_mae: 27.8797\n",
      "Epoch 93/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.8071 - mae: 16.2922 - val_loss: 27.3986 - val_mae: 27.8931\n",
      "Epoch 94/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.0604 - mae: 16.5542 - val_loss: 27.5192 - val_mae: 28.0133\n",
      "Epoch 95/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.3033 - mae: 16.7979 - val_loss: 27.6414 - val_mae: 28.1401\n",
      "Epoch 96/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.5986 - mae: 17.0908 - val_loss: 27.6869 - val_mae: 28.1831\n",
      "Epoch 97/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.1136 - mae: 16.6050 - val_loss: 27.4305 - val_mae: 27.9286\n",
      "Epoch 98/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.3713 - mae: 16.8657 - val_loss: 27.3135 - val_mae: 27.8112\n",
      "Epoch 99/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.9871 - mae: 15.4732 - val_loss: 27.6501 - val_mae: 28.1476\n",
      "Epoch 100/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.4483 - mae: 16.9363 - val_loss: 27.8072 - val_mae: 28.3051\n",
      "Epoch 101/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.6963 - mae: 16.1841 - val_loss: 27.7577 - val_mae: 28.2556\n",
      "Epoch 102/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.2606 - mae: 16.7524 - val_loss: 27.8194 - val_mae: 28.3186\n",
      "Epoch 103/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.8459 - mae: 15.3340 - val_loss: 27.5347 - val_mae: 28.0340\n",
      "Epoch 104/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.4246 - mae: 15.9172 - val_loss: 27.4501 - val_mae: 27.9399\n",
      "Epoch 105/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.7878 - mae: 15.2774 - val_loss: 27.4573 - val_mae: 27.9521\n",
      "Epoch 106/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.7013 - mae: 15.1922 - val_loss: 27.8112 - val_mae: 28.3031\n",
      "Epoch 107/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.3685 - mae: 14.8617 - val_loss: 27.8344 - val_mae: 28.3281\n",
      "Epoch 108/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.2613 - mae: 15.7538 - val_loss: 27.6989 - val_mae: 28.1959\n",
      "Epoch 109/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.1022 - mae: 14.5929 - val_loss: 27.8431 - val_mae: 28.3393\n",
      "Epoch 110/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.8278 - mae: 15.3210 - val_loss: 27.7481 - val_mae: 28.2455\n",
      "Epoch 111/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.4629 - mae: 15.9543 - val_loss: 27.8450 - val_mae: 28.3416\n",
      "Epoch 112/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.8749 - mae: 15.3691 - val_loss: 27.9560 - val_mae: 28.4529\n",
      "Epoch 113/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.1502 - mae: 15.6425 - val_loss: 27.8745 - val_mae: 28.3689\n",
      "Epoch 114/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.4665 - mae: 14.9597 - val_loss: 27.9435 - val_mae: 28.4431\n",
      "Epoch 115/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.2654 - mae: 13.7562 - val_loss: 27.8991 - val_mae: 28.3936\n",
      "Epoch 116/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.7977 - mae: 16.2899 - val_loss: 27.9303 - val_mae: 28.4265\n",
      "Epoch 117/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15.4579 - mae: 15.9496 - val_loss: 28.0444 - val_mae: 28.5353\n",
      "Epoch 118/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.8965 - mae: 15.3900 - val_loss: 28.0348 - val_mae: 28.5345\n",
      "Epoch 119/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.5796 - mae: 15.0699 - val_loss: 27.7901 - val_mae: 28.2884\n",
      "Epoch 120/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.3840 - mae: 14.8766 - val_loss: 27.6979 - val_mae: 28.1949\n",
      "Epoch 121/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.4584 - mae: 14.9561 - val_loss: 28.2856 - val_mae: 28.7821\n",
      "Epoch 122/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.7489 - mae: 15.2364 - val_loss: 28.0900 - val_mae: 28.5835\n",
      "Epoch 123/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.0674 - mae: 14.5587 - val_loss: 27.9643 - val_mae: 28.4635\n",
      "Epoch 124/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.1319 - mae: 14.6238 - val_loss: 28.1725 - val_mae: 28.6723\n",
      "Epoch 125/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.6224 - mae: 15.1128 - val_loss: 28.1878 - val_mae: 28.6878\n",
      "Epoch 126/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.6829 - mae: 14.1696 - val_loss: 28.1932 - val_mae: 28.6927\n",
      "Epoch 127/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.2189 - mae: 13.7055 - val_loss: 28.2844 - val_mae: 28.7810\n",
      "Epoch 128/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.4328 - mae: 14.9231 - val_loss: 28.4669 - val_mae: 28.9651\n",
      "Epoch 129/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.0245 - mae: 13.5110 - val_loss: 27.9265 - val_mae: 28.4213\n",
      "Epoch 130/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.5439 - mae: 14.0352 - val_loss: 28.2918 - val_mae: 28.7898\n",
      "Epoch 131/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.1704 - mae: 13.6594 - val_loss: 28.3542 - val_mae: 28.8533\n",
      "Epoch 132/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.5779 - mae: 14.0681 - val_loss: 28.3404 - val_mae: 28.8395\n",
      "Epoch 133/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.2715 - mae: 14.7617 - val_loss: 28.6788 - val_mae: 29.1757\n",
      "Epoch 134/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.5626 - mae: 14.0542 - val_loss: 28.5465 - val_mae: 29.0441\n",
      "Epoch 135/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.3290 - mae: 14.8175 - val_loss: 28.2716 - val_mae: 28.7709\n",
      "Epoch 136/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.8721 - mae: 13.3640 - val_loss: 28.6300 - val_mae: 29.1252\n",
      "Epoch 137/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.8167 - mae: 14.3099 - val_loss: 28.2943 - val_mae: 28.7909\n",
      "Epoch 138/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.1707 - mae: 13.6629 - val_loss: 28.2615 - val_mae: 28.7615\n",
      "Epoch 139/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.8518 - mae: 14.3458 - val_loss: 28.2909 - val_mae: 28.7904\n",
      "Epoch 140/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.4902 - mae: 13.9801 - val_loss: 28.2904 - val_mae: 28.7875\n",
      "Epoch 141/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.4717 - mae: 14.9664 - val_loss: 28.4218 - val_mae: 28.9194\n",
      "Epoch 142/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.7417 - mae: 14.2328 - val_loss: 28.6640 - val_mae: 29.1640\n",
      "Epoch 143/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.0856 - mae: 13.5785 - val_loss: 28.6109 - val_mae: 29.1109\n",
      "Epoch 144/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.8069 - mae: 14.3021 - val_loss: 28.5998 - val_mae: 29.0949\n",
      "Epoch 145/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.2407 - mae: 13.7322 - val_loss: 28.5944 - val_mae: 29.0944\n",
      "Epoch 146/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.3039 - mae: 12.7918 - val_loss: 28.7412 - val_mae: 29.2412\n",
      "Epoch 147/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.2570 - mae: 13.7515 - val_loss: 28.4032 - val_mae: 28.9021\n",
      "Epoch 148/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.8562 - mae: 13.3461 - val_loss: 28.6083 - val_mae: 29.1082\n",
      "Epoch 149/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.2349 - mae: 13.7288 - val_loss: 28.9457 - val_mae: 29.4413\n",
      "Epoch 150/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.6019 - mae: 13.0949 - val_loss: 28.3289 - val_mae: 28.8287\n",
      "Epoch 151/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.1399 - mae: 12.6295 - val_loss: 28.5085 - val_mae: 29.0085\n",
      "Epoch 152/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.6643 - mae: 13.1594 - val_loss: 28.7901 - val_mae: 29.2901\n",
      "Epoch 153/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.7420 - mae: 13.2301 - val_loss: 28.7017 - val_mae: 29.1983\n",
      "Epoch 154/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3066 - mae: 12.7887 - val_loss: 28.5833 - val_mae: 29.0802\n",
      "Epoch 155/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.8173 - mae: 12.3043 - val_loss: 28.9481 - val_mae: 29.4473\n",
      "Epoch 156/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.6239 - mae: 12.1132 - val_loss: 28.7287 - val_mae: 29.2282\n",
      "Epoch 157/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.8724 - mae: 13.3648 - val_loss: 28.6410 - val_mae: 29.1385\n",
      "Epoch 158/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.1690 - mae: 12.6572 - val_loss: 28.3280 - val_mae: 28.8266\n",
      "Epoch 159/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.6570 - mae: 13.1518 - val_loss: 28.6065 - val_mae: 29.1048\n",
      "Epoch 160/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.7145 - mae: 13.2002 - val_loss: 29.0630 - val_mae: 29.5616\n",
      "Epoch 161/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.4360 - mae: 11.9285 - val_loss: 28.9940 - val_mae: 29.4939\n",
      "Epoch 162/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.4001 - mae: 12.8906 - val_loss: 28.7247 - val_mae: 29.2213\n",
      "Epoch 163/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.1269 - mae: 12.6144 - val_loss: 29.0366 - val_mae: 29.5356\n",
      "Epoch 164/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.0998 - mae: 13.5905 - val_loss: 28.8131 - val_mae: 29.3122\n",
      "Epoch 165/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.2840 - mae: 12.7723 - val_loss: 29.2193 - val_mae: 29.7141\n",
      "Epoch 166/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5350 - mae: 13.0256 - val_loss: 29.0297 - val_mae: 29.5267\n",
      "Epoch 167/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.5886 - mae: 12.0777 - val_loss: 28.9642 - val_mae: 29.4621\n",
      "Epoch 168/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.3626 - mae: 12.8532 - val_loss: 29.4492 - val_mae: 29.9474\n",
      "Epoch 169/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.0386 - mae: 12.5300 - val_loss: 29.1415 - val_mae: 29.6378\n",
      "Epoch 170/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.3137 - mae: 12.8046 - val_loss: 29.1147 - val_mae: 29.6111\n",
      "Epoch 171/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7743 - mae: 11.2621 - val_loss: 29.2668 - val_mae: 29.7632\n",
      "Epoch 172/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.3569 - mae: 11.8464 - val_loss: 29.4290 - val_mae: 29.9244\n",
      "Epoch 173/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0909 - mae: 11.5764 - val_loss: 29.3850 - val_mae: 29.8827\n",
      "Epoch 174/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.3136 - mae: 11.8051 - val_loss: 29.3342 - val_mae: 29.8324\n",
      "Epoch 175/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.5866 - mae: 12.0816 - val_loss: 29.0582 - val_mae: 29.5556\n",
      "Epoch 176/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.9411 - mae: 11.4319 - val_loss: 29.2318 - val_mae: 29.7299\n",
      "Epoch 177/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7650 - mae: 11.2572 - val_loss: 29.3018 - val_mae: 29.8009\n",
      "Epoch 178/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.3428 - mae: 11.8328 - val_loss: 28.8917 - val_mae: 29.3853\n",
      "Epoch 179/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5894 - mae: 11.0798 - val_loss: 29.7019 - val_mae: 30.2007\n",
      "Epoch 180/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0070 - mae: 11.4961 - val_loss: 29.1325 - val_mae: 29.6319\n",
      "Epoch 181/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.5856 - mae: 12.0778 - val_loss: 29.2927 - val_mae: 29.7905\n",
      "Epoch 182/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.7011 - mae: 12.1911 - val_loss: 29.2187 - val_mae: 29.7159\n",
      "Epoch 183/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.4339 - mae: 11.9232 - val_loss: 29.1877 - val_mae: 29.6861\n",
      "Epoch 184/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.7268 - mae: 11.2190 - val_loss: 28.9613 - val_mae: 29.4603\n",
      "Epoch 185/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.2391 - mae: 11.7301 - val_loss: 28.9511 - val_mae: 29.4511\n",
      "Epoch 186/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.7061 - mae: 11.1884 - val_loss: 29.0061 - val_mae: 29.5060\n",
      "Epoch 187/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6659 - mae: 11.1580 - val_loss: 29.2170 - val_mae: 29.7114\n",
      "Epoch 188/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4481 - mae: 11.9378 - val_loss: 29.4637 - val_mae: 29.9574\n",
      "Epoch 189/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4638 - mae: 11.9561 - val_loss: 29.4479 - val_mae: 29.9471\n",
      "Epoch 190/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0780 - mae: 10.5693 - val_loss: 29.4019 - val_mae: 29.8969\n",
      "Epoch 191/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3730 - mae: 10.8650 - val_loss: 29.3406 - val_mae: 29.8361\n",
      "Epoch 192/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2111 - mae: 10.6958 - val_loss: 29.6306 - val_mae: 30.1306\n",
      "Epoch 193/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7742 - mae: 11.2612 - val_loss: 29.5677 - val_mae: 30.0648\n",
      "Epoch 194/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3927 - mae: 10.8830 - val_loss: 29.7106 - val_mae: 30.2099\n",
      "Epoch 195/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.4029 - mae: 10.8897 - val_loss: 29.3141 - val_mae: 29.8103\n",
      "Epoch 196/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.4399 - mae: 10.9326 - val_loss: 29.1802 - val_mae: 29.6755\n",
      "Epoch 197/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8875 - mae: 10.3798 - val_loss: 29.1841 - val_mae: 29.6814\n",
      "Epoch 198/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.3801 - mae: 10.8677 - val_loss: 29.4416 - val_mae: 29.9361\n",
      "Epoch 199/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.6615 - mae: 11.1492 - val_loss: 29.4082 - val_mae: 29.9066\n",
      "Epoch 200/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8709 - mae: 11.3560 - val_loss: 29.2282 - val_mae: 29.7242\n",
      "Epoch 201/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.9602 - mae: 11.4484 - val_loss: 29.0689 - val_mae: 29.5649\n",
      "Epoch 202/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9780 - mae: 10.4711 - val_loss: 29.7311 - val_mae: 30.2289\n",
      "Epoch 203/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7707 - mae: 10.2633 - val_loss: 29.7303 - val_mae: 30.2300\n",
      "Epoch 204/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.9478 - mae: 11.4360 - val_loss: 29.4936 - val_mae: 29.9882\n",
      "Epoch 205/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.5924 - mae: 11.0822 - val_loss: 29.4883 - val_mae: 29.9864\n",
      "Epoch 206/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7187 - mae: 10.2060 - val_loss: 29.6796 - val_mae: 30.1766\n",
      "Epoch 207/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1755 - mae: 10.6613 - val_loss: 29.5755 - val_mae: 30.0703\n",
      "Epoch 208/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8462 - mae: 10.3352 - val_loss: 29.6647 - val_mae: 30.1591\n",
      "Epoch 209/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9417 - mae: 10.4313 - val_loss: 29.8694 - val_mae: 30.3650\n",
      "Epoch 210/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3656 - mae: 10.8557 - val_loss: 29.7809 - val_mae: 30.2766\n",
      "Epoch 211/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6226 - mae: 10.1065 - val_loss: 29.5334 - val_mae: 30.0304\n",
      "Epoch 212/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0271 - mae: 10.5156 - val_loss: 29.6491 - val_mae: 30.1451\n",
      "Epoch 213/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7522 - mae: 10.2453 - val_loss: 29.7546 - val_mae: 30.2527\n",
      "Epoch 214/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9852 - mae: 10.4731 - val_loss: 29.8590 - val_mae: 30.3589\n",
      "Epoch 215/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8152 - mae: 10.2987 - val_loss: 29.9656 - val_mae: 30.4649\n",
      "Epoch 216/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9727 - mae: 10.4610 - val_loss: 29.8369 - val_mae: 30.3317\n",
      "Epoch 217/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7147 - mae: 10.2052 - val_loss: 29.8192 - val_mae: 30.3169\n",
      "Epoch 218/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8104 - mae: 10.3010 - val_loss: 29.8230 - val_mae: 30.3195\n",
      "Epoch 219/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5902 - mae: 10.0806 - val_loss: 29.7442 - val_mae: 30.2422\n",
      "Epoch 220/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5056 - mae: 9.9880 - val_loss: 29.7844 - val_mae: 30.2831\n",
      "Epoch 221/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8805 - mae: 10.3675 - val_loss: 29.8416 - val_mae: 30.3390\n",
      "Epoch 222/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2996 - mae: 9.7870 - val_loss: 29.9344 - val_mae: 30.4300\n",
      "Epoch 223/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6778 - mae: 10.1679 - val_loss: 29.4287 - val_mae: 29.9265\n",
      "Epoch 224/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5735 - mae: 10.0567 - val_loss: 29.7032 - val_mae: 30.1970\n",
      "Epoch 225/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2984 - mae: 9.7849 - val_loss: 29.8681 - val_mae: 30.3667\n",
      "Epoch 226/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2805 - mae: 10.7678 - val_loss: 29.6539 - val_mae: 30.1507\n",
      "Epoch 227/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4657 - mae: 9.9577 - val_loss: 29.7761 - val_mae: 30.2711\n",
      "Epoch 228/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6507 - mae: 10.1406 - val_loss: 29.7941 - val_mae: 30.2915\n",
      "Epoch 229/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3386 - mae: 9.8240 - val_loss: 29.7148 - val_mae: 30.2104\n",
      "Epoch 230/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6857 - mae: 10.1745 - val_loss: 29.5945 - val_mae: 30.0931\n",
      "Epoch 231/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3569 - mae: 9.8455 - val_loss: 29.7529 - val_mae: 30.2486\n",
      "Epoch 232/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1824 - mae: 9.6684 - val_loss: 30.0733 - val_mae: 30.5698\n",
      "Epoch 233/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9880 - mae: 10.4727 - val_loss: 30.0157 - val_mae: 30.5143\n",
      "Epoch 234/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5505 - mae: 9.0395 - val_loss: 29.8800 - val_mae: 30.3763\n",
      "Epoch 235/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2140 - mae: 9.7007 - val_loss: 29.8965 - val_mae: 30.3944\n",
      "Epoch 236/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3876 - mae: 9.8733 - val_loss: 29.9703 - val_mae: 30.4664\n",
      "Epoch 237/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2710 - mae: 9.7610 - val_loss: 29.9108 - val_mae: 30.4015\n",
      "Epoch 238/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9194 - mae: 10.4102 - val_loss: 30.4598 - val_mae: 30.9566\n",
      "Epoch 239/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8520 - mae: 9.3424 - val_loss: 30.2350 - val_mae: 30.7328\n",
      "Epoch 240/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7268 - mae: 9.2201 - val_loss: 30.1159 - val_mae: 30.6111\n",
      "Epoch 241/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3800 - mae: 9.8685 - val_loss: 30.3241 - val_mae: 30.8209\n",
      "Epoch 242/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2355 - mae: 9.7191 - val_loss: 29.9686 - val_mae: 30.4672\n",
      "Epoch 243/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5534 - mae: 10.0416 - val_loss: 29.8435 - val_mae: 30.3389\n",
      "Epoch 244/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1482 - mae: 9.6333 - val_loss: 29.7790 - val_mae: 30.2780\n",
      "Epoch 245/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8375 - mae: 9.3194 - val_loss: 30.2018 - val_mae: 30.6996\n",
      "Epoch 246/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9182 - mae: 9.4078 - val_loss: 30.1235 - val_mae: 30.6159\n",
      "Epoch 247/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8235 - mae: 9.3106 - val_loss: 29.9174 - val_mae: 30.4159\n",
      "Epoch 248/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9787 - mae: 9.4666 - val_loss: 29.9311 - val_mae: 30.4285\n",
      "Epoch 249/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9304 - mae: 9.4179 - val_loss: 30.1289 - val_mae: 30.6289\n",
      "Epoch 250/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6444 - mae: 9.1298 - val_loss: 30.1411 - val_mae: 30.6339\n",
      "Epoch 251/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6782 - mae: 9.1661 - val_loss: 30.1487 - val_mae: 30.6487\n",
      "Epoch 252/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6344 - mae: 10.1199 - val_loss: 30.1960 - val_mae: 30.6918\n",
      "Epoch 253/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4448 - mae: 8.9337 - val_loss: 30.3886 - val_mae: 30.8822\n",
      "Epoch 254/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2351 - mae: 9.7236 - val_loss: 30.0855 - val_mae: 30.5855\n",
      "Epoch 255/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0653 - mae: 8.5571 - val_loss: 29.8927 - val_mae: 30.3866\n",
      "Epoch 256/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0058 - mae: 9.4926 - val_loss: 29.9976 - val_mae: 30.4962\n",
      "Epoch 257/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7109 - mae: 9.1957 - val_loss: 30.1065 - val_mae: 30.6052\n",
      "Epoch 258/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2515 - mae: 8.7402 - val_loss: 30.0918 - val_mae: 30.5893\n",
      "Epoch 259/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8397 - mae: 9.3307 - val_loss: 29.8938 - val_mae: 30.3892\n",
      "Epoch 260/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4425 - mae: 8.9303 - val_loss: 29.9673 - val_mae: 30.4606\n",
      "Epoch 261/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9071 - mae: 8.3954 - val_loss: 30.0731 - val_mae: 30.5678\n",
      "Epoch 262/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9978 - mae: 8.4829 - val_loss: 30.6193 - val_mae: 31.1161\n",
      "Epoch 263/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2417 - mae: 8.7319 - val_loss: 30.5036 - val_mae: 31.0007\n",
      "Epoch 264/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3843 - mae: 8.8683 - val_loss: 29.9557 - val_mae: 30.4520\n",
      "Epoch 265/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5620 - mae: 9.0487 - val_loss: 30.0038 - val_mae: 30.4996\n",
      "Epoch 266/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2728 - mae: 8.7615 - val_loss: 29.6819 - val_mae: 30.1775\n",
      "Epoch 267/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3510 - mae: 8.8323 - val_loss: 30.0203 - val_mae: 30.5176\n",
      "Epoch 268/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4818 - mae: 8.9699 - val_loss: 29.8529 - val_mae: 30.3528\n",
      "Epoch 269/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6184 - mae: 9.1043 - val_loss: 29.8223 - val_mae: 30.3196\n",
      "Epoch 270/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9593 - mae: 8.4385 - val_loss: 29.8744 - val_mae: 30.3701\n",
      "Epoch 271/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1874 - mae: 8.6741 - val_loss: 30.2687 - val_mae: 30.7684\n",
      "Epoch 272/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4572 - mae: 8.9452 - val_loss: 30.3112 - val_mae: 30.8107\n",
      "Epoch 273/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5729 - mae: 9.0613 - val_loss: 30.2247 - val_mae: 30.7216\n",
      "Epoch 274/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7728 - mae: 9.2564 - val_loss: 30.3826 - val_mae: 30.8796\n",
      "Epoch 275/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9230 - mae: 8.4079 - val_loss: 30.3179 - val_mae: 30.8153\n",
      "Epoch 276/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5072 - mae: 8.9958 - val_loss: 30.5520 - val_mae: 31.0505\n",
      "Epoch 277/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4242 - mae: 8.9128 - val_loss: 30.1908 - val_mae: 30.6879\n",
      "Epoch 278/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5267 - mae: 9.0138 - val_loss: 29.8380 - val_mae: 30.3327\n",
      "Epoch 279/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1402 - mae: 8.6293 - val_loss: 29.8338 - val_mae: 30.3320\n",
      "Epoch 280/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6738 - mae: 8.1584 - val_loss: 29.9560 - val_mae: 30.4544\n",
      "Epoch 281/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9939 - mae: 8.4827 - val_loss: 30.2284 - val_mae: 30.7265\n",
      "Epoch 282/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5247 - mae: 9.0075 - val_loss: 30.2372 - val_mae: 30.7313\n",
      "Epoch 283/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2898 - mae: 8.7836 - val_loss: 30.1997 - val_mae: 30.6962\n",
      "Epoch 284/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3838 - mae: 8.8700 - val_loss: 30.2762 - val_mae: 30.7744\n",
      "Epoch 285/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1802 - mae: 8.6677 - val_loss: 30.2860 - val_mae: 30.7817\n",
      "Epoch 286/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4765 - mae: 8.9645 - val_loss: 29.9546 - val_mae: 30.4492\n",
      "Epoch 287/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6806 - mae: 8.1718 - val_loss: 30.2708 - val_mae: 30.7685\n",
      "Epoch 288/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1627 - mae: 8.6522 - val_loss: 30.4186 - val_mae: 30.9104\n",
      "Epoch 289/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0569 - mae: 8.5465 - val_loss: 30.3268 - val_mae: 30.8201\n",
      "Epoch 290/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2276 - mae: 8.7120 - val_loss: 30.2015 - val_mae: 30.6943\n",
      "Epoch 291/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8493 - mae: 8.3375 - val_loss: 30.3347 - val_mae: 30.8292\n",
      "Epoch 292/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7842 - mae: 8.2674 - val_loss: 30.3284 - val_mae: 30.8260\n",
      "Epoch 293/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5127 - mae: 7.9962 - val_loss: 30.0642 - val_mae: 30.5576\n",
      "Epoch 294/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8473 - mae: 8.3293 - val_loss: 30.3356 - val_mae: 30.8300\n",
      "Epoch 295/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6786 - mae: 8.1688 - val_loss: 30.2730 - val_mae: 30.7702\n",
      "Epoch 296/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7271 - mae: 8.2188 - val_loss: 30.3208 - val_mae: 30.8208\n",
      "Epoch 297/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8612 - mae: 8.3443 - val_loss: 30.1964 - val_mae: 30.6944\n",
      "Epoch 298/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8960 - mae: 8.3751 - val_loss: 30.0378 - val_mae: 30.5366\n",
      "Epoch 299/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0040 - mae: 8.4939 - val_loss: 30.0027 - val_mae: 30.4955\n",
      "Epoch 300/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6011 - mae: 9.0879 - val_loss: 30.2562 - val_mae: 30.7478\n",
      "Epoch 301/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8187 - mae: 8.3069 - val_loss: 30.1239 - val_mae: 30.6231\n",
      "Epoch 302/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7407 - mae: 8.2280 - val_loss: 30.0796 - val_mae: 30.5784\n",
      "Epoch 303/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7821 - mae: 8.2652 - val_loss: 30.4421 - val_mae: 30.9341\n",
      "Epoch 304/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5619 - mae: 8.0437 - val_loss: 30.7500 - val_mae: 31.2434\n",
      "Epoch 305/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0516 - mae: 8.5439 - val_loss: 30.4180 - val_mae: 30.9139\n",
      "Epoch 306/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0777 - mae: 8.5683 - val_loss: 30.2712 - val_mae: 30.7682\n",
      "Epoch 307/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3627 - mae: 7.8497 - val_loss: 30.0882 - val_mae: 30.5855\n",
      "Epoch 308/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8139 - mae: 8.3026 - val_loss: 30.1007 - val_mae: 30.5975\n",
      "Epoch 309/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7772 - mae: 8.2615 - val_loss: 30.4327 - val_mae: 30.9305\n",
      "Epoch 310/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1361 - mae: 8.6212 - val_loss: 30.4973 - val_mae: 30.9945\n",
      "Epoch 311/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1880 - mae: 8.6725 - val_loss: 30.0794 - val_mae: 30.5753\n",
      "Epoch 312/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4899 - mae: 7.9711 - val_loss: 30.6581 - val_mae: 31.1577\n",
      "Epoch 313/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5923 - mae: 8.0819 - val_loss: 30.2686 - val_mae: 30.7627\n",
      "Epoch 314/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2165 - mae: 7.7043 - val_loss: 30.0728 - val_mae: 30.5701\n",
      "Epoch 315/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9154 - mae: 8.4003 - val_loss: 30.1382 - val_mae: 30.6372\n",
      "Epoch 316/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5500 - mae: 8.0368 - val_loss: 30.2262 - val_mae: 30.7217\n",
      "Epoch 317/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4152 - mae: 7.9004 - val_loss: 30.1739 - val_mae: 30.6723\n",
      "Epoch 318/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0406 - mae: 8.5295 - val_loss: 30.3330 - val_mae: 30.8304\n",
      "Epoch 319/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3252 - mae: 7.8113 - val_loss: 30.3111 - val_mae: 30.8039\n",
      "Epoch 320/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8051 - mae: 8.2930 - val_loss: 30.2981 - val_mae: 30.7941\n",
      "Epoch 321/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6084 - mae: 8.0992 - val_loss: 30.3944 - val_mae: 30.8931\n",
      "Epoch 322/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0098 - mae: 7.4967 - val_loss: 30.1563 - val_mae: 30.6553\n",
      "Epoch 323/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4828 - mae: 7.9750 - val_loss: 30.1641 - val_mae: 30.6635\n",
      "Epoch 324/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6204 - mae: 8.1043 - val_loss: 30.0198 - val_mae: 30.5187\n",
      "Epoch 325/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1447 - mae: 7.6290 - val_loss: 29.9616 - val_mae: 30.4541\n",
      "Epoch 326/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4209 - mae: 7.9102 - val_loss: 29.9011 - val_mae: 30.3986\n",
      "Epoch 327/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7699 - mae: 8.2560 - val_loss: 30.3920 - val_mae: 30.8885\n",
      "Epoch 328/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9591 - mae: 8.4493 - val_loss: 30.4138 - val_mae: 30.9125\n",
      "Epoch 329/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0697 - mae: 7.5547 - val_loss: 30.6361 - val_mae: 31.1351\n",
      "Epoch 330/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0821 - mae: 7.5638 - val_loss: 30.3571 - val_mae: 30.8551\n",
      "Epoch 331/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7729 - mae: 8.2592 - val_loss: 30.4092 - val_mae: 30.9063\n",
      "Epoch 332/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1946 - mae: 7.6784 - val_loss: 30.4628 - val_mae: 30.9604\n",
      "Epoch 333/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4600 - mae: 7.9457 - val_loss: 30.0201 - val_mae: 30.5201\n",
      "Epoch 334/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5028 - mae: 7.9961 - val_loss: 29.7057 - val_mae: 30.2057\n",
      "Epoch 335/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2483 - mae: 7.7373 - val_loss: 29.9865 - val_mae: 30.4865\n",
      "Epoch 336/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6282 - mae: 7.1086 - val_loss: 29.9745 - val_mae: 30.4738\n",
      "Epoch 337/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1867 - mae: 7.6749 - val_loss: 30.5073 - val_mae: 31.0072\n",
      "Epoch 338/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0214 - mae: 7.5074 - val_loss: 29.8131 - val_mae: 30.3111\n",
      "Epoch 339/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9100 - mae: 7.3970 - val_loss: 30.2493 - val_mae: 30.7483\n",
      "Epoch 340/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3462 - mae: 7.8349 - val_loss: 30.2075 - val_mae: 30.7007\n",
      "Epoch 341/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4926 - mae: 7.9811 - val_loss: 29.9634 - val_mae: 30.4631\n",
      "Epoch 342/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6290 - mae: 8.1196 - val_loss: 30.1660 - val_mae: 30.6614\n",
      "Epoch 343/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5217 - mae: 8.0092 - val_loss: 30.3932 - val_mae: 30.8907\n",
      "Epoch 344/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4282 - mae: 7.9119 - val_loss: 30.3676 - val_mae: 30.8630\n",
      "Epoch 345/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1835 - mae: 7.6705 - val_loss: 30.1685 - val_mae: 30.6653\n",
      "Epoch 346/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8393 - mae: 7.3246 - val_loss: 30.3510 - val_mae: 30.8474\n",
      "Epoch 347/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5577 - mae: 7.0369 - val_loss: 30.4517 - val_mae: 30.9486\n",
      "Epoch 348/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6054 - mae: 8.0891 - val_loss: 29.9529 - val_mae: 30.4462\n",
      "Epoch 349/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9797 - mae: 7.4668 - val_loss: 30.3656 - val_mae: 30.8656\n",
      "Epoch 350/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2781 - mae: 7.7652 - val_loss: 30.0073 - val_mae: 30.5020\n",
      "Epoch 351/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4640 - mae: 6.9524 - val_loss: 30.5490 - val_mae: 31.0460\n",
      "Epoch 352/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1768 - mae: 7.6665 - val_loss: 30.3036 - val_mae: 30.8029\n",
      "Epoch 353/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5488 - mae: 7.0310 - val_loss: 30.0577 - val_mae: 30.5567\n",
      "Epoch 354/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3465 - mae: 7.8292 - val_loss: 30.0756 - val_mae: 30.5734\n",
      "Epoch 355/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6739 - mae: 7.1567 - val_loss: 29.8042 - val_mae: 30.3012\n",
      "Epoch 356/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1771 - mae: 7.6674 - val_loss: 29.6850 - val_mae: 30.1747\n",
      "Epoch 357/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0743 - mae: 7.5656 - val_loss: 29.7558 - val_mae: 30.2514\n",
      "Epoch 358/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5902 - mae: 7.0734 - val_loss: 29.9843 - val_mae: 30.4814\n",
      "Epoch 359/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6253 - mae: 7.1126 - val_loss: 30.0644 - val_mae: 30.5610\n",
      "Epoch 360/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2719 - mae: 7.7591 - val_loss: 30.2471 - val_mae: 30.7426\n",
      "Epoch 361/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4024 - mae: 7.8867 - val_loss: 30.3542 - val_mae: 30.8537\n",
      "Epoch 362/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5966 - mae: 7.0780 - val_loss: 30.3344 - val_mae: 30.8326\n",
      "Epoch 363/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3977 - mae: 7.8861 - val_loss: 30.4327 - val_mae: 30.9297\n",
      "Epoch 364/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0770 - mae: 7.5587 - val_loss: 29.7694 - val_mae: 30.2667\n",
      "Epoch 365/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9945 - mae: 7.4804 - val_loss: 29.8574 - val_mae: 30.3565\n",
      "Epoch 366/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4621 - mae: 6.9446 - val_loss: 30.4116 - val_mae: 30.9073\n",
      "Epoch 367/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1527 - mae: 7.6400 - val_loss: 30.7329 - val_mae: 31.2317\n",
      "Epoch 368/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8795 - mae: 7.3624 - val_loss: 30.2185 - val_mae: 30.7166\n",
      "Epoch 369/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9431 - mae: 7.4260 - val_loss: 30.4091 - val_mae: 30.9081\n",
      "Epoch 370/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6809 - mae: 7.1618 - val_loss: 30.2247 - val_mae: 30.7234\n",
      "Epoch 371/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6639 - mae: 7.1440 - val_loss: 30.0241 - val_mae: 30.5203\n",
      "Epoch 372/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7421 - mae: 7.2266 - val_loss: 29.9587 - val_mae: 30.4555\n",
      "Epoch 373/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1686 - mae: 7.6580 - val_loss: 30.1298 - val_mae: 30.6295\n",
      "Epoch 374/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0532 - mae: 7.5415 - val_loss: 30.0716 - val_mae: 30.5703\n",
      "Epoch 375/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8723 - mae: 7.3570 - val_loss: 29.9657 - val_mae: 30.4626\n",
      "Epoch 376/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6939 - mae: 7.1763 - val_loss: 30.2174 - val_mae: 30.7115\n",
      "Epoch 377/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7703 - mae: 7.2474 - val_loss: 30.4615 - val_mae: 30.9567\n",
      "Epoch 378/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8687 - mae: 7.3530 - val_loss: 30.1428 - val_mae: 30.6384\n",
      "Epoch 379/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8035 - mae: 7.2918 - val_loss: 29.9218 - val_mae: 30.4201\n",
      "Epoch 380/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9593 - mae: 7.4497 - val_loss: 30.0330 - val_mae: 30.5297\n",
      "Epoch 381/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4578 - mae: 6.9392 - val_loss: 29.8307 - val_mae: 30.3275\n",
      "Epoch 382/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0225 - mae: 7.5042 - val_loss: 29.9575 - val_mae: 30.4564\n",
      "Epoch 383/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0320 - mae: 7.5137 - val_loss: 29.6114 - val_mae: 30.1051\n",
      "Epoch 384/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3523 - mae: 6.8388 - val_loss: 29.6087 - val_mae: 30.1054\n",
      "Epoch 385/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0480 - mae: 7.5363 - val_loss: 29.9409 - val_mae: 30.4393\n",
      "Epoch 386/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3125 - mae: 6.7884 - val_loss: 30.0059 - val_mae: 30.5056\n",
      "Epoch 387/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3560 - mae: 7.8484 - val_loss: 30.2233 - val_mae: 30.7187\n",
      "Epoch 388/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0485 - mae: 7.5350 - val_loss: 29.9024 - val_mae: 30.4017\n",
      "Epoch 389/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7493 - mae: 7.2346 - val_loss: 29.9260 - val_mae: 30.4234\n",
      "Epoch 390/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7984 - mae: 7.2887 - val_loss: 30.1140 - val_mae: 30.6079\n",
      "Epoch 391/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7315 - mae: 7.2231 - val_loss: 29.8447 - val_mae: 30.3427\n",
      "Epoch 392/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5128 - mae: 6.9970 - val_loss: 29.7541 - val_mae: 30.2525\n",
      "Epoch 393/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1459 - mae: 7.6277 - val_loss: 30.1733 - val_mae: 30.6733\n",
      "Epoch 394/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5208 - mae: 7.0098 - val_loss: 30.4012 - val_mae: 30.8996\n",
      "Epoch 395/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1805 - mae: 7.6701 - val_loss: 30.0558 - val_mae: 30.5534\n",
      "Epoch 396/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6765 - mae: 7.1564 - val_loss: 30.2234 - val_mae: 30.7234\n",
      "Epoch 397/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8762 - mae: 7.3615 - val_loss: 30.3798 - val_mae: 30.8793\n",
      "Epoch 398/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7543 - mae: 7.2359 - val_loss: 30.6303 - val_mae: 31.1201\n",
      "Epoch 399/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6678 - mae: 7.1449 - val_loss: 30.0075 - val_mae: 30.5046\n",
      "Epoch 400/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5456 - mae: 7.0338 - val_loss: 30.2338 - val_mae: 30.7293\n",
      "Test Loss: 28.9227, Test MAE: 29.4188\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E75E471E40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "True: 67.89, Predicted: 33.29\n",
      "True: 48.64, Predicted: 46.94\n",
      "True: 16.54, Predicted: 57.88\n",
      "True: 47.05, Predicted: 25.62\n",
      "True: 78.52, Predicted: 51.80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import Huber\n",
    "\n",
    "# Example: Generate Synthetic Data (Replace with your dataset)\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 10, 1)  # 1000 samples, 10 time steps, 1 feature\n",
    "y = np.random.rand(1000) * 100  # Regression target\n",
    "\n",
    "# 1. Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Normalize the Data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# 3. Define the Model\n",
    "model = Sequential([\n",
    "    Conv1D(128, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(64, kernel_size=2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])\n",
    "\n",
    "# 4. Compile the Model\n",
    "optimizer = Adam(learning_rate=0.0005)  # Lower learning rate\n",
    "model.compile(optimizer=optimizer, loss=Huber(), metrics=['mae'])\n",
    "\n",
    "# 5. Define Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 6. Train the Model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=400,\n",
    "    batch_size=32,\n",
    "    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7. Evaluate the Model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "# 8. Plot Training History\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# 9. Predict on Test Data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Example: Compare True and Predicted Values\n",
    "for true, pred in zip(y_test[:5], y_pred[:5]):\n",
    "    print(f\"True: {true:.2f}, Predicted: {pred[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e09a5-6918-4c16-bc96-fab676450b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
