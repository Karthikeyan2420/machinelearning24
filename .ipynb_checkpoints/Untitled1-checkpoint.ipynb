{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ffcd608-4423-461c-a543-c4a2a677f2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['text', 'mining', 'is', 'the', 'process', 'of', 'extracting', 'meaningful', 'information', 'from', 'text', 'data', 'it', 'involves', 'transforming', 'unstructured', 'data', 'into', 'structured', 'data', 'for', 'analysis']\n",
      "Filtered Tokens (No Stop Words): ['text', 'mining', 'process', 'extracting', 'meaningful', 'information', 'text', 'data', 'involves', 'transforming', 'unstructured', 'data', 'structured', 'data', 'analysis']\n",
      "Word Frequencies: Counter({'data': 3, 'text': 2, 'mining': 1, 'process': 1, 'extracting': 1, 'meaningful': 1, 'information': 1, 'involves': 1, 'transforming': 1, 'unstructured': 1, 'structured': 1, 'analysis': 1})\n",
      "Most Common Words: [('data', 3), ('text', 2), ('mining', 1), ('process', 1), ('extracting', 1)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"Text mining is the process of extracting meaningful information from text data. \n",
    "It involves transforming unstructured data into structured data for analysis.\"\"\"\n",
    "\n",
    "# Step 1: Preprocess the text (convert to lowercase and remove punctuation)\n",
    "text_cleaned = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "# Step 2: Tokenize the text (split into words)\n",
    "tokens = text_cleaned.split()\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Step 3: Remove stop words manually\n",
    "stop_words = {\"is\", \"the\", \"of\", \"from\", \"it\", \"for\", \"and\", \"into\"}\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "print(\"Filtered Tokens (No Stop Words):\", filtered_tokens)\n",
    "\n",
    "# Step 4: Count word frequencies\n",
    "word_counts = Counter(filtered_tokens)\n",
    "print(\"Word Frequencies:\", word_counts)\n",
    "\n",
    "# Step 5: Identify the most common words\n",
    "most_common_words = word_counts.most_common(5)\n",
    "print(\"Most Common Words:\", most_common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "004c41e9-c154-49a2-8cb1-c933b5be4566",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy Model for NLP\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function for Data Extraction\n",
    "def extract_data(url=None, file_path=None):\n",
    "    if url:\n",
    "        # Web scraping\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text_data = soup.get_text(separator=\"\\n\")\n",
    "        return text_data\n",
    "    elif file_path:\n",
    "        # Reading a local file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    else:\n",
    "        raise ValueError(\"Provide a URL or file path for data extraction!\")\n",
    "\n",
    "# Function for NLP Processing\n",
    "def process_text(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    word_freq = {}\n",
    "    for token in doc:\n",
    "        if token.is_alpha and not token.is_stop:\n",
    "            word_freq[token.text.lower()] = word_freq.get(token.text.lower(), 0) + 1\n",
    "    return entities, word_freq\n",
    "\n",
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Extract text from a URL or a local file\n",
    "    # url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "    # text = extract_data(url=url)\n",
    "    file_path = \"example.txt\"  # Replace with a valid file path\n",
    "    text = extract_data(file_path=file_path)\n",
    "\n",
    "    # Process the extracted text\n",
    "    named_entities, word_frequency = process_text(text)\n",
    "\n",
    "    # Display Results\n",
    "    print(\"Named Entities:\")\n",
    "    for entity, label in named_entities:\n",
    "        print(f\"{entity} ({label})\")\n",
    "\n",
    "    print(\"\\nWord Frequency:\")\n",
    "    word_freq_df = pd.DataFrame(word_frequency.items(), columns=[\"Word\", \"Frequency\"]).sort_values(by=\"Frequency\", ascending=False)\n",
    "    print(word_freq_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fba85f-be75-4276-95d5-630108e06583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01e0b4-e444-4251-93e8-54b0c9d166cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
